{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbfU1KJjEuLq"
   },
   "source": [
    "## **In this notebook (Random Forest)**\n",
    "I followed a step-by-step process to train and tune each model efficiently. First, I created a baseline model using a 100k-row subset with basic parameters, giving me a reference point to measure how hyperparameter tuning impacted performance. Next, I experimented with different parameter settings on this 100k subset to identify the best configurations. Once I had the optimal parameters, I scaled up to the full 600k-row dataset to test how well these settings performed on a larger scale.\n",
    "<br>\n",
    "\n",
    "This approach was necessary because a single run of `Random Forest` was taking around 9 hours, making it impractical to tune all 8 parameters directly on the full dataset. By downsizing hyperparameter tuning to 100k rows, I could find the best parameters and then apply them to 600k rows for final testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10218,
     "status": "ok",
     "timestamp": 1729800391604,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "TrusAsY8DQjh",
    "outputId": "9812ab74-f793-4a6d-c159-8b0e849c4a93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tqdm is already installed.\n",
      "\n",
      "dask is already installed.\n",
      "\n",
      "nltk is already installed.\n",
      "\n",
      "scikit-learn is NOT installed. Installing now...\n",
      "scikit-learn installation completed.\n",
      "\n",
      "numpy is already installed.\n",
      "\n",
      "pyspark is already installed.\n",
      "\n",
      "gdown is already installed.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import subprocess\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "def check_and_install_package(package_name):\n",
    "    try:\n",
    "        importlib.import_module(package_name)\n",
    "        print(f\"\\n{package_name} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"\\n{package_name} is NOT installed. Installing now...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
    "        print(f\"{package_name} installation completed.\")\n",
    "\n",
    "# List of packages to check\n",
    "packages = [\n",
    "    \"tqdm\",\n",
    "    \"dask\",\n",
    "    \"nltk\",\n",
    "    \"scikit-learn\",\n",
    "    \"numpy\",\n",
    "    \"pyspark\",\n",
    "    \"gdown\"\n",
    "]\n",
    "\n",
    "# Checking and installing the packages\n",
    "for package in packages:\n",
    "    check_and_install_package(package)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19879,
     "status": "ok",
     "timestamp": 1729800414017,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "RB9_uhR9DTds",
    "outputId": "c1108c47-5960-4272-bf45-17d14e042bd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8404,
     "status": "ok",
     "timestamp": 1729800424094,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "b28mbQ0oJnLj",
    "outputId": "998108d5-d9a6-4da9-d3d9-be645a3ee748"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session started with version: 3.5.3\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RandomForestModel\") \\\n",
    "    .config(\"spark.driver.memory\", \"16g\") \\\n",
    "    .config(\"spark.executor.memory\", \"16g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"8g\") \\\n",
    "    .config(\"spark.executor.memoryOverhead\", \"12g\") \\\n",
    "    .config(\"spark.executor.cores\", \"5\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2047m\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.file.impl\", \"org.apache.hadoop.fs.LocalFileSystem\") \\\n",
    "    .config(\"spark.executor.extraJavaOptions\", \"-XX:+UseG1GC -XX:InitiatingHeapOccupancyPercent=35 -XX:ConcGCThreads=4 -XX:ParallelGCThreads=4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Verifying Spark session creation\n",
    "print(f\"Spark session started with version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12318,
     "status": "ok",
     "timestamp": 1729800436409,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "5bKzhFj55zKq",
    "outputId": "98efff96-a00b-420e-c1b6-a9ee436e4543"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Feature Engineered DataFrame has been loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "!cp '/content/drive/MyDrive/Big Data Analytics - Project/Datasets/Feature_Engineered_DF.parquet' /content/\n",
    "\n",
    "output_path = '/content/Feature_Engineered_DF.parquet'\n",
    "df = spark.read.parquet(output_path)\n",
    "print(\"The Feature Engineered DataFrame has been loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2293,
     "status": "ok",
     "timestamp": 1729800438700,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "ihYMF6M96BHG",
    "outputId": "f97e5896-b21f-4ed5-a2ae-839db6578f94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the loaded DataFrame is: (3000040, 47)\n"
     ]
    }
   ],
   "source": [
    "# Printing the shape of the DataFrame\n",
    "total_rows = df.count()\n",
    "total_columns = len(df.columns)\n",
    "\n",
    "print(f\"The shape of the loaded DataFrame is: ({total_rows}, {total_columns})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1729800439730,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "o3En3RUf6J6y",
    "outputId": "741d91bc-7b08-4a88-879f-3c180ad12dfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average price of a car: 29933\n"
     ]
    }
   ],
   "source": [
    "# Calculating the average price\n",
    "avg_price = df.agg({\"price\": \"avg\"}).collect()[0][0]\n",
    "print(f\"Average price of a car: {round(avg_price)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "executionInfo": {
     "elapsed": 11624,
     "status": "ok",
     "timestamp": 1729800451352,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "F8KnhlDP6Ov0",
    "outputId": "9399640a-6ebd-4146-bb4c-42c2828e5560"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "pandas_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-94d42482-32d9-4435-a460-261710b1ed03\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>body_type</th>\n",
       "      <th>city</th>\n",
       "      <th>city_fuel_economy</th>\n",
       "      <th>days_in_market</th>\n",
       "      <th>dealer_zip</th>\n",
       "      <th>engine_displacement</th>\n",
       "      <th>engine_type</th>\n",
       "      <th>exterior_color</th>\n",
       "      <th>franchise_dealer</th>\n",
       "      <th>fuel_tank_volume</th>\n",
       "      <th>height</th>\n",
       "      <th>highway_fuel_economy</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>interior_color</th>\n",
       "      <th>is_new</th>\n",
       "      <th>latitude</th>\n",
       "      <th>length</th>\n",
       "      <th>listing_color</th>\n",
       "      <th>longitude</th>\n",
       "      <th>make_name</th>\n",
       "      <th>maximum_seating</th>\n",
       "      <th>model_name</th>\n",
       "      <th>price</th>\n",
       "      <th>savings_amount</th>\n",
       "      <th>seller_rating</th>\n",
       "      <th>sp_name</th>\n",
       "      <th>torque</th>\n",
       "      <th>transmission</th>\n",
       "      <th>transmission_display</th>\n",
       "      <th>wheel_system_display</th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>width</th>\n",
       "      <th>manufactured_year</th>\n",
       "      <th>combined_fuel_economy</th>\n",
       "      <th>legroom</th>\n",
       "      <th>log_mileage</th>\n",
       "      <th>major_options_count</th>\n",
       "      <th>hp_x_engine_disp</th>\n",
       "      <th>hp_x_torque</th>\n",
       "      <th>listed_day</th>\n",
       "      <th>listed_month</th>\n",
       "      <th>listed_year</th>\n",
       "      <th>age</th>\n",
       "      <th>resale_value_score</th>\n",
       "      <th>maintenance_cost</th>\n",
       "      <th>luxury_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gasoline</td>\n",
       "      <td>SUV / Crossover</td>\n",
       "      <td>North Dartmouth</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18</td>\n",
       "      <td>02747</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>I4</td>\n",
       "      <td>Blue</td>\n",
       "      <td>True</td>\n",
       "      <td>17.4</td>\n",
       "      <td>64.5</td>\n",
       "      <td>28.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>Mixed Colors</td>\n",
       "      <td>False</td>\n",
       "      <td>41.639900</td>\n",
       "      <td>183.3</td>\n",
       "      <td>BLUE</td>\n",
       "      <td>-71.005402</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>5.0</td>\n",
       "      <td>GLC-Class</td>\n",
       "      <td>37635.0</td>\n",
       "      <td>276</td>\n",
       "      <td>3.263158</td>\n",
       "      <td>Dartmouth Nissan</td>\n",
       "      <td>273.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>All-Wheel Drive</td>\n",
       "      <td>113.1</td>\n",
       "      <td>82.5</td>\n",
       "      <td>2018</td>\n",
       "      <td>24.5</td>\n",
       "      <td>78.1</td>\n",
       "      <td>9.28</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.00537</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gasoline</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Antioch</td>\n",
       "      <td>33.0</td>\n",
       "      <td>19</td>\n",
       "      <td>37013</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>I4</td>\n",
       "      <td>Red</td>\n",
       "      <td>True</td>\n",
       "      <td>11.9</td>\n",
       "      <td>57.1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>36.043598</td>\n",
       "      <td>172.6</td>\n",
       "      <td>RED</td>\n",
       "      <td>-86.657501</td>\n",
       "      <td>Kia</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Rio</td>\n",
       "      <td>17202.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>Greenway Kia Hickory Hollow</td>\n",
       "      <td>112.0</td>\n",
       "      <td>CVT</td>\n",
       "      <td>Continuously Variable Transmission</td>\n",
       "      <td>Front-Wheel Drive</td>\n",
       "      <td>101.6</td>\n",
       "      <td>67.9</td>\n",
       "      <td>2020</td>\n",
       "      <td>37.0</td>\n",
       "      <td>75.6</td>\n",
       "      <td>0.69</td>\n",
       "      <td>3</td>\n",
       "      <td>1.48</td>\n",
       "      <td>2.04545</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gasoline</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>29.0</td>\n",
       "      <td>168</td>\n",
       "      <td>78233</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>I4</td>\n",
       "      <td>Other</td>\n",
       "      <td>True</td>\n",
       "      <td>12.4</td>\n",
       "      <td>56.9</td>\n",
       "      <td>39.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>29.526501</td>\n",
       "      <td>182.7</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>-98.393097</td>\n",
       "      <td>Nissan</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Sentra</td>\n",
       "      <td>19418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.159420</td>\n",
       "      <td>World Car Nissan Hyundai</td>\n",
       "      <td>146.0</td>\n",
       "      <td>CVT</td>\n",
       "      <td>Continuously Variable Transmission</td>\n",
       "      <td>Front-Wheel Drive</td>\n",
       "      <td>106.8</td>\n",
       "      <td>71.5</td>\n",
       "      <td>2020</td>\n",
       "      <td>34.0</td>\n",
       "      <td>81.4</td>\n",
       "      <td>1.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.22982</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gasoline</td>\n",
       "      <td>Pickup Truck</td>\n",
       "      <td>Apopka</td>\n",
       "      <td>16.0</td>\n",
       "      <td>61</td>\n",
       "      <td>32703</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>V6</td>\n",
       "      <td>Red</td>\n",
       "      <td>True</td>\n",
       "      <td>26.0</td>\n",
       "      <td>77.2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>28.672899</td>\n",
       "      <td>231.9</td>\n",
       "      <td>RED</td>\n",
       "      <td>-81.481102</td>\n",
       "      <td>Ford</td>\n",
       "      <td>6.0</td>\n",
       "      <td>F-150</td>\n",
       "      <td>56199.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>Mullinax Ford of Central Florida</td>\n",
       "      <td>400.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Four-Wheel Drive</td>\n",
       "      <td>145.0</td>\n",
       "      <td>96.8</td>\n",
       "      <td>2020</td>\n",
       "      <td>19.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>3.91</td>\n",
       "      <td>14</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.79666</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>43</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gasoline</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Jupiter</td>\n",
       "      <td>16.0</td>\n",
       "      <td>67</td>\n",
       "      <td>33458</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>V8</td>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>18.0</td>\n",
       "      <td>57.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>26.934799</td>\n",
       "      <td>195.4</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>-80.122498</td>\n",
       "      <td>BMW</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5 Series</td>\n",
       "      <td>51876.0</td>\n",
       "      <td>1139</td>\n",
       "      <td>4.777778</td>\n",
       "      <td>Braman BMW Jupiter</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "      <td>8-Speed Automatic</td>\n",
       "      <td>All-Wheel Drive</td>\n",
       "      <td>117.1</td>\n",
       "      <td>83.7</td>\n",
       "      <td>2018</td>\n",
       "      <td>20.5</td>\n",
       "      <td>77.9</td>\n",
       "      <td>10.81</td>\n",
       "      <td>12</td>\n",
       "      <td>2.63</td>\n",
       "      <td>4.68331</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94d42482-32d9-4435-a460-261710b1ed03')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-94d42482-32d9-4435-a460-261710b1ed03 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-94d42482-32d9-4435-a460-261710b1ed03');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-00562ee3-cd2d-4507-bd6c-7c72f3cbac22\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-00562ee3-cd2d-4507-bd6c-7c72f3cbac22')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-00562ee3-cd2d-4507-bd6c-7c72f3cbac22 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_6891af7d-af0b-4150-b5d0-2b98906af055\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pandas_df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_6891af7d-af0b-4150-b5d0-2b98906af055 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('pandas_df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "  fuel_type        body_type             city  city_fuel_economy  \\\n",
       "0  Gasoline  SUV / Crossover  North Dartmouth               21.0   \n",
       "1  Gasoline            Sedan          Antioch               33.0   \n",
       "2  Gasoline            Sedan      San Antonio               29.0   \n",
       "3  Gasoline     Pickup Truck           Apopka               16.0   \n",
       "4  Gasoline            Sedan          Jupiter               16.0   \n",
       "\n",
       "   days_in_market dealer_zip  engine_displacement engine_type exterior_color  \\\n",
       "0              18      02747               2000.0          I4           Blue   \n",
       "1              19      37013               1600.0          I4            Red   \n",
       "2             168      78233               2000.0          I4          Other   \n",
       "3              61      32703               3500.0          V6            Red   \n",
       "4              67      33458               4400.0          V8          Black   \n",
       "\n",
       "   franchise_dealer  fuel_tank_volume  height  highway_fuel_economy  \\\n",
       "0              True              17.4    64.5                  28.0   \n",
       "1              True              11.9    57.1                  41.0   \n",
       "2              True              12.4    56.9                  39.0   \n",
       "3              True              26.0    77.2                  22.0   \n",
       "4              True              18.0    57.8                  25.0   \n",
       "\n",
       "   horsepower interior_color  is_new   latitude  length listing_color  \\\n",
       "0       241.0   Mixed Colors   False  41.639900   183.3          BLUE   \n",
       "1       120.0          Black    True  36.043598   172.6           RED   \n",
       "2       149.0          Black    True  29.526501   182.7       UNKNOWN   \n",
       "3       375.0          Black    True  28.672899   231.9           RED   \n",
       "4       456.0          Other   False  26.934799   195.4         BLACK   \n",
       "\n",
       "   longitude      make_name  maximum_seating model_name    price  \\\n",
       "0 -71.005402  Mercedes-Benz              5.0  GLC-Class  37635.0   \n",
       "1 -86.657501            Kia              5.0        Rio  17202.0   \n",
       "2 -98.393097         Nissan              5.0     Sentra  19418.0   \n",
       "3 -81.481102           Ford              6.0      F-150  56199.0   \n",
       "4 -80.122498            BMW              5.0   5 Series  51876.0   \n",
       "\n",
       "   savings_amount  seller_rating                           sp_name  torque  \\\n",
       "0             276       3.263158                  Dartmouth Nissan   273.0   \n",
       "1               0       4.636364       Greenway Kia Hickory Hollow   112.0   \n",
       "2               0       4.159420          World Car Nissan Hyundai   146.0   \n",
       "3               0       4.285714  Mullinax Ford of Central Florida   400.0   \n",
       "4            1139       4.777778                Braman BMW Jupiter   480.0   \n",
       "\n",
       "  transmission                transmission_display wheel_system_display  \\\n",
       "0            A                           Automatic      All-Wheel Drive   \n",
       "1          CVT  Continuously Variable Transmission    Front-Wheel Drive   \n",
       "2          CVT  Continuously Variable Transmission    Front-Wheel Drive   \n",
       "3            A                           Automatic     Four-Wheel Drive   \n",
       "4            A                   8-Speed Automatic      All-Wheel Drive   \n",
       "\n",
       "   wheelbase  width  manufactured_year  combined_fuel_economy  legroom  \\\n",
       "0      113.1   82.5               2018                   24.5     78.1   \n",
       "1      101.6   67.9               2020                   37.0     75.6   \n",
       "2      106.8   71.5               2020                   34.0     81.4   \n",
       "3      145.0   96.8               2020                   19.0     87.5   \n",
       "4      117.1   83.7               2018                   20.5     77.9   \n",
       "\n",
       "   log_mileage  major_options_count  hp_x_engine_disp  hp_x_torque  \\\n",
       "0         9.28                    5              0.05     -0.00537   \n",
       "1         0.69                    3              1.48      2.04545   \n",
       "2         1.10                    6              0.80      1.22982   \n",
       "3         3.91                   14              0.62      1.79666   \n",
       "4        10.81                   12              2.63      4.68331   \n",
       "\n",
       "   listed_day  listed_month  listed_year  age  resale_value_score  \\\n",
       "0          22             8         2020    2                  29   \n",
       "1          23             8         2020    0                  32   \n",
       "2          27             3         2020    0                  28   \n",
       "3          11             7         2020    0                  29   \n",
       "4           5             7         2020    2                  24   \n",
       "\n",
       "   maintenance_cost  luxury_score  \n",
       "0                40            32  \n",
       "1                35            30  \n",
       "2                37            31  \n",
       "3                43            37  \n",
       "4                47            38  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Converting the Spark DataFrame to a Pandas DataFrame and displaying the first 5 rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "pandas_df = df.orderBy(F.rand()).limit(5).toPandas()\n",
    "display(pandas_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBxKsVzQFczh"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utIx-HLvDIWi"
   },
   "source": [
    "# **Random Forest Regressor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpTZYEZgFeCg"
   },
   "source": [
    "### **Initial Training on a Subset (100k Rows):**\n",
    "\n",
    "I begin by training Random Forest on a subset of 100k rows with specific parameters, establishing a baseline model. This baseline serves as a comparison point, allowing me to evaluate how each hyperparameter tuning experiment impacts performance, either increasing or decreasing metrics relative to the baseline. The initial 100k subset is thus used specifically for benchmarking improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3139169,
     "status": "ok",
     "timestamp": 1729587988075,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "j_G3V2-r4cRJ",
    "outputId": "315ea8b2-8335-400c-d9d0-bbec307cf74f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing and Training: 100%|██████████| 7/7 [50:48<00:00, 435.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Evaluating the model...\n",
      "\n",
      "\n",
      "R-Squared Score (Accuracy): 75.25%\n",
      "\n",
      "\n",
      "Train size: 79,346 samples\n",
      "Test size: 19,771 samples\n",
      "\n",
      "Overall runtime: 52 minutes.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, OneHotEncoder, Imputer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.sql.functions import mean as sql_mean, log\n",
    "import pyspark.sql.functions as F\n",
    "import time\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Starting to track overall runtime\n",
    "start_time = time.time()\n",
    "\n",
    "with tqdm(total=7, desc=\"Processing and Training\") as pbar:\n",
    "\n",
    "    df_sample = df.sample(fraction=0.033, seed=42)  # Random sampling 100k records\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Removing rows where 'price' is <= 0 (to avoid issues with log transformation)\n",
    "    df_sample = df_sample.filter(F.col(\"price\") > 0)\n",
    "\n",
    "    # Log transforming the target variable\n",
    "    df_sample = df_sample.withColumn(\"log_price\", log(\"price\"))\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Handling categorical columns\n",
    "    cat_columns = [field for (field, dtype) in df_sample.dtypes if dtype == \"string\"]\n",
    "    stages = []\n",
    "    for col_name in cat_columns:\n",
    "        indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_indexed\", handleInvalid=\"keep\")\n",
    "        encoder = OneHotEncoder(inputCol=f\"{col_name}_indexed\", outputCol=f\"{col_name}_encoded\")\n",
    "        stages += [indexer, encoder]\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Converting 'franchise_dealer' to numeric\n",
    "    df_sample = df_sample.withColumn(\"franchise_dealer\", F.col(\"franchise_dealer\").cast(\"int\"))\n",
    "\n",
    "    # Assembling features (ensure all columns used in 'VectorAssembler' are numeric)\n",
    "    num_columns = [col for col in df_sample.columns if col not in ['price', 'log_price'] + cat_columns]\n",
    "    encoded_columns = [f\"{col}_encoded\" for col in cat_columns]\n",
    "    feature_columns = num_columns + encoded_columns\n",
    "    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "    stages += [assembler]\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Adding scaling to the pipeline (to scale the assembled feature vectors)\n",
    "    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
    "    stages += [scaler]\n",
    "\n",
    "    # Creating and applying the pipeline\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    try:\n",
    "        pipeline_model = pipeline.fit(df_sample)\n",
    "        df_sample = pipeline_model.transform(df_sample)\n",
    "        pbar.update(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during pipeline fit: {e}\")\n",
    "        pbar.update(1)\n",
    "\n",
    "    # Splitting the data into training and test sets\n",
    "    train_df, test_df = df_sample.randomSplit([0.8, 0.2], seed=42)\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Defining the RandomForestRegressor model\n",
    "    rf = RandomForestRegressor(\n",
    "      featuresCol=\"scaled_features\",\n",
    "      labelCol=\"log_price\",\n",
    "      numTrees=50,\n",
    "      maxDepth=10,\n",
    "      minInstancesPerNode=10,\n",
    "      seed=42\n",
    "    )\n",
    "\n",
    "    # Fitting the model to the training data\n",
    "    try:\n",
    "        model = rf.fit(train_df)\n",
    "        pbar.update(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model training: {e}\")\n",
    "        pbar.update(1)\n",
    "\n",
    "# Making predictions\n",
    "print(\"Making predictions...\")\n",
    "try:\n",
    "    predictions = model.transform(test_df)\n",
    "    predictions = predictions.withColumn(\"exp_prediction\", F.exp(\"prediction\"))\n",
    "except Exception as e:\n",
    "    print(f\"Error during prediction: {e}\")\n",
    "\n",
    "# Evaluating the model\n",
    "print(\"Evaluating the model...\")\n",
    "try:\n",
    "    evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"exp_prediction\", metricName=\"r2\")\n",
    "    r2 = evaluator.evaluate(predictions)\n",
    "    print(f\"\\n\\nR-Squared Score (Accuracy): {r2 * 100:.2f}%\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during evaluation: {e}\")\n",
    "\n",
    "# Displaying results\n",
    "print(f\"\\n\\nTrain size: {train_df.count():,} samples\")\n",
    "print(f\"Test size: {test_df.count():,} samples\")\n",
    "\n",
    "# Calculating total runtime\n",
    "end_time = time.time()\n",
    "total_runtime = (end_time - start_time) / 60\n",
    "print(f\"\\nOverall runtime: {round(total_runtime)} minutes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 86339,
     "status": "ok",
     "timestamp": 1729588074412,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "NyYAbqVS4lui",
    "outputId": "1e154a28-01b1-48c5-c2c7-26c6beba2dcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Metrics:\n",
      "Mean Absolute Error: 3517\n",
      "Mean Squared Error: 88738726\n",
      "Root Mean Squared Error: 9420\n"
     ]
    }
   ],
   "source": [
    "# Calculating additional metrics\n",
    "mae_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"exp_prediction\", metricName=\"mae\")\n",
    "mae = mae_evaluator.evaluate(predictions)\n",
    "\n",
    "mse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"exp_prediction\", metricName=\"mse\")\n",
    "mse = mse_evaluator.evaluate(predictions)\n",
    "\n",
    "rmse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"exp_prediction\", metricName=\"rmse\")\n",
    "rmse = rmse_evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Additional Metrics:\")\n",
    "print(f\"Mean Absolute Error: {round(mae)}\")\n",
    "print(f\"Mean Squared Error: {round(mse)}\")\n",
    "print(f\"Root Mean Squared Error: {round(rmse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8dcym2IEKq0"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pp2xUjVzxo7w"
   },
   "source": [
    "# **Hyper parameter tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUF9z9JiFv5s"
   },
   "source": [
    "### **Hyperparameter Tuning**  [on the same subset used in the above cells = 100k Rows] :\n",
    "\n",
    "Once I established baseline metrics, I proceeded with hyperparameter tuning on the same subset. Training on 100k rows with different parameter combinations enabled me to evaluate the impact of various hyperparameters. This step was crucial to narrow down the most promising configurations and avoid overfitting due to excessive tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 518,
     "status": "ok",
     "timestamp": 1729719489100,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "mzWHhS80Ec0Z",
    "outputId": "419e6ed9-0b2c-455d-d753-5a3bba8f3f71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing and Training: 100%|██████████| 6/6 [00:08<00:00,  1.49s/it]\n",
      "\n",
      "Training Random Forest model with parameters: {'numTrees': 50, 'maxDepth': 10, 'minInstancesPerNode': 10}\n",
      "\n",
      "R-Squared Score (Accuracy): 75.71%\n",
      "Additional Metrics:\n",
      "Mean Absolute Error: 3504\n",
      "Mean Squared Error: 87085658\n",
      "Root Mean Squared Error: 9332\n",
      "----------------------------------------\n",
      "\n",
      "Training Random Forest model with parameters: {'numTrees': 50, 'maxDepth': 10, 'minInstancesPerNode': 20}\n",
      "\n",
      "R-Squared Score (Accuracy): 74.52%\n",
      "Additional Metrics:\n",
      "Mean Absolute Error: 3538\n",
      "Mean Squared Error: 91340987\n",
      "Root Mean Squared Error: 9557\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Training Random Forest model with parameters: {'numTrees': 50, 'maxDepth': 20, 'minInstancesPerNode': 10}\n",
      "\n",
      "R-Squared Score (Accuracy): 79.30%\n",
      "Additional Metrics:\n",
      "Mean Absolute Error: 2689\n",
      "Mean Squared Error: 74216693\n",
      "Root Mean Squared Error: 8615\n",
      "----------------------------------------\n",
      "\n",
      "Training Random Forest model with parameters: {'numTrees': 50, 'maxDepth': 20, 'minInstancesPerNode': 20}\n",
      "\n",
      "R-Squared Score (Accuracy): 78.00%\n",
      "Additional Metrics:\n",
      "Mean Absolute Error: 2831\n",
      "Mean Squared Error: 78867758\n",
      "Root Mean Squared Error: 8881\n",
      "----------------------------------------\n",
      "\n",
      "Training Random Forest model with parameters: {'numTrees': 100, 'maxDepth': 10, 'minInstancesPerNode': 10}\n",
      "\n",
      "R-Squared Score (Accuracy): 75.72%\n",
      "Additional Metrics:\n",
      "Mean Absolute Error: 3498\n",
      "Mean Squared Error: 87034740\n",
      "Root Mean Squared Error: 9329\n",
      "----------------------------------------\n",
      "\n",
      "Training Random Forest model with parameters: {'numTrees': 100, 'maxDepth': 10, 'minInstancesPerNode': 20}\n",
      "\n",
      "R-Squared Score (Accuracy): 74.75%\n",
      "Additional Metrics:\n",
      "Mean Absolute Error: 3527\n",
      "Mean Squared Error: 90509739\n",
      "Root Mean Squared Error: 9514\n",
      "----------------------------------------\n",
      "\n",
      "Training Random Forest model with parameters: {'numTrees': 100, 'maxDepth': 20, 'minInstancesPerNode': 10}\n",
      "\n",
      "R-Squared Score (Accuracy): 79.49%\n",
      "Additional Metrics:\n",
      "Mean Absolute Error: 2675\n",
      "Mean Squared Error: 73508433\n",
      "Root Mean Squared Error: 8574\n",
      "----------------------------------------\n",
      "\n",
      "Training Random Forest model with parameters: {'numTrees': 100, 'maxDepth': 20, 'minInstancesPerNode': 20}\n",
      "\n",
      "R-Squared Score (Accuracy): 77.87%\n",
      "Additional Metrics:\n",
      "Mean Absolute Error: 2820\n",
      "Mean Squared Error: 79318562\n",
      "Root Mean Squared Error: 8906\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Best R² (Accuracy): 79.49% with parameters: {'numTrees': 100, 'maxDepth': 20, 'minInstancesPerNode': 10}\n",
      "Best MAE: 2675.38 with parameters: {'numTrees': 100, 'maxDepth': 20, 'minInstancesPerNode': 10}\n",
      "Best RMSE: 8573.71 with parameters: {'numTrees': 100, 'maxDepth': 20, 'minInstancesPerNode': 10}\n",
      "\n",
      "Overall runtime: 1017 minutes.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "import time\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Start to track overall runtime\n",
    "start_time = time.time()\n",
    "\n",
    "with tqdm(total=6, desc=\"Processing and Training\") as pbar:\n",
    "    df_sample = df.sample(fraction=0.033, seed=42)  # Randomly sample 100k records of the data\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Remove rows where 'price' is <= 0 (to avoid issues with log transformation)\n",
    "    df_sample = df_sample.filter(F.col(\"price\") > 0)\n",
    "\n",
    "    # Log transforming the target variable\n",
    "    df_sample = df_sample.withColumn(\"log_price\", F.log(\"price\"))\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Handling categorical columns\n",
    "    cat_columns = [field for (field, dtype) in df_sample.dtypes if dtype == \"string\"]\n",
    "    stages = []\n",
    "    for col_name in cat_columns:\n",
    "        indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_indexed\", handleInvalid=\"keep\")\n",
    "        encoder = OneHotEncoder(inputCol=f\"{col_name}_indexed\", outputCol=f\"{col_name}_encoded\")\n",
    "        stages += [indexer, encoder]\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Converting 'franchise_dealer' to numeric\n",
    "    df_sample = df_sample.withColumn(\"franchise_dealer\", F.col(\"franchise_dealer\").cast(\"int\"))\n",
    "\n",
    "    # Assembling features\n",
    "    num_columns = [col for col in df_sample.columns if col not in ['price', 'log_price'] + cat_columns]\n",
    "    encoded_columns = [f\"{col}_encoded\" for col in cat_columns]\n",
    "    feature_columns = num_columns + encoded_columns\n",
    "    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "    stages += [assembler]\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Adding scaling to the pipeline\n",
    "    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
    "    stages += [scaler]\n",
    "\n",
    "    # Creating and applying the pipeline\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    pipeline_model = pipeline.fit(df_sample)\n",
    "    df_sample = pipeline_model.transform(df_sample)\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Splitting the data into training and test sets\n",
    "    train_df, test_df = df_sample.randomSplit([0.8, 0.2], seed=42)\n",
    "    pbar.update(1)\n",
    "\n",
    "# Defining hyperparameters for Random Forest\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(RandomForestRegressor.numTrees, [50, 100]) \\\n",
    "    .addGrid(RandomForestRegressor.maxDepth, [10,20]) \\\n",
    "    .addGrid(RandomForestRegressor.minInstancesPerNode, [10,20]) \\\n",
    "    .build()\n",
    "\n",
    "# Initializing best scores and parameters\n",
    "best_r2 = -float(\"inf\")\n",
    "best_mae = float(\"inf\")\n",
    "best_rmse = float(\"inf\")\n",
    "best_params_r2 = None\n",
    "best_params_mae = None\n",
    "best_params_rmse = None\n",
    "\n",
    "# Manually iterating over each parameter combination and evaluate metrics\n",
    "for params in param_grid:\n",
    "\n",
    "    # Extracting the parameter names and values\n",
    "    param_values = {param.name: value for param, value in params.items()}\n",
    "\n",
    "    print(f\"\\nTraining Random Forest model with parameters: {param_values}\")\n",
    "\n",
    "    # Defining the RandomForestRegressor model with the current hyperparameters\n",
    "    rf = RandomForestRegressor(\n",
    "        featuresCol=\"scaled_features\",\n",
    "        labelCol=\"log_price\",\n",
    "        **param_values\n",
    "    )\n",
    "\n",
    "    # Fitting the model to the training data\n",
    "    try:\n",
    "        model = rf.fit(train_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model training: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Making predictions\n",
    "    try:\n",
    "        predictions = model.transform(test_df)\n",
    "        predictions = predictions.withColumn(\"exp_prediction\", F.exp(\"prediction\"))\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Evaluating the model\n",
    "    try:\n",
    "        evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"exp_prediction\", metricName=\"r2\")\n",
    "        r2 = evaluator.evaluate(predictions)\n",
    "        print(f\"\\n\\nR-Squared Score (Accuracy): {r2 * 100:.2f}%\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during evaluation: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Calculating additional metrics\n",
    "    mae_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"exp_prediction\", metricName=\"mae\")\n",
    "    mae = mae_evaluator.evaluate(predictions)\n",
    "\n",
    "    mse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"exp_prediction\", metricName=\"mse\")\n",
    "    mse = mse_evaluator.evaluate(predictions)\n",
    "\n",
    "    rmse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"exp_prediction\", metricName=\"rmse\")\n",
    "    rmse = rmse_evaluator.evaluate(predictions)\n",
    "\n",
    "    print(\"Additional Metrics:\")\n",
    "    print(f\"Mean Absolute Error: {round(mae)}\")\n",
    "    print(f\"Mean Squared Error: {round(mse)}\")\n",
    "    print(f\"Root Mean Squared Error: {round(rmse)}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # Tracking the best scores and corresponding parameters\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_params_r2 = param_values\n",
    "\n",
    "    if mae < best_mae:\n",
    "        best_mae = mae\n",
    "        best_params_mae = param_values\n",
    "\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_params_rmse = param_values\n",
    "\n",
    "# Printing the best model and its corresponding parameters\n",
    "print(f\"\\nBest R² (Accuracy): {best_r2 * 100:.2f}% with parameters: {best_params_r2}\")\n",
    "print(f\"Best MAE: {best_mae:.2f} with parameters: {best_params_mae}\")\n",
    "print(f\"Best RMSE: {best_rmse:.2f} with parameters: {best_params_rmse}\")\n",
    "\n",
    "# Calculating total runtime\n",
    "end_time = time.time()\n",
    "total_runtime = (end_time - start_time) / 60\n",
    "print(f\"\\nOverall runtime: {round(total_runtime)} minutes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68Bu5GWo9bmj"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yprigAOr87cv"
   },
   "source": [
    "\n",
    "## **Summary of HPT on 100k rows**\n",
    "\n",
    "I experimented with various configurations of the Random Forest model to identify the best-performing parameters. The parameters tested included `numTrees` (50 and 100), `maxDepth` (10 and 20), and `minInstancesPerNode` (10 and 20).\n",
    "\n",
    "**Best Configuration and Performance:**\n",
    "- **Best Parameters:** `numTrees` = 100, `maxDepth` = 20, `minInstancesPerNode` = 10\n",
    "- **Best R² Score (Accuracy):** 79.49%\n",
    "- **Best MAE:** 2675\n",
    "- **Best RMSE:** 8574\n",
    "\n",
    "**Comparison to Baseline:**\n",
    "The baseline model, with an R² of 75.25%, used simpler parameters. By optimizing the parameters, I achieved a `4.24% increase in R²`, improving the model's accuracy from 75.25% to 79.49%. Additionally, `error metrics were reduced significantly`, with MAE dropping from 3517 to 2675 and RMSE from 9420 to 8574."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSdGwPXUSjta"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlvnFLzPSnFA"
   },
   "source": [
    "# **Running with Best Parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDb-GAW4GYCw"
   },
   "source": [
    "### **Scaling Up with Optimized Parameters (600k Rows):**\n",
    "Once the best parameters were identified, I applied them to the full 600k-row dataset to test scalability. This step allowed me to verify performance improvements and confirm the effectiveness of the chosen parameters on the final, larger dataset.\n",
    "\n",
    "**Best Parameters:** `numTrees` = 100, `maxDepth` = 20, `minInstancesPerNode` = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCU1X_VGSufO"
   },
   "source": [
    "## **600k records**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1729909698708,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "dLQ2bRjmSlUm",
    "outputId": "2a14dffd-f3f3-4773-c3e0-a212c4f3da0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing and Training: 100%|██████████| 7/7 [8:22:00<00:00, 4302.89s/it]\n",
      "Making predictions...\n",
      "Evaluating the model...\n",
      "\n",
      "\n",
      "R-Squared Score (Accuracy): 87.92%\n",
      "\n",
      "Train size: 480,411 samples\n",
      "Test size: 120,366 samples\n",
      "\n",
      "Overall runtime: 1134 minutes.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, OneHotEncoder, Imputer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.sql.functions import mean as sql_mean, log\n",
    "import pyspark.sql.functions as F\n",
    "import time  # To measure overall runtime\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Start tracking overall runtime\n",
    "start_time = time.time()\n",
    "\n",
    "with tqdm(total=7, desc=\"Processing and Training\") as pbar:\n",
    "\n",
    "    df_sample = df.sample(fraction=0.2, seed=42)  # Randomly sample 100k records\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Removing rows where 'price' is <= 0 (to avoid issues with log transformation)\n",
    "    df_sample = df_sample.filter(F.col(\"price\") > 0)\n",
    "\n",
    "    # Log transforming the target variable\n",
    "    df_sample = df_sample.withColumn(\"log_price\", log(\"price\"))\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Handling categorical columns\n",
    "    cat_columns = [field for (field, dtype) in df_sample.dtypes if dtype == \"string\"]\n",
    "    stages = []\n",
    "    for col_name in cat_columns:\n",
    "        indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_indexed\", handleInvalid=\"keep\")\n",
    "        encoder = OneHotEncoder(inputCol=f\"{col_name}_indexed\", outputCol=f\"{col_name}_encoded\")\n",
    "        stages += [indexer, encoder]\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Converting 'franchise_dealer' to numeric\n",
    "    df_sample = df_sample.withColumn(\"franchise_dealer\", F.col(\"franchise_dealer\").cast(\"int\"))\n",
    "\n",
    "    # Assembling features (to ensure all columns used in 'VectorAssembler' are numeric)\n",
    "    num_columns = [col for col in df_sample.columns if col not in ['price', 'log_price'] + cat_columns]\n",
    "    encoded_columns = [f\"{col}_encoded\" for col in cat_columns]\n",
    "    feature_columns = num_columns + encoded_columns\n",
    "    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "    stages += [assembler]\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Adding scaling to the pipeline (scale the assembled feature vectors)\n",
    "    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
    "    stages += [scaler]\n",
    "\n",
    "    # Creating and applying the pipeline\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    try:\n",
    "        pipeline_model = pipeline.fit(df_sample)\n",
    "        df_sample = pipeline_model.transform(df_sample)\n",
    "        pbar.update(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during pipeline fit: {e}\")\n",
    "        pbar.update(1)\n",
    "\n",
    "    # Splitting the data into training and test sets\n",
    "    train_df, test_df = df_sample.randomSplit([0.8, 0.2], seed=42)\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Defining the RandomForestRegressor model\n",
    "    rf = RandomForestRegressor(\n",
    "      featuresCol=\"scaled_features\",\n",
    "      labelCol=\"log_price\",\n",
    "      numTrees=100,\n",
    "      maxDepth=20,\n",
    "      minInstancesPerNode=10,\n",
    "      seed=42\n",
    "    )\n",
    "\n",
    "    # Fitting the model to the training data\n",
    "    try:\n",
    "        model = rf.fit(train_df)\n",
    "        pbar.update(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model training: {e}\")\n",
    "        pbar.update(1)\n",
    "\n",
    "# Making predictions\n",
    "print(\"Making predictions...\")\n",
    "try:\n",
    "    predictions = model.transform(test_df)\n",
    "    predictions = predictions.withColumn(\"exp_prediction\", F.exp(\"prediction\"))\n",
    "except Exception as e:\n",
    "    print(f\"Error during prediction: {e}\")\n",
    "\n",
    "# Evaluating the model\n",
    "print(\"Evaluating the model...\")\n",
    "try:\n",
    "    evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"exp_prediction\", metricName=\"r2\")\n",
    "    r2 = evaluator.evaluate(predictions)\n",
    "    print(f\"\\n\\nR-Squared Score (Accuracy): {r2 * 100:.2f}%\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during evaluation: {e}\")\n",
    "\n",
    "# Displaying the results\n",
    "print(f\"\\n\\nTrain size: {train_df.count():,} samples\")\n",
    "print(f\"Test size: {test_df.count():,} samples\")\n",
    "\n",
    "# Calculate total runtime\n",
    "end_time = time.time()\n",
    "total_runtime = (end_time - start_time) / 60\n",
    "print(f\"\\nOverall runtime: {round(total_runtime)} minutes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 324,
     "status": "ok",
     "timestamp": 1729910003758,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "YTILyFWwUhfs",
    "outputId": "e83b37d3-a764-4b0c-a928-dae2fd9afefa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Metrics:\n",
      "Mean Absolute Error: 3442\n",
      "Mean Squared Error: 44980420\n",
      "Root Mean Squared Error: 6543\n"
     ]
    }
   ],
   "source": [
    "# Calculating additional metrics\n",
    "mae_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"exp_prediction\", metricName=\"mae\")\n",
    "mae = mae_evaluator.evaluate(predictions)\n",
    "\n",
    "mse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"exp_prediction\", metricName=\"mse\")\n",
    "mse = mse_evaluator.evaluate(predictions)\n",
    "\n",
    "rmse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"exp_prediction\", metricName=\"rmse\")\n",
    "rmse = rmse_evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Additional Metrics:\")\n",
    "print(f\"Mean Absolute Error: {round(mae)}\")\n",
    "print(f\"Mean Squared Error: {round(mse)}\")\n",
    "print(f\"Root Mean Squared Error: {round(rmse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehE49dKtw3ju"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqY3nsROY9Pm"
   },
   "source": [
    "## **Comparison before and after training with `Best Hyper Parameters`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8cWPgnqY_U6"
   },
   "source": [
    "### <font color='orange'>**Before**</font>\n",
    "**Old parameters:** `{'numTrees': 50, 'maxDepth': 10, 'minInstancesPerNode': 10}`\n",
    "<br></br>\n",
    "R-Squared Score (Accuracy): ***86.35 %***\n",
    "<br></br>\n",
    "**Additional Metrics:**\n",
    "\n",
    "Mean Absolute Error: 3488\n",
    "\n",
    "Root Mean Squared Error: 6707\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AfXbsAlZAiF"
   },
   "source": [
    "### <font color='yellow'>**After**</font>\n",
    "**Best parameters:** `{'numTrees': 100, 'maxDepth': 20, 'minInstancesPerNode': 10}`\n",
    "<br></br>\n",
    "R-Squared Score (Accuracy): ***87.92%***\n",
    "<br></br>\n",
    "**Additional Metrics:**\n",
    "\n",
    "Mean Absolute Error: 3442\n",
    "\n",
    "Root Mean Squared Error: 6543"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1wDZZHSEh19oiycPxgDhUntGO56Gpnhx1",
     "timestamp": 1727142835432
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfgrtYKqE5dQ"
   },
   "source": [
    "## **In this notebook (GBT Regressor)**\n",
    "I followed a step-by-step process to train and tune each model efficiently. First, I created a baseline model using a 100k-row subset with basic parameters, giving me a reference point to measure how hyperparameter tuning impacted performance. Next, I experimented with different parameter settings on this 100k subset to identify the best configurations. Once I had the optimal parameters, I scaled up to the full 600k-row dataset to test how well these settings performed on a larger scale.\n",
    "<br>\n",
    "\n",
    "This approach was necessary because a single run of `GBT Regressor` was taking around 11 hours, making it impractical to tune all 8 parameters directly on the full dataset. By downsizing hyperparameter tuning to 100k rows, I could find the best parameters and then apply them to 600k rows for final testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29796,
     "status": "ok",
     "timestamp": 1729720088242,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "Y4sx5FAzCLlV",
    "outputId": "bc1f05f5-c5f0-41c5-ef9f-f0eae77ddaf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tqdm is already installed.\n",
      "\n",
      "pyspark is NOT installed. Installing now...\n",
      "pyspark installation completed.\n",
      "\n",
      "gdown is already installed.\n",
      "\n",
      "numpy is already installed.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import subprocess\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "def check_and_install_package(package_name, version=None):\n",
    "    try:\n",
    "        importlib.import_module(package_name)\n",
    "        print(f\"\\n{package_name} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"\\n{package_name} is NOT installed. Installing now...\")\n",
    "        if version:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", f\"{package_name}=={version}\"])\n",
    "        else:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
    "        print(f\"{package_name} installation completed.\")\n",
    "\n",
    "# List of packages to check along with specific versions if necessary\n",
    "packages = [\n",
    "    {\"name\": \"tqdm\", \"version\": None},\n",
    "    {\"name\": \"pyspark\", \"version\": \"3.5.2\"},\n",
    "    {\"name\": \"gdown\", \"version\": None},\n",
    "    {\"name\": \"numpy\", \"version\": \"1.23.5\"}\n",
    "]\n",
    "\n",
    "# Checking and installing the packages\n",
    "for package in packages:\n",
    "    check_and_install_package(package[\"name\"], package[\"version\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38104,
     "status": "ok",
     "timestamp": 1729720140662,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "1qHiZs8DBCtb",
    "outputId": "5c7d6aa0-1da0-41db-cbfc-0053a6996c0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4648,
     "status": "ok",
     "timestamp": 1729720150171,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "hkf0ch56Jqvg",
    "outputId": "c1ba324c-94bb-4aea-b891-132f66a62035"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session started with version: 3.5.2\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Defining the path to the copied jar files in the local instance\n",
    "jar_files = \"/resources/xgboost4j_2.12-1.7.6.jar,/resources/xgboost4j-spark_2.12-1.7.6.jar\"\n",
    "\n",
    "# Set the environment variable to include the JARs from the local instance\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"GBTModel\") \\\n",
    "    .config(\"spark.driver.memory\", \"16g\") \\\n",
    "    .config(\"spark.executor.memory\", \"16g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"8g\") \\\n",
    "    .config(\"spark.executor.memoryOverhead\", \"12g\") \\\n",
    "    .config(\"spark.executor.cores\", \"5\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2047m\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.file.impl\", \"org.apache.hadoop.fs.LocalFileSystem\") \\\n",
    "    .config(\"spark.executor.extraJavaOptions\", \"-XX:+UseG1GC -XX:InitiatingHeapOccupancyPercent=35 -XX:ConcGCThreads=4 -XX:ParallelGCThreads=4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Verifying Spark session creation\n",
    "print(f\"Spark session started with version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11331,
     "status": "ok",
     "timestamp": 1729720163425,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "ffdRgs1p5J8s",
    "outputId": "250ada46-a8a7-4c6d-ff05-e40fe28e3b94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Feature Engineered DataFrame has been loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "!cp '/content/drive/MyDrive/Big Data Analytics - Project/Datasets/Feature_Engineered_DF.parquet' /content/\n",
    "\n",
    "output_path = '/content/Feature_Engineered_DF.parquet'\n",
    "df = spark.read.parquet(output_path)\n",
    "print(\"The Feature Engineered DataFrame has been loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 479,
     "status": "ok",
     "timestamp": 1729720163886,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "gdr4vpKq5-Ch",
    "outputId": "898e7309-5018-4ead-f951-166f6edc0658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the loaded DataFrame is: (3000040, 47)\n"
     ]
    }
   ],
   "source": [
    "# Printing the shape of the DataFrame\n",
    "total_rows = df.count()\n",
    "total_columns = len(df.columns)\n",
    "\n",
    "print(f\"The shape of the loaded DataFrame is: ({total_rows}, {total_columns})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1729720163888,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "V-w-DYTK6F9s",
    "outputId": "04a015e4-4750-4a7f-a30e-879c1ee913dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average price of a car: 29933\n"
     ]
    }
   ],
   "source": [
    "# Calculating the average price\n",
    "avg_price = df.agg({\"price\": \"avg\"}).collect()[0][0]\n",
    "print(f\"Average price of a car: {round(avg_price)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "executionInfo": {
     "elapsed": 9325,
     "status": "ok",
     "timestamp": 1729720173196,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "SwSGhH_x6MJZ",
    "outputId": "16587b3c-9360-4a14-ec3b-03a694daec7e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "pandas_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-39cfd640-352b-4a1e-85c0-adac708c2626\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>body_type</th>\n",
       "      <th>city</th>\n",
       "      <th>city_fuel_economy</th>\n",
       "      <th>days_in_market</th>\n",
       "      <th>dealer_zip</th>\n",
       "      <th>engine_displacement</th>\n",
       "      <th>engine_type</th>\n",
       "      <th>exterior_color</th>\n",
       "      <th>franchise_dealer</th>\n",
       "      <th>fuel_tank_volume</th>\n",
       "      <th>height</th>\n",
       "      <th>highway_fuel_economy</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>interior_color</th>\n",
       "      <th>is_new</th>\n",
       "      <th>latitude</th>\n",
       "      <th>length</th>\n",
       "      <th>listing_color</th>\n",
       "      <th>longitude</th>\n",
       "      <th>make_name</th>\n",
       "      <th>maximum_seating</th>\n",
       "      <th>model_name</th>\n",
       "      <th>price</th>\n",
       "      <th>savings_amount</th>\n",
       "      <th>seller_rating</th>\n",
       "      <th>sp_name</th>\n",
       "      <th>torque</th>\n",
       "      <th>transmission</th>\n",
       "      <th>transmission_display</th>\n",
       "      <th>wheel_system_display</th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>width</th>\n",
       "      <th>manufactured_year</th>\n",
       "      <th>combined_fuel_economy</th>\n",
       "      <th>legroom</th>\n",
       "      <th>log_mileage</th>\n",
       "      <th>major_options_count</th>\n",
       "      <th>hp_x_engine_disp</th>\n",
       "      <th>hp_x_torque</th>\n",
       "      <th>listed_day</th>\n",
       "      <th>listed_month</th>\n",
       "      <th>listed_year</th>\n",
       "      <th>age</th>\n",
       "      <th>resale_value_score</th>\n",
       "      <th>maintenance_cost</th>\n",
       "      <th>luxury_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gasoline</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36</td>\n",
       "      <td>78249</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>I4</td>\n",
       "      <td>Other</td>\n",
       "      <td>True</td>\n",
       "      <td>12.4</td>\n",
       "      <td>55.7</td>\n",
       "      <td>40.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>Gray</td>\n",
       "      <td>False</td>\n",
       "      <td>29.580200</td>\n",
       "      <td>182.3</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>-98.597298</td>\n",
       "      <td>Honda</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Civic</td>\n",
       "      <td>16600.0</td>\n",
       "      <td>138</td>\n",
       "      <td>4.280000</td>\n",
       "      <td>Gunn Honda</td>\n",
       "      <td>138.00</td>\n",
       "      <td>CVT</td>\n",
       "      <td>Continuously Variable Transmission</td>\n",
       "      <td>Front-Wheel Drive</td>\n",
       "      <td>106.3</td>\n",
       "      <td>70.8</td>\n",
       "      <td>2017</td>\n",
       "      <td>35.5</td>\n",
       "      <td>79.7</td>\n",
       "      <td>10.08</td>\n",
       "      <td>3</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.19255</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gasoline</td>\n",
       "      <td>SUV / Crossover</td>\n",
       "      <td>Midvale</td>\n",
       "      <td>16.0</td>\n",
       "      <td>46</td>\n",
       "      <td>84047</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>V6</td>\n",
       "      <td>Black</td>\n",
       "      <td>False</td>\n",
       "      <td>21.0</td>\n",
       "      <td>68.2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>Black</td>\n",
       "      <td>False</td>\n",
       "      <td>40.599899</td>\n",
       "      <td>191.6</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>-111.890999</td>\n",
       "      <td>Acura</td>\n",
       "      <td>7.0</td>\n",
       "      <td>MDX</td>\n",
       "      <td>11995.0</td>\n",
       "      <td>1217</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>America Auto Group</td>\n",
       "      <td>270.00</td>\n",
       "      <td>A</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>All-Wheel Drive</td>\n",
       "      <td>108.3</td>\n",
       "      <td>78.5</td>\n",
       "      <td>2012</td>\n",
       "      <td>18.5</td>\n",
       "      <td>79.9</td>\n",
       "      <td>11.76</td>\n",
       "      <td>7</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.02622</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gasoline</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Tallahassee</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>32308</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>I4</td>\n",
       "      <td>Red</td>\n",
       "      <td>False</td>\n",
       "      <td>13.2</td>\n",
       "      <td>57.3</td>\n",
       "      <td>36.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>Black</td>\n",
       "      <td>False</td>\n",
       "      <td>30.476999</td>\n",
       "      <td>183.1</td>\n",
       "      <td>RED</td>\n",
       "      <td>-84.236397</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Corolla</td>\n",
       "      <td>15688.0</td>\n",
       "      <td>1986</td>\n",
       "      <td>4.692307</td>\n",
       "      <td>David Lloyd Tallahassee</td>\n",
       "      <td>128.00</td>\n",
       "      <td>A</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Front-Wheel Drive</td>\n",
       "      <td>106.3</td>\n",
       "      <td>69.9</td>\n",
       "      <td>2017</td>\n",
       "      <td>32.0</td>\n",
       "      <td>83.7</td>\n",
       "      <td>10.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.65957</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gasoline</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Staunton</td>\n",
       "      <td>24.0</td>\n",
       "      <td>49</td>\n",
       "      <td>24401</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>I4</td>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>13.2</td>\n",
       "      <td>57.8</td>\n",
       "      <td>32.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>38.117901</td>\n",
       "      <td>168.0</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>-79.068199</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>5.0</td>\n",
       "      <td>GTI</td>\n",
       "      <td>34475.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>Valley Volkswagen</td>\n",
       "      <td>258.00</td>\n",
       "      <td>Dual Clutch</td>\n",
       "      <td>7-Speed Dual Clutch</td>\n",
       "      <td>Front-Wheel Drive</td>\n",
       "      <td>103.6</td>\n",
       "      <td>70.8</td>\n",
       "      <td>2020</td>\n",
       "      <td>28.0</td>\n",
       "      <td>76.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.01480</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hybrid</td>\n",
       "      <td>SUV / Crossover</td>\n",
       "      <td>Columbia</td>\n",
       "      <td>43.0</td>\n",
       "      <td>54</td>\n",
       "      <td>65203</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>I4</td>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>14.2</td>\n",
       "      <td>68.6</td>\n",
       "      <td>37.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>38.960800</td>\n",
       "      <td>180.5</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>-92.367599</td>\n",
       "      <td>Ford</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Escape Hybrid</td>\n",
       "      <td>30805.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.260870</td>\n",
       "      <td>Joe Machens Ford Lincoln</td>\n",
       "      <td>265.22</td>\n",
       "      <td>CVT</td>\n",
       "      <td>Continuously Variable Transmission</td>\n",
       "      <td>All-Wheel Drive</td>\n",
       "      <td>106.7</td>\n",
       "      <td>85.6</td>\n",
       "      <td>2020</td>\n",
       "      <td>40.0</td>\n",
       "      <td>81.2</td>\n",
       "      <td>8.91</td>\n",
       "      <td>9</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39cfd640-352b-4a1e-85c0-adac708c2626')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-39cfd640-352b-4a1e-85c0-adac708c2626 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-39cfd640-352b-4a1e-85c0-adac708c2626');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-7043b488-40a0-4742-baba-61670085b322\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7043b488-40a0-4742-baba-61670085b322')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-7043b488-40a0-4742-baba-61670085b322 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_c96c9673-aa8a-43bf-a465-58bdec11139a\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pandas_df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_c96c9673-aa8a-43bf-a465-58bdec11139a button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('pandas_df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "  fuel_type        body_type         city  city_fuel_economy  days_in_market  \\\n",
       "0  Gasoline            Sedan  San Antonio               31.0              36   \n",
       "1  Gasoline  SUV / Crossover      Midvale               16.0              46   \n",
       "2  Gasoline            Sedan  Tallahassee               28.0               1   \n",
       "3  Gasoline        Hatchback     Staunton               24.0              49   \n",
       "4    Hybrid  SUV / Crossover     Columbia               43.0              54   \n",
       "\n",
       "  dealer_zip  engine_displacement engine_type exterior_color  \\\n",
       "0      78249               2000.0          I4          Other   \n",
       "1      84047               3700.0          V6          Black   \n",
       "2      32308               1800.0          I4            Red   \n",
       "3      24401               2000.0          I4          Black   \n",
       "4      65203               2500.0          I4          Black   \n",
       "\n",
       "   franchise_dealer  fuel_tank_volume  height  highway_fuel_economy  \\\n",
       "0              True              12.4    55.7                  40.0   \n",
       "1             False              21.0    68.2                  21.0   \n",
       "2             False              13.2    57.3                  36.0   \n",
       "3              True              13.2    57.8                  32.0   \n",
       "4              True              14.2    68.6                  37.0   \n",
       "\n",
       "   horsepower interior_color  is_new   latitude  length listing_color  \\\n",
       "0       158.0           Gray   False  29.580200   182.3       UNKNOWN   \n",
       "1       300.0          Black   False  40.599899   191.6         BLACK   \n",
       "2       132.0          Black   False  30.476999   183.1           RED   \n",
       "3       228.0          Black    True  38.117901   168.0         BLACK   \n",
       "4       198.0          Black    True  38.960800   180.5         BLACK   \n",
       "\n",
       "    longitude   make_name  maximum_seating     model_name    price  \\\n",
       "0  -98.597298       Honda              5.0          Civic  16600.0   \n",
       "1 -111.890999       Acura              7.0            MDX  11995.0   \n",
       "2  -84.236397      Toyota              5.0        Corolla  15688.0   \n",
       "3  -79.068199  Volkswagen              5.0            GTI  34475.0   \n",
       "4  -92.367599        Ford              5.0  Escape Hybrid  30805.0   \n",
       "\n",
       "   savings_amount  seller_rating                   sp_name  torque  \\\n",
       "0             138       4.280000                Gunn Honda  138.00   \n",
       "1            1217       4.428571        America Auto Group  270.00   \n",
       "2            1986       4.692307   David Lloyd Tallahassee  128.00   \n",
       "3               0       5.000000         Valley Volkswagen  258.00   \n",
       "4               0       4.260870  Joe Machens Ford Lincoln  265.22   \n",
       "\n",
       "  transmission                transmission_display wheel_system_display  \\\n",
       "0          CVT  Continuously Variable Transmission    Front-Wheel Drive   \n",
       "1            A                           Automatic      All-Wheel Drive   \n",
       "2            A                           Automatic    Front-Wheel Drive   \n",
       "3  Dual Clutch                 7-Speed Dual Clutch    Front-Wheel Drive   \n",
       "4          CVT  Continuously Variable Transmission      All-Wheel Drive   \n",
       "\n",
       "   wheelbase  width  manufactured_year  combined_fuel_economy  legroom  \\\n",
       "0      106.3   70.8               2017                   35.5     79.7   \n",
       "1      108.3   78.5               2012                   18.5     79.9   \n",
       "2      106.3   69.9               2017                   32.0     83.7   \n",
       "3      103.6   70.8               2020                   28.0     76.8   \n",
       "4      106.7   85.6               2020                   40.0     81.2   \n",
       "\n",
       "   log_mileage  major_options_count  hp_x_engine_disp  hp_x_torque  \\\n",
       "0        10.08                    3              0.73      1.19255   \n",
       "1        11.76                    7              0.34      0.02622   \n",
       "2        10.62                    0              1.14      1.65957   \n",
       "3         0.00                    3              0.16      0.01480   \n",
       "4         8.91                    9              0.19     -0.00001   \n",
       "\n",
       "   listed_day  listed_month  listed_year  age  resale_value_score  \\\n",
       "0           6             8         2020    3                  21   \n",
       "1          27             7         2020    8                  17   \n",
       "2           9             9         2020    3                  26   \n",
       "3          23             7         2020    0                  30   \n",
       "4          19             7         2020    0                  26   \n",
       "\n",
       "   maintenance_cost  luxury_score  \n",
       "0                34            28  \n",
       "1                35            33  \n",
       "2                30            28  \n",
       "3                42            30  \n",
       "4                43            34  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Converting the Spark DataFrame to a Pandas DataFrame and displaying 5 random rows with all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pandas_df = df.orderBy(F.rand()).limit(5).toPandas()\n",
    "display(pandas_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ak-ZUPijzUGG"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OQoi0SfGyzI"
   },
   "source": [
    "# **GBT Regressor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2WktPxgG4PY"
   },
   "source": [
    "### **Initial Training on a Subset (100k Rows):**\n",
    "\n",
    "I begin by training GBT Regressor on a subset of 100k rows with specific parameters, establishing a baseline model. This baseline serves as a comparison point, allowing me to evaluate how each hyperparameter tuning experiment impacts performance, either increasing or decreasing metrics relative to the baseline. The initial 100k subset is thus used specifically for benchmarking improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19169,
     "status": "ok",
     "timestamp": 1729582812977,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "XowYTouCZ0Al",
    "outputId": "63568637-ada9-460f-aa1d-63559583f051"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 5/5 [00:18<00:00,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Data preprocessing and splitting completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import mean as sql_mean\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Processing the data...\")\n",
    "with tqdm(total=5, desc=\"Progress\") as pbar:\n",
    "\n",
    "    df_sample = df.sample(fraction=0.033, seed=42)  # Randomly sample 100k records of the data\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Handling categorical columns\n",
    "    cat_columns = [field for (field, dtype) in df_sample.dtypes if dtype == \"string\"]\n",
    "    stages = []\n",
    "    for col_name in cat_columns:\n",
    "        indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_indexed\", handleInvalid=\"keep\")\n",
    "        encoder = OneHotEncoder(inputCol=f\"{col_name}_indexed\", outputCol=f\"{col_name}_encoded\")\n",
    "        stages += [indexer, encoder]\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Assembling features\n",
    "    num_columns = [col for col in df_sample.columns if col != 'price' and col not in cat_columns]\n",
    "    encoded_columns = [f\"{col}_encoded\" for col in cat_columns]\n",
    "    feature_columns = num_columns + encoded_columns\n",
    "    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "    stages += [assembler]\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Adding scaling to the pipeline\n",
    "    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
    "    stages += [scaler]\n",
    "\n",
    "    # Creating and applying the pipeline\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    pipeline_model = pipeline.fit(df_sample)\n",
    "    df_sample = pipeline_model.transform(df_sample)\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Splitting the data\n",
    "    train_df, test_df = df_sample.randomSplit([0.8, 0.2], seed=42)\n",
    "    pbar.update(1)\n",
    "\n",
    "print(\"\\n\\nData preprocessing and splitting completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10880917,
     "status": "ok",
     "timestamp": 1729593703544,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "FlcjbW5tZ4aN",
    "outputId": "0ee2d31f-10f5-4bd9-d9f7-d9913e4c6472"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GBTRegressor model...\n",
      "Making predictions...\n",
      "Evaluating the model...\n",
      "\n",
      "Train size: 79,346 samples\n",
      "Test size: 19,771 samples\n",
      "\n",
      "\n",
      "R-Squared Score (Accuracy): 78.56%\n",
      "\n",
      "\n",
      "Overall runtime: 181 minutes.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import time\n",
    "\n",
    "# Starting to track overall run time\n",
    "start_time = time.time()\n",
    "\n",
    "# Model training\n",
    "print(\"Training GBTRegressor model...\")\n",
    "\n",
    "\n",
    "# Using GBTRegressor with tuned parameters\n",
    "gbt_regressor = GBTRegressor(\n",
    "    featuresCol=\"scaled_features\",\n",
    "    labelCol=\"price\",\n",
    "    maxIter=100,\n",
    "    maxDepth=5,\n",
    "    seed=42,\n",
    "  # parallelism=4\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "model = gbt_regressor.fit(train_df)\n",
    "\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "# Making predictions\n",
    "print(\"Making predictions...\")\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "# Evaluating the model\n",
    "print(\"Evaluating the model...\")\n",
    "evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"\\nTrain size: {train_df.count():,} samples\")\n",
    "print(f\"Test size: {test_df.count():,} samples\")\n",
    "\n",
    "print(f\"\\n\\nR-Squared Score (Accuracy): {r2 * 100:.2f}%\")\n",
    "\n",
    "# Calculating total runtime\n",
    "end_time = time.time()\n",
    "total_runtime = (end_time - start_time) / 60\n",
    "print(f\"\\n\\nOverall runtime: {round(total_runtime)} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 142751,
     "status": "ok",
     "timestamp": 1729593846292,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "-AKAGgNwuTkb",
    "outputId": "144d9321-ed16-4f85-bcf1-0666334b7210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Metrics:\n",
      "Mean Absolute Error: 3604\n",
      "Mean Squared Error: 76868028\n",
      "Root Mean Squared Error: 8767\n"
     ]
    }
   ],
   "source": [
    "# Calculating additional metrics\n",
    "mae_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae = mae_evaluator.evaluate(predictions)\n",
    "\n",
    "mse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mse = mse_evaluator.evaluate(predictions)\n",
    "\n",
    "rmse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = rmse_evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Additional Metrics:\")\n",
    "print(f\"Mean Absolute Error: {round(mae)}\")\n",
    "print(f\"Mean Squared Error: {round(mse)}\")\n",
    "print(f\"Root Mean Squared Error: {round(rmse)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QqaddjxrDXU3"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVUYS-UmHKG-"
   },
   "source": [
    "# **Hyper Parameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnQTonG4HMia"
   },
   "source": [
    "### **Hyperparameter Tuning**  [on the same subset used in the above cells = 100k Rows] :\n",
    "\n",
    "Once I established baseline metrics, I proceeded with hyperparameter tuning on the same subset. Training on 100k rows with different parameter combinations enabled me to evaluate the impact of various hyperparameters. This step was crucial to narrow down the most promising configurations and avoid overfitting due to excessive tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49040146,
     "status": "ok",
     "timestamp": 1729697036413,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "jnefEqKhDYk9",
    "outputId": "e251e350-5868-41c2-8b0c-44d971285121"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 5/5 [00:17<00:00,  3.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Data preprocessing and splitting completed!\n",
      "\n",
      "Training model with parameters: {'maxIter': 50, 'maxDepth': 5}\n",
      "R² (Accuracy): 75.68%\n",
      "MAE: 4137.68\n",
      "RMSE: 9336.50\n",
      "----------------------------------------\n",
      "\n",
      "Training model with parameters: {'maxIter': 50, 'maxDepth': 10}\n",
      "R² (Accuracy): 77.32%\n",
      "MAE: 3131.38\n",
      "RMSE: 9017.60\n",
      "----------------------------------------\n",
      "\n",
      "Training model with parameters: {'maxIter': 100, 'maxDepth': 5}\n",
      "R² (Accuracy): 78.56%\n",
      "MAE: 3604.40\n",
      "RMSE: 8767.44\n",
      "----------------------------------------\n",
      "\n",
      "Training model with parameters: {'maxIter': 100, 'maxDepth': 10}\n",
      "R² (Accuracy): 77.61%\n",
      "MAE: 3025.09\n",
      "RMSE: 8957.95\n",
      "----------------------------------------\n",
      "Best R² (Accuracy): 78.56% with parameters: {'maxIter': 100, 'maxDepth': 5}\n",
      "Best MAE: 3025.09 with parameters: {'maxIter': 100, 'maxDepth': 10}\n",
      "Best RMSE: 8767.44 with parameters: {'maxIter': 100, 'maxDepth': 5}\n",
      "\n",
      "Overall runtime: 817 minutes.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "import time\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Starting to track overall run time\n",
    "start_time = time.time()\n",
    "\n",
    "# Data preprocessing and feature engineering\n",
    "print(\"Processing the data...\")\n",
    "with tqdm(total=5, desc=\"Progress\") as pbar:\n",
    "\n",
    "    df_sample = df.sample(fraction=0.033, seed=42)  # Randomly sample 100k records of the data\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Handling categorical columns\n",
    "    cat_columns = [field for (field, dtype) in df_sample.dtypes if dtype == \"string\"]\n",
    "    stages = []\n",
    "    for col_name in cat_columns:\n",
    "        indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_indexed\", handleInvalid=\"keep\")\n",
    "        encoder = OneHotEncoder(inputCol=f\"{col_name}_indexed\", outputCol=f\"{col_name}_encoded\")\n",
    "        stages += [indexer, encoder]\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Assembling features\n",
    "    num_columns = [col for col in df_sample.columns if col != 'price' and col not in cat_columns]\n",
    "    encoded_columns = [f\"{col}_encoded\" for col in cat_columns]\n",
    "    feature_columns = num_columns + encoded_columns\n",
    "    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "    stages += [assembler]\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Adding scaling to the pipeline\n",
    "    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
    "    stages += [scaler]\n",
    "\n",
    "    # Creating and applying the pipeline\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    pipeline_model = pipeline.fit(df_sample)\n",
    "    df_sample = pipeline_model.transform(df_sample)\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Splitting the data\n",
    "    train_df, test_df = df_sample.randomSplit([0.8, 0.2], seed=42)\n",
    "    pbar.update(1)\n",
    "\n",
    "print(\"\\n\\nData preprocessing and splitting completed!\")\n",
    "\n",
    "# Defining the GBT Regressor model\n",
    "gbt_regressor = GBTRegressor(\n",
    "    featuresCol=\"scaled_features\",  # Using scaled features\n",
    "    labelCol=\"price\",               # Target column\n",
    "    seed=42                         # Random seed\n",
    ")\n",
    "\n",
    "# Creating a ParamGridBuilder for hyperparameter tuning\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt_regressor.maxIter, [50, 100]) \\\n",
    "    .addGrid(gbt_regressor.maxDepth, [5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "# Defining evaluators for each metric\n",
    "r2_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "mae_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "rmse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "# Initializing best scores and parameters\n",
    "best_r2 = -float(\"inf\")\n",
    "best_mae = float(\"inf\")\n",
    "best_rmse = float(\"inf\")\n",
    "best_params_r2 = None\n",
    "best_params_mae = None\n",
    "best_params_rmse = None\n",
    "\n",
    "# Manually iterate over each parameter combination and evaluate metrics\n",
    "for params in param_grid:\n",
    "\n",
    "    # Extracting the parameter names and values\n",
    "    param_values = {param.name: value for param, value in params.items()}\n",
    "\n",
    "    print(f\"\\nTraining model with parameters: {param_values}\")\n",
    "\n",
    "    # Using a copy to apply parameters\n",
    "    model = gbt_regressor.copy(params).fit(train_df)\n",
    "\n",
    "    # Making predictions on the test data\n",
    "    predictions = model.transform(test_df)\n",
    "\n",
    "    # Evaluating metrics\n",
    "    r2 = r2_evaluator.evaluate(predictions)\n",
    "    mae = mae_evaluator.evaluate(predictions)\n",
    "    rmse = rmse_evaluator.evaluate(predictions)\n",
    "\n",
    "    # Printing the metrics for this combination\n",
    "    print(f\"R² (Accuracy): {r2 * 100:.2f}%\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # Tracking the best scores and corresponding parameters\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_params_r2 = param_values\n",
    "\n",
    "    if mae < best_mae:\n",
    "        best_mae = mae\n",
    "        best_params_mae = param_values\n",
    "\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_params_rmse = param_values\n",
    "\n",
    "# Print the best model and its corresponding parameters\n",
    "print(f\"Best R² (Accuracy): {best_r2 * 100:.2f}% with parameters: {best_params_r2}\")\n",
    "print(f\"Best MAE: {best_mae:.2f} with parameters: {best_params_mae}\")\n",
    "print(f\"Best RMSE: {best_rmse:.2f} with parameters: {best_params_rmse}\")\n",
    "\n",
    "# Calculating total runtime\n",
    "end_time = time.time()\n",
    "total_runtime = (end_time - start_time) / 60\n",
    "print(f\"\\nOverall runtime: {round(total_runtime)} minutes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1WYlM_3Wzlt"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YC8KKYME-L_m"
   },
   "source": [
    "\n",
    "\n",
    "## **HPT Summary**\n",
    "\n",
    "For the GBT Regressor model, I experimented with different configurations to find the best-performing parameters. The hyperparameters tested included `maxIter` (50 and 100) and `maxDepth` (5 and 10), aiming to improve accuracy and minimize error metrics.\n",
    "\n",
    "**Best Configuration and Performance:**\n",
    "- **Best Parameters:** `maxIter` = 100, `maxDepth` = 5\n",
    "- **Best R² Score (Accuracy):** 78.56%\n",
    "- **Best MAE:** 3025 (achieved with `maxIter` = 100, `maxDepth` = 10)\n",
    "- **Best RMSE:** 8767\n",
    "\n",
    "**Comparison to Baseline:**\n",
    "The baseline GBT model achieved an R² of 78.56%. While the baseline already performed well, tuning the parameters enabled me to explore slight performance trade-offs. Notably, the configuration with `maxIter` = 100 and `maxDepth` = 10 achieved a lower MAE of 3025, compared to the baseline's MAE of 3604, showing an improvement in the model’s error metric.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8V0tzI7q-K5U"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oW81iQlTW0nI"
   },
   "source": [
    "# **Running with Best Parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PT78T8urHhW8"
   },
   "source": [
    "### **Scaling Up with Optimized Parameters (600k Rows):**\n",
    "Once the best parameters were identified, I applied them to the full 600k-row dataset to test scalability. This step allowed me to verify performance improvements and confirm the effectiveness of the chosen parameters on the final, larger dataset. This helps me compare the model before and after hyper parameter tuning.\n",
    "\n",
    "**Best Parameters:** `numTrees` = 100, `maxDepth` = 5, `stepSize` = 0.1,\n",
    " `minInstancesPerNode` = 10, `maxBins` = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9liglkuW41X"
   },
   "source": [
    "## **600k records**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19765,
     "status": "ok",
     "timestamp": 1729720239486,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "QAqLMxGVW9rD",
    "outputId": "0d635922-cd44-46ca-9c67-1b5089d3a7e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 5/5 [00:19<00:00,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Data preprocessing and splitting completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import mean as sql_mean\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Processing the data...\")\n",
    "with tqdm(total=5, desc=\"Progress\") as pbar:\n",
    "\n",
    "    df_sample = df.sample(fraction=0.2, seed=42)  # Randomly sample 100k records of the data\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Handling categorical columns\n",
    "    cat_columns = [field for (field, dtype) in df_sample.dtypes if dtype == \"string\"]\n",
    "    stages = []\n",
    "    for col_name in cat_columns:\n",
    "        indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_indexed\", handleInvalid=\"keep\")\n",
    "        encoder = OneHotEncoder(inputCol=f\"{col_name}_indexed\", outputCol=f\"{col_name}_encoded\")\n",
    "        stages += [indexer, encoder]\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Assembling features\n",
    "    num_columns = [col for col in df_sample.columns if col != 'price' and col not in cat_columns]\n",
    "    encoded_columns = [f\"{col}_encoded\" for col in cat_columns]\n",
    "    feature_columns = num_columns + encoded_columns\n",
    "    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "    stages += [assembler]\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Adding scaling to the pipeline\n",
    "    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
    "    stages += [scaler]\n",
    "\n",
    "    # Creating and applying the pipeline\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    pipeline_model = pipeline.fit(df_sample)\n",
    "    df_sample = pipeline_model.transform(df_sample)\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Splitting the data\n",
    "    train_df, test_df = df_sample.randomSplit([0.8, 0.2], seed=42)\n",
    "    pbar.update(1)\n",
    "\n",
    "print(\"\\n\\nData preprocessing and splitting completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42524332,
     "status": "ok",
     "timestamp": 1729763119414,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "hZqDXUZdXDBS",
    "outputId": "8af2608c-0196-474e-e0e8-b36376f51d9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GBTRegressor model...\n",
      "Making predictions...\n",
      "Evaluating the model...\n",
      "\n",
      "Train size: 480,411 samples\n",
      "Test size: 120,366 samples\n",
      "\n",
      "\n",
      "R-Squared Score (Accuracy): 88.82%\n",
      "\n",
      "\n",
      "Overall runtime: 709 minutes.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import time\n",
    "\n",
    "# Starting to track overall run time\n",
    "start_time = time.time()\n",
    "\n",
    "# Model training\n",
    "print(\"Training GBTRegressor model...\")\n",
    "\n",
    "\n",
    "# Using GBTRegressor with tuned parameters\n",
    "gbt_regressor = GBTRegressor(\n",
    "    featuresCol=\"scaled_features\",\n",
    "    labelCol=\"price\",\n",
    "    maxIter=100,\n",
    "    maxDepth=5,\n",
    "    seed=42,\n",
    "    stepSize=0.1,\n",
    "    minInstancesPerNode=10,\n",
    "    maxBins=50\n",
    ")\n",
    "\n",
    "\n",
    "# Training the model\n",
    "model = gbt_regressor.fit(train_df)\n",
    "\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "# Making predictions\n",
    "print(\"Making predictions...\")\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "# Evaluating the model\n",
    "print(\"Evaluating the model...\")\n",
    "evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"\\nTrain size: {train_df.count():,} samples\")\n",
    "print(f\"Test size: {test_df.count():,} samples\")\n",
    "\n",
    "print(f\"\\n\\nR-Squared Score (Accuracy): {r2 * 100:.2f}%\")\n",
    "\n",
    "# Calculating total runtime\n",
    "end_time = time.time()\n",
    "total_runtime = (end_time - start_time) / 60\n",
    "print(f\"\\n\\nOverall runtime: {round(total_runtime)} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 741242,
     "status": "ok",
     "timestamp": 1729763860641,
     "user": {
      "displayName": "Adithya R",
      "userId": "06981244434554202327"
     },
     "user_tz": -480
    },
    "id": "v9s8WqjWYKg6",
    "outputId": "2fcc367e-6e0c-4ed6-93c2-a5ea0a37d2ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Metrics:\n",
      "Mean Absolute Error: 3717\n",
      "Mean Squared Error: 36852583\n",
      "Root Mean Squared Error: 6071\n"
     ]
    }
   ],
   "source": [
    "# Calculating additional metrics\n",
    "mae_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae = mae_evaluator.evaluate(predictions)\n",
    "\n",
    "mse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mse = mse_evaluator.evaluate(predictions)\n",
    "\n",
    "rmse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = rmse_evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Additional Metrics:\")\n",
    "print(f\"Mean Absolute Error: {round(mae)}\")\n",
    "print(f\"Mean Squared Error: {round(mse)}\")\n",
    "print(f\"Root Mean Squared Error: {round(rmse)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7ftZjW9WxVY"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AthjmRErWzob"
   },
   "source": [
    "## **Comparison before and after training with `Best Hyper Parameters`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mk5bQcoW25t"
   },
   "source": [
    "### <font color='orange'>**Before**</font>\n",
    "**Old parameters:** `{'maxDepth': 5, 'maxIter': 100}`\n",
    "<br></br>\n",
    "R-Squared Score (Accuracy): ***88.57 %***\n",
    "<br></br>\n",
    "**Additional Metrics:**\n",
    "\n",
    "Mean Absolute Error: 3649\n",
    "\n",
    "Root Mean Squared Error: 6137\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5CLzcy6BX1ks"
   },
   "source": [
    "### <font color='yellow'>**After**</font>\n",
    "\n",
    "**Best parameters:** `{'maxDepth': 5,'maxIter': 100,'stepSize': 0.1,'minInstancesPerNode': 10,'maxBins': 50}`\n",
    "<br></br>\n",
    "R-Squared Score (Accuracy): ***88.82 %***\n",
    "<br></br>\n",
    "**Additional Metrics:**\n",
    "\n",
    "Mean Absolute Error: 3717\n",
    "\n",
    "Root Mean Squared Error: 6071"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1Lumq3Qj1NfyHg0nBLz75xzRN3kTP4QIP",
     "timestamp": 1728896799798
    },
    {
     "file_id": "1ZOoCwp36utVqUygsPBzcsOWnbRM2Ej2V",
     "timestamp": 1727142698141
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

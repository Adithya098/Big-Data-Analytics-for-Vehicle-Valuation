{"cells":[{"cell_type":"markdown","source":["## **In this notebook (XGBoost)**\n","I followed a structured process to train and tune the `XGBoost model` efficiently. First, I created a baseline model using a `300k-row subset` with a speicific set of parameters. This initial model run served as a benchmark to measure how subsequent hyperparameter tuning would impact performance metrics such as R², MAE, and RMSE.\n","\n","With XGBoost's computational efficiency (with each run on 300k rows taking at least 1.25 hours, but up to 2-4 times longer with complex parameters like higher iterations and increased depth), I was able to explore tuning across 8 different parameters.\n","\n","By systematically adjusting each parameter, I aimed to identify the best settings that would enhance the model's accuracy and minimize error rates."],"metadata":{"id":"u6IfSAgHvsCC"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46304,"status":"ok","timestamp":1730107723694,"user":{"displayName":"Adithya R","userId":"06981244434554202327"},"user_tz":-480},"id":"O4Zdpj42Q-4L","outputId":"927f846a-f5d3-4bf3-8812-b8599a2300f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","tqdm is already installed.\n","\n","pyspark is NOT installed. Installing now...\n","pyspark installation completed.\n","\n","gdown is already installed.\n","\n","numpy is already installed.\n","\n","xgboost is NOT installed. Installing now...\n","xgboost installation completed.\n","\n","sparkxgb is NOT installed. Installing now...\n","sparkxgb installation completed.\n"]}],"source":["import importlib\n","import subprocess\n","import sys\n","import gc\n","\n","def check_and_install_package(package_name, version=None):\n","    try:\n","        importlib.import_module(package_name)\n","        print(f\"\\n{package_name} is already installed.\")\n","    except ImportError:\n","        print(f\"\\n{package_name} is NOT installed. Installing now...\")\n","        if version:\n","            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", f\"{package_name}=={version}\"])\n","        else:\n","            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n","        print(f\"{package_name} installation completed.\")\n","\n","# List of packages to check along with specific versions if necessary\n","packages = [\n","    {\"name\": \"tqdm\", \"version\": None},\n","    {\"name\": \"pyspark\", \"version\": \"3.1.1\"},\n","    {\"name\": \"gdown\", \"version\": None},\n","    {\"name\": \"numpy\", \"version\": \"1.22.4\"},\n","    {\"name\": \"xgboost\", \"version\": None},\n","    {\"name\": \"sparkxgb\", \"version\": None},\n","]\n","\n","# Checking and installing packages\n","for package in packages:\n","    check_and_install_package(package[\"name\"], package[\"version\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1859,"status":"ok","timestamp":1730106354795,"user":{"displayName":"Adithya R","userId":"06981244434554202327"},"user_tz":-480},"id":"M0LqyJRl0VQN","outputId":"5ed2874f-b3e9-40c8-d0f8-6cda84475e90"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy==1.22.4 in /usr/local/lib/python3.10/dist-packages (1.22.4)\n"]}],"source":["!pip install numpy==1.22.4"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1729725103784,"user":{"displayName":"Adithya R","userId":"06981244434554202327"},"user_tz":-480},"id":"jogYwheA0ZXo","outputId":"80a247ef-1447-46a3-ae20-71d4b486f77c"},"outputs":[{"output_type":"stream","name":"stdout","text":["1.22.4\n"]}],"source":["import numpy\n","print(numpy.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1721,"status":"ok","timestamp":1729725106648,"user":{"displayName":"Adithya R","userId":"06981244434554202327"},"user_tz":-480},"id":"CPD4U30UJDrh","outputId":"aba814c2-27b7-4828-8888-62cd214ef242"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sparkxgb in /usr/local/lib/python3.10/dist-packages (0.1)\n","Requirement already satisfied: pyspark==3.1.1 in /usr/local/lib/python3.10/dist-packages (from sparkxgb) (3.1.1)\n","Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.10/dist-packages (from pyspark==3.1.1->sparkxgb) (0.10.9)\n"]}],"source":["!pip install sparkxgb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2515,"status":"ok","timestamp":1730106361899,"user":{"displayName":"Adithya R","userId":"06981244434554202327"},"user_tz":-480},"id":"RzKYWgsyRGny","outputId":"8cffa7ec-f8de-4f99-e02d-555fc7f091cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":315,"status":"ok","timestamp":1730106366267,"user":{"displayName":"Adithya R","userId":"06981244434554202327"},"user_tz":-480},"id":"4QHkLfzsGy18","outputId":"6248752e-d721-4762-b681-9e456d3e2140"},"outputs":[{"output_type":"stream","name":"stdout","text":["Jar Files copied to: /resources\n","['xgboost4j-spark_2.12-1.7.6.jar', 'xgboost4j_2.12-1.7.6.jar']\n"]}],"source":["import os\n","import shutil\n","\n","# Defining local resources directory\n","local_resources_path = \"/resources\"\n","os.makedirs(local_resources_path, exist_ok=True)\n","\n","# Defining the source paths from your mounted Google Drive\n","xgboost4j_source = \"/content/drive/MyDrive/Big Data Analytics - Project/resources/xgboost4j_2.12-1.7.6.jar\"\n","xgboost4j_spark_source = \"/content/drive/MyDrive/Big Data Analytics - Project/resources/xgboost4j-spark_2.12-1.7.6.jar\"\n","\n","# Defining the destination paths in the instance's local file system\n","xgboost4j_dest = os.path.join(local_resources_path, \"xgboost4j_2.12-1.7.6.jar\")\n","xgboost4j_spark_dest = os.path.join(local_resources_path, \"xgboost4j-spark_2.12-1.7.6.jar\")\n","\n","# Copying the files from Google Drive to the local instance\n","shutil.copyfile(xgboost4j_source, xgboost4j_dest)\n","shutil.copyfile(xgboost4j_spark_source, xgboost4j_spark_dest)\n","\n","# Verifying that the files are copied\n","print(f\"Jar Files copied to: {local_resources_path}\")\n","print(os.listdir(local_resources_path))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4250,"status":"ok","timestamp":1730106373982,"user":{"displayName":"Adithya R","userId":"06981244434554202327"},"user_tz":-480},"id":"dMvRtGAZRWKh","outputId":"91415331-a0ff-4c2f-ce45-02c87a9d659c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Spark session started with version: 3.1.1\n"]}],"source":["from pyspark.sql import SparkSession\n","\n","# Defining the path to the copied jar files in the local instance\n","jar_files = \"/resources/xgboost4j_2.12-1.7.6.jar,/resources/xgboost4j-spark_2.12-1.7.6.jar\"\n","\n","# Initializing Spark session with the JAR files\n","spark = SparkSession.builder \\\n","    .appName(\"XGBoostRegressor\") \\\n","    .config(\"spark.driver.memory\", \"120g\") \\\n","    .config(\"spark.executor.memory\", \"120g\") \\\n","    .config(\"spark.driver.maxResultSize\", \"40g\") \\\n","    .config(\"spark.executor.memoryOverhead\", \"40g\") \\\n","    .config(\"spark.executor.cores\", \"5\") \\\n","    .config(\"spark.kryoserializer.buffer.max\", \"2047m\") \\\n","    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n","    .config(\"spark.dynamicAllocation.enabled\", \"true\") \\\n","    .config(\"spark.sql.shuffle.partitions\", \"400\") \\\n","    .config(\"spark.hadoop.fs.file.impl\", \"org.apache.hadoop.fs.LocalFileSystem\") \\\n","    .config(\"spark.executor.extraJavaOptions\", \"-XX:+UseG1GC -XX:InitiatingHeapOccupancyPercent=35 -XX:ConcGCThreads=4 -XX:ParallelGCThreads=4\") \\\n","    .config(\"spark.jars\", jar_files) \\\n","    .getOrCreate()\n","\n","# Verifying Spark session creation\n","print(f\"Spark session started with version: {spark.version}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1730106373983,"user":{"displayName":"Adithya R","userId":"06981244434554202327"},"user_tz":-480},"id":"x5Z292PcHRYR","outputId":"425af523-7a50-4e5a-ddcc-6b39e7b8c84d"},"outputs":[{"output_type":"stream","name":"stdout","text":["sparkxgb loaded successfully!\n"]}],"source":["# Testing if sparkxgb is loaded properly\n","try:\n","    from sparkxgb import XGBoostRegressor\n","\n","    model = XGBoostRegressor()\n","    print(\"sparkxgb loaded successfully!\")\n","except Exception as e:\n","    print(f\"Error loading sparkxgb: {e}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2906,"status":"ok","timestamp":1730106376887,"user":{"displayName":"Adithya R","userId":"06981244434554202327"},"user_tz":-480},"id":"74JPP1A15OAQ","outputId":"81547a66-b745-42ee-efc5-7bbb82fbe95a"},"outputs":[{"output_type":"stream","name":"stdout","text":["The Feature Engineered DataFrame has been loaded successfully.\n"]}],"source":["!cp '/content/drive/MyDrive/Big Data Analytics - Project/Datasets/Feature_Engineered_DF.parquet' /content/\n","\n","output_path = '/content/Feature_Engineered_DF.parquet'\n","df = spark.read.parquet(output_path)\n","print(\"The Feature Engineered DataFrame has been loaded successfully.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1708,"status":"ok","timestamp":1730106378593,"user":{"displayName":"Adithya R","userId":"06981244434554202327"},"user_tz":-480},"id":"jIQ0jom35_PN","outputId":"c01d3317-e05f-467c-a3c5-59e6078bbbaa"},"outputs":[{"output_type":"stream","name":"stdout","text":["The shape of the loaded DataFrame is: (3000040, 47)\n"]}],"source":["# Printing the shape of the DataFrame\n","total_rows = df.count()\n","total_columns = len(df.columns)\n","\n","print(f\"The shape of the loaded DataFrame is: ({total_rows}, {total_columns})\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":709,"status":"ok","timestamp":1730106379301,"user":{"displayName":"Adithya R","userId":"06981244434554202327"},"user_tz":-480},"id":"Ngd7Um5Q6H-Y","outputId":"ab54a87a-fc42-4822-ca96-467ca6600e66"},"outputs":[{"output_type":"stream","name":"stdout","text":["Average price of a car: 29933\n"]}],"source":["# Calculating the average price\n","avg_price = df.agg({\"price\": \"avg\"}).collect()[0][0]\n","print(f\"Average price of a car: {round(avg_price)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":399},"executionInfo":{"elapsed":9471,"status":"ok","timestamp":1730106388771,"user":{"displayName":"Adithya R","userId":"06981244434554202327"},"user_tz":-480},"id":"loBieuHM6NG5","outputId":"1a88ae29-a5c8-49df-baa1-f5d83a185ea8"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  fuel_type        body_type          city  city_fuel_economy  days_in_market  \\\n","0  Gasoline            Sedan        Venice          26.000000              12   \n","1  Gasoline  SUV / Crossover    Texas City          21.000000              19   \n","2  Gasoline  SUV / Crossover     Knoxville          22.690001              50   \n","3  Gasoline  SUV / Crossover  Murfreesboro          26.000000              76   \n","4  Gasoline  SUV / Crossover       Houston          21.000000              22   \n","\n","  dealer_zip  engine_displacement      engine_type exterior_color  \\\n","0      34285               1800.0               I4            Red   \n","1      77590               2300.0               I4          White   \n","2      37923               5700.0  Gasoline engine          Black   \n","3      37129               1200.0               I3          Other   \n","4      77034               2300.0               I4          Black   \n","\n","   franchise_dealer  fuel_tank_volume  height  highway_fuel_economy  \\\n","0              True         13.200000    57.7             34.000000   \n","1              True         19.200001    69.9             28.000000   \n","2              True         24.600000    69.4             29.469999   \n","3              True         13.200000    64.1             30.000000   \n","4              True         19.200001    69.9             28.000000   \n","\n","   horsepower interior_color  is_new   latitude  length listing_color  \\\n","0       132.0          Other   False  27.092600   178.7           RED   \n","1       300.0          White    True  29.395201   198.8         WHITE   \n","2       360.0   Mixed Colors   False  35.917500   189.8         BLACK   \n","3       137.0           Gray    True  35.866199   171.4       UNKNOWN   \n","4       300.0          Black    True  29.622200   198.8         BLACK   \n","\n","   longitude make_name  maximum_seating      model_name    price  \\\n","0 -82.432999    Toyota              5.0         Corolla   7980.0   \n","1 -94.931702      Ford              7.0        Explorer  42700.0   \n","2 -84.073601      Jeep              5.0  Grand Cherokee  16999.0   \n","3 -86.458702     Buick              5.0       Encore GX  21963.0   \n","4 -95.222099      Ford              7.0        Explorer  36806.0   \n","\n","   savings_amount  seller_rating  \\\n","0             821       2.909091   \n","1               0       4.250000   \n","2            3409       4.100000   \n","3               0       4.366667   \n","4               0       4.490566   \n","\n","                                        sp_name  torque transmission  \\\n","0                              Nissan of Venice  128.00            A   \n","1                                     Cook Ford  265.22            A   \n","2                        Grayson Hyundai Subaru  390.00            A   \n","3  Chevrolet Buick Cadillac GMC of Murfreesboro  162.00          CVT   \n","4                  AutoNation Ford Gulf Freeway  265.22            A   \n","\n","                 transmission_display wheel_system_display  wheelbase  width  \\\n","0                   4-Speed Automatic    Front-Wheel Drive      102.4   69.3   \n","1                           Automatic     Rear-Wheel Drive      119.1   89.3   \n","2                   8-Speed Automatic     Four-Wheel Drive      114.8   84.8   \n","3  Continuously Variable Transmission    Front-Wheel Drive      102.2   71.4   \n","4                           Automatic     Rear-Wheel Drive      119.1   89.3   \n","\n","   manufactured_year  combined_fuel_economy  legroom  log_mileage  \\\n","0               2010                  30.00     78.0        11.06   \n","1               2020                  24.50     82.0         1.10   \n","2               2015                  26.08     78.9        11.63   \n","3               2020                  28.00     76.9         8.91   \n","4               2020                  24.50     82.0         2.30   \n","\n","   major_options_count  hp_x_engine_disp  hp_x_torque  listed_day  \\\n","0                    0              1.14      1.65957          30   \n","1                    6             -0.29      0.00001          23   \n","2                    8              2.69      1.46753          22   \n","3                    4              1.67      1.19436          27   \n","4                    3             -0.29      0.00001          20   \n","\n","   listed_month  listed_year  age  resale_value_score  maintenance_cost  \\\n","0             8         2020   10                  20                27   \n","1             8         2020    0                  34                40   \n","2             7         2020    5                  20                39   \n","3             6         2020    0                  24                35   \n","4             8         2020    0                  31                40   \n","\n","   luxury_score  \n","0            24  \n","1            37  \n","2            35  \n","3            30  \n","4            36  "],"text/html":["\n","  <div id=\"df-f119aade-baf7-48e0-847a-d39d780cfbd9\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fuel_type</th>\n","      <th>body_type</th>\n","      <th>city</th>\n","      <th>city_fuel_economy</th>\n","      <th>days_in_market</th>\n","      <th>dealer_zip</th>\n","      <th>engine_displacement</th>\n","      <th>engine_type</th>\n","      <th>exterior_color</th>\n","      <th>franchise_dealer</th>\n","      <th>fuel_tank_volume</th>\n","      <th>height</th>\n","      <th>highway_fuel_economy</th>\n","      <th>horsepower</th>\n","      <th>interior_color</th>\n","      <th>is_new</th>\n","      <th>latitude</th>\n","      <th>length</th>\n","      <th>listing_color</th>\n","      <th>longitude</th>\n","      <th>make_name</th>\n","      <th>maximum_seating</th>\n","      <th>model_name</th>\n","      <th>price</th>\n","      <th>savings_amount</th>\n","      <th>seller_rating</th>\n","      <th>sp_name</th>\n","      <th>torque</th>\n","      <th>transmission</th>\n","      <th>transmission_display</th>\n","      <th>wheel_system_display</th>\n","      <th>wheelbase</th>\n","      <th>width</th>\n","      <th>manufactured_year</th>\n","      <th>combined_fuel_economy</th>\n","      <th>legroom</th>\n","      <th>log_mileage</th>\n","      <th>major_options_count</th>\n","      <th>hp_x_engine_disp</th>\n","      <th>hp_x_torque</th>\n","      <th>listed_day</th>\n","      <th>listed_month</th>\n","      <th>listed_year</th>\n","      <th>age</th>\n","      <th>resale_value_score</th>\n","      <th>maintenance_cost</th>\n","      <th>luxury_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Gasoline</td>\n","      <td>Sedan</td>\n","      <td>Venice</td>\n","      <td>26.000000</td>\n","      <td>12</td>\n","      <td>34285</td>\n","      <td>1800.0</td>\n","      <td>I4</td>\n","      <td>Red</td>\n","      <td>True</td>\n","      <td>13.200000</td>\n","      <td>57.7</td>\n","      <td>34.000000</td>\n","      <td>132.0</td>\n","      <td>Other</td>\n","      <td>False</td>\n","      <td>27.092600</td>\n","      <td>178.7</td>\n","      <td>RED</td>\n","      <td>-82.432999</td>\n","      <td>Toyota</td>\n","      <td>5.0</td>\n","      <td>Corolla</td>\n","      <td>7980.0</td>\n","      <td>821</td>\n","      <td>2.909091</td>\n","      <td>Nissan of Venice</td>\n","      <td>128.00</td>\n","      <td>A</td>\n","      <td>4-Speed Automatic</td>\n","      <td>Front-Wheel Drive</td>\n","      <td>102.4</td>\n","      <td>69.3</td>\n","      <td>2010</td>\n","      <td>30.00</td>\n","      <td>78.0</td>\n","      <td>11.06</td>\n","      <td>0</td>\n","      <td>1.14</td>\n","      <td>1.65957</td>\n","      <td>30</td>\n","      <td>8</td>\n","      <td>2020</td>\n","      <td>10</td>\n","      <td>20</td>\n","      <td>27</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Gasoline</td>\n","      <td>SUV / Crossover</td>\n","      <td>Texas City</td>\n","      <td>21.000000</td>\n","      <td>19</td>\n","      <td>77590</td>\n","      <td>2300.0</td>\n","      <td>I4</td>\n","      <td>White</td>\n","      <td>True</td>\n","      <td>19.200001</td>\n","      <td>69.9</td>\n","      <td>28.000000</td>\n","      <td>300.0</td>\n","      <td>White</td>\n","      <td>True</td>\n","      <td>29.395201</td>\n","      <td>198.8</td>\n","      <td>WHITE</td>\n","      <td>-94.931702</td>\n","      <td>Ford</td>\n","      <td>7.0</td>\n","      <td>Explorer</td>\n","      <td>42700.0</td>\n","      <td>0</td>\n","      <td>4.250000</td>\n","      <td>Cook Ford</td>\n","      <td>265.22</td>\n","      <td>A</td>\n","      <td>Automatic</td>\n","      <td>Rear-Wheel Drive</td>\n","      <td>119.1</td>\n","      <td>89.3</td>\n","      <td>2020</td>\n","      <td>24.50</td>\n","      <td>82.0</td>\n","      <td>1.10</td>\n","      <td>6</td>\n","      <td>-0.29</td>\n","      <td>0.00001</td>\n","      <td>23</td>\n","      <td>8</td>\n","      <td>2020</td>\n","      <td>0</td>\n","      <td>34</td>\n","      <td>40</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Gasoline</td>\n","      <td>SUV / Crossover</td>\n","      <td>Knoxville</td>\n","      <td>22.690001</td>\n","      <td>50</td>\n","      <td>37923</td>\n","      <td>5700.0</td>\n","      <td>Gasoline engine</td>\n","      <td>Black</td>\n","      <td>True</td>\n","      <td>24.600000</td>\n","      <td>69.4</td>\n","      <td>29.469999</td>\n","      <td>360.0</td>\n","      <td>Mixed Colors</td>\n","      <td>False</td>\n","      <td>35.917500</td>\n","      <td>189.8</td>\n","      <td>BLACK</td>\n","      <td>-84.073601</td>\n","      <td>Jeep</td>\n","      <td>5.0</td>\n","      <td>Grand Cherokee</td>\n","      <td>16999.0</td>\n","      <td>3409</td>\n","      <td>4.100000</td>\n","      <td>Grayson Hyundai Subaru</td>\n","      <td>390.00</td>\n","      <td>A</td>\n","      <td>8-Speed Automatic</td>\n","      <td>Four-Wheel Drive</td>\n","      <td>114.8</td>\n","      <td>84.8</td>\n","      <td>2015</td>\n","      <td>26.08</td>\n","      <td>78.9</td>\n","      <td>11.63</td>\n","      <td>8</td>\n","      <td>2.69</td>\n","      <td>1.46753</td>\n","      <td>22</td>\n","      <td>7</td>\n","      <td>2020</td>\n","      <td>5</td>\n","      <td>20</td>\n","      <td>39</td>\n","      <td>35</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Gasoline</td>\n","      <td>SUV / Crossover</td>\n","      <td>Murfreesboro</td>\n","      <td>26.000000</td>\n","      <td>76</td>\n","      <td>37129</td>\n","      <td>1200.0</td>\n","      <td>I3</td>\n","      <td>Other</td>\n","      <td>True</td>\n","      <td>13.200000</td>\n","      <td>64.1</td>\n","      <td>30.000000</td>\n","      <td>137.0</td>\n","      <td>Gray</td>\n","      <td>True</td>\n","      <td>35.866199</td>\n","      <td>171.4</td>\n","      <td>UNKNOWN</td>\n","      <td>-86.458702</td>\n","      <td>Buick</td>\n","      <td>5.0</td>\n","      <td>Encore GX</td>\n","      <td>21963.0</td>\n","      <td>0</td>\n","      <td>4.366667</td>\n","      <td>Chevrolet Buick Cadillac GMC of Murfreesboro</td>\n","      <td>162.00</td>\n","      <td>CVT</td>\n","      <td>Continuously Variable Transmission</td>\n","      <td>Front-Wheel Drive</td>\n","      <td>102.2</td>\n","      <td>71.4</td>\n","      <td>2020</td>\n","      <td>28.00</td>\n","      <td>76.9</td>\n","      <td>8.91</td>\n","      <td>4</td>\n","      <td>1.67</td>\n","      <td>1.19436</td>\n","      <td>27</td>\n","      <td>6</td>\n","      <td>2020</td>\n","      <td>0</td>\n","      <td>24</td>\n","      <td>35</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Gasoline</td>\n","      <td>SUV / Crossover</td>\n","      <td>Houston</td>\n","      <td>21.000000</td>\n","      <td>22</td>\n","      <td>77034</td>\n","      <td>2300.0</td>\n","      <td>I4</td>\n","      <td>Black</td>\n","      <td>True</td>\n","      <td>19.200001</td>\n","      <td>69.9</td>\n","      <td>28.000000</td>\n","      <td>300.0</td>\n","      <td>Black</td>\n","      <td>True</td>\n","      <td>29.622200</td>\n","      <td>198.8</td>\n","      <td>BLACK</td>\n","      <td>-95.222099</td>\n","      <td>Ford</td>\n","      <td>7.0</td>\n","      <td>Explorer</td>\n","      <td>36806.0</td>\n","      <td>0</td>\n","      <td>4.490566</td>\n","      <td>AutoNation Ford Gulf Freeway</td>\n","      <td>265.22</td>\n","      <td>A</td>\n","      <td>Automatic</td>\n","      <td>Rear-Wheel Drive</td>\n","      <td>119.1</td>\n","      <td>89.3</td>\n","      <td>2020</td>\n","      <td>24.50</td>\n","      <td>82.0</td>\n","      <td>2.30</td>\n","      <td>3</td>\n","      <td>-0.29</td>\n","      <td>0.00001</td>\n","      <td>20</td>\n","      <td>8</td>\n","      <td>2020</td>\n","      <td>0</td>\n","      <td>31</td>\n","      <td>40</td>\n","      <td>36</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f119aade-baf7-48e0-847a-d39d780cfbd9')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f119aade-baf7-48e0-847a-d39d780cfbd9 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f119aade-baf7-48e0-847a-d39d780cfbd9');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-330d886e-4101-4005-84e0-bb2a7e6fce80\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-330d886e-4101-4005-84e0-bb2a7e6fce80')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-330d886e-4101-4005-84e0-bb2a7e6fce80 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_647227b6-6777-4ab6-a119-b53e9b66514a\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pandas_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_647227b6-6777-4ab6-a119-b53e9b66514a button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('pandas_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"pandas_df"}},"metadata":{}}],"source":["import pandas as pd\n","from IPython.display import display\n","import pyspark.sql.functions as F\n","\n","# Converting the Spark DataFrame to a Pandas DataFrame and displaying the first 5 rows\n","pd.set_option('display.max_columns', None)\n","pandas_df = df.orderBy(F.rand()).limit(5).toPandas()\n","display(pandas_df)\n"]},{"cell_type":"markdown","metadata":{"id":"fkRyN8vemDZA"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","source":["# **XG Boost**"],"metadata":{"id":"JZRO41WZVNQY"}},{"cell_type":"markdown","source":["### **Initial Training on a Subset (300k Rows):**\n","\n","This was the baseline I trained on (after feature engineering).\n","\n","I begin by training XGB on a subset of 300k rows with specific parameters, establishing a baseline model. This baseline serves as a comparison point, allowing me to evaluate how each hyperparameter tuning experiment impacts performance, either increasing or decreasing metrics relative to the baseline. The initial 300k subset is thus used specifically for benchmarking improvements."],"metadata":{"id":"Av9kUpc-UWn8"}},{"cell_type":"code","source":["import warnings\n","from tqdm import tqdm\n","from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, OneHotEncoder\n","from pyspark.ml import Pipeline\n","from pyspark.sql.functions import mean as sql_mean\n","import pyspark.sql.functions as F\n","\n","# Ignore warnings\n","warnings.filterwarnings('ignore')\n","\n","print(\"Processing the data...\")\n","with tqdm(total=6, desc=\"Progress\") as pbar:\n","\n","    df_sample = df.sample(fraction=0.1, seed=42)   # Randomly sampling 10% of the data\n","    pbar.update(1)\n","\n","    # Handling categorical columns\n","    cat_columns = [field for (field, dtype) in df_sample.dtypes if dtype == \"string\"]\n","    stages = []\n","    for col_name in cat_columns:\n","        indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_indexed\", handleInvalid=\"keep\")\n","        encoder = OneHotEncoder(inputCol=f\"{col_name}_indexed\", outputCol=f\"{col_name}_encoded\")\n","        stages += [indexer, encoder]\n","    pbar.update(1)\n","\n","    # Assembling features\n","    num_columns = [col for col in df_sample.columns if col != 'price' and col not in cat_columns]\n","    encoded_columns = [f\"{col}_encoded\" for col in cat_columns]\n","    feature_columns = num_columns + encoded_columns\n","    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n","    stages += [assembler]\n","    pbar.update(1)\n","\n","    # Adding scaling to the pipeline\n","    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n","    stages += [scaler]\n","\n","    # Creating and apply the pipeline\n","    pipeline = Pipeline(stages=stages)\n","    pipeline_model = pipeline.fit(df_sample)\n","    df_sample = pipeline_model.transform(df_sample)\n","    pbar.update(1)\n","\n","    # Filling in missing values\n","    for col in df_sample.columns:\n","        if df_sample.schema[col].dataType.typeName() in [\"double\", \"float\", \"int\", \"long\"]:\n","            mean_value = df_sample.select(sql_mean(col)).first()[0]\n","            df_sample = df_sample.na.fill({col: mean_value})\n","    pbar.update(1)\n","\n","    # Splitting the data\n","    train_df, test_df = df_sample.randomSplit([0.8, 0.2], seed=42)\n","    pbar.update(1)\n","\n","print(\"\\n\\nData preprocessing and splitting completed!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gF9wddNdU7KN","executionInfo":{"status":"ok","timestamp":1730106426009,"user_tz":-480,"elapsed":35039,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"8e97ed36-2a41-46f8-e5d9-cbf94c4be587"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing the data...\n"]},{"output_type":"stream","name":"stderr","text":["Progress: 100%|██████████| 6/6 [00:34<00:00,  5.79s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Data preprocessing and splitting completed!\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["from pyspark.ml.evaluation import RegressionEvaluator\n","from sparkxgb import XGBoostRegressor\n","import time\n","\n","# Model training\n","print(\"Training XGBoost model...\")\n","\n","xgb_regressor = XGBoostRegressor(\n","    featuresCol=\"scaled_features\",\n","    labelCol=\"price\",\n","    maxDepth=6,\n","    numRound=100,\n","    objective=\"reg:squarederror\",\n","    treeMethod=\"hist\",\n",")\n","\n","\n","# Before training\n","start_time = time.time()\n","\n","# Training the model\n","model = xgb_regressor.fit(train_df)\n","\n","# Making predictions\n","print(\"Making predictions...\")\n","predictions = model.transform(test_df)\n","\n","# Evaluating the model\n","print(\"Evaluating the model...\")\n","evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n","r2 = evaluator.evaluate(predictions)\n","\n","print(f\"\\nTrain size: {train_df.count()} samples\")\n","print(f\"Test size: {test_df.count()} samples\")\n","print(f\"\\n\\nR-Squared Score (Accuracy): {round(r2 * 100)}%\\n\")\n","\n","# Calculating total runtime\n","end_time = time.time()\n","total_runtime = (end_time - start_time) / 60\n","print(f\"\\nOverall runtime: {round(total_runtime)} minutes.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q2FQD0MrVUnV","executionInfo":{"status":"ok","timestamp":1730106084779,"user_tz":-480,"elapsed":335,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"2a19b327-bbac-4a92-bad3-7e1242492969"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training XGBoost model...\n","Making predictions...\n","Evaluating the model...\n","\n","Train size: 240,048 samples\n","Test size: 59,933 samples\n","\n","R-Squared Score (Accuracy): 91.84%\n","\n","Overall runtime: 75 minutes.\n","\n"]}]},{"cell_type":"code","source":["# Calculating additional metrics\n","mae_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"mae\")\n","mae = mae_evaluator.evaluate(predictions)\n","\n","mse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"mse\")\n","mse = mse_evaluator.evaluate(predictions)\n","\n","rmse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n","rmse = rmse_evaluator.evaluate(predictions)\n","\n","print(\"Additional Metrics:\")\n","print(f\"Mean Absolute Error: {round(mae)}\")\n","print(f\"Mean Squared Error: {round(mse)}\")\n","print(f\"Root Mean Squared Error: {round(rmse)}\")\n","\n","# Calculating total runtime\n","end_time = time.time()\n","total_runtime = (end_time - start_time) / 60\n","print(f\"\\n\\nOverall runtime: {round(total_runtime)} minutes.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UOgaGM9AVbBJ","executionInfo":{"status":"ok","timestamp":1730107772463,"user_tz":-480,"elapsed":324,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"8578665d-3062-4c1b-f0bb-c89b878f1bdf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Additional Metrics:\n","Mean Absolute Error: 3018\n","Mean Squared Error: 27751838\n","Root Mean Squared Error: 5268\n"]}]},{"cell_type":"markdown","metadata":{"id":"tne-jyA8C0BF"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"QWidlAKgC4KK"},"source":["## **Hyper Parameter Tuning**"]},{"cell_type":"markdown","source":["### **Hyperparameter Tuning on 300k Rows:**\n","\n","Once I established baseline metrics, I proceeded with hyperparameter tuning on the same subset. Training on 300k rows with different parameter combinations enabled me to evaluate the impact of various hyperparameters. This step was crucial to narrow down the most promising configurations (increased accuracy and decreased RMSE/MAE)."],"metadata":{"id":"xWoESczhfti3"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"DMfAwnvDC22u","outputId":"7a81bf55-4c7b-4c0b-cf88-b51b790d4267"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Processing the data...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Progress: 6it [00:42,  7.16s/it]                       \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Data preprocessing and splitting completed!\n","---------------------------------------------------------------------------\n","\n","Training model with parameters: {'maxDepth': 6, 'numRound': 100, 'eta': 0.1}\n","R² (Accuracy): 90.63%\n","MAE: 3371.68\n","RMSE: 5644.62\n","----------------------------------------\n","\n","Training model with parameters: {'maxDepth': 6, 'numRound': 100, 'eta': 0.05}\n","R² (Accuracy): 88.75%\n","MAE: 3739.64\n","RMSE: 6185.30\n","----------------------------------------\n","\n","Training model with parameters: {'maxDepth': 6, 'numRound': 200, 'eta': 0.1}\n","R² (Accuracy): 91.75%\n","MAE: 3091.11\n","RMSE: 5294.57\n","----------------------------------------\n","\n","Training model with parameters: {'maxDepth': 6, 'numRound': 200, 'eta': 0.05}\n","R² (Accuracy): 90.73%\n","MAE: 3360.87\n","RMSE: 5612.34\n","----------------------------------------\n","\n","Training model with parameters: {'maxDepth': 8, 'numRound': 100, 'eta': 0.1}\n","R² (Accuracy): 92.06%\n","MAE: 2966.11\n","RMSE: 5196.14\n","----------------------------------------\n","\n","Training model with parameters: {'maxDepth': 8, 'numRound': 100, 'eta': 0.05}\n","R² (Accuracy): 90.61%\n","MAE: 3276.04\n","RMSE: 5650.81\n","----------------------------------------\n","\n","Training model with parameters: {'maxDepth': 8, 'numRound': 200, 'eta': 0.1}\n","R² (Accuracy): 92.75%\n","MAE: 2759.39\n","RMSE: 4963.51\n","----------------------------------------\n","\n","Training model with parameters: {'maxDepth': 8, 'numRound': 200, 'eta': 0.05}\n"]}],"source":["from pyspark.ml.evaluation import RegressionEvaluator\n","from sparkxgb import XGBoostRegressor\n","from pyspark.ml.tuning import ParamGridBuilder\n","import time\n","import warnings\n","from tqdm import tqdm\n","from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, OneHotEncoder\n","from pyspark.ml import Pipeline\n","import pyspark.sql.functions as F\n","\n","# Ignore warnings\n","warnings.filterwarnings('ignore')\n","\n","# Start tracking overall runtime\n","start_time = time.time()\n","\n","# Data preprocessing and feature engineering\n","print(\"Processing the data...\")\n","with tqdm(total=5, desc=\"Progress\") as pbar:\n","\n","    df_sample = df.sample(fraction=0.1, seed=42)  # Random sampling 300k records of the data\n","    pbar.update(1)\n","\n","    # Handling categorical columns\n","    cat_columns = [field for (field, dtype) in df_sample.dtypes if dtype == \"string\"]\n","    stages = []\n","    for col_name in cat_columns:\n","        indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_indexed\", handleInvalid=\"keep\")\n","        encoder = OneHotEncoder(inputCol=f\"{col_name}_indexed\", outputCol=f\"{col_name}_encoded\")\n","        stages += [indexer, encoder]\n","    pbar.update(1)\n","\n","    # Assembling features\n","    num_columns = [col for col in df_sample.columns if col != 'price' and col not in cat_columns]\n","    encoded_columns = [f\"{col}_encoded\" for col in cat_columns]\n","    feature_columns = num_columns + encoded_columns\n","    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n","    stages += [assembler]\n","    pbar.update(1)\n","\n","    # Adding scaling to the pipeline\n","    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n","    stages += [scaler]\n","\n","    # Creating and applying the pipeline\n","    pipeline = Pipeline(stages=stages)\n","    pipeline_model = pipeline.fit(df_sample)\n","    df_sample = pipeline_model.transform(df_sample)\n","    pbar.update(1)\n","\n","    # Filling in missing values\n","    for col in df_sample.columns:\n","        if df_sample.schema[col].dataType.typeName() in [\"double\", \"float\", \"int\", \"long\"]:\n","            mean_value = df_sample.select(F.mean(col)).first()[0]\n","            df_sample = df_sample.na.fill({col: mean_value})\n","    pbar.update(1)\n","\n","    # Splitting the data\n","    train_df, test_df = df_sample.randomSplit([0.8, 0.2], seed=42)\n","    pbar.update(1)\n","\n","print(\"\\nData preprocessing and splitting completed!\")\n","\n","# Defining the XGBoost Regressor model\n","xgb_regressor = XGBoostRegressor(\n","    featuresCol=\"scaled_features\",  # Using the scaled features\n","    labelCol=\"price\",               # Target column\n","    objective=\"reg:squarederror\",   # Regression task\n","    treeMethod=\"hist\",              # Tree construction algorithm\n","    seed=42                         # Random seed\n",")\n","\n","# Creating a ParamGridBuilder for hyperparameter tuning\n","param_grid = ParamGridBuilder() \\\n","    .addGrid(xgb_regressor.maxDepth, [6, 8]) \\\n","    .addGrid(xgb_regressor.numRound, [100, 200]) \\\n","    .addGrid(xgb_regressor.eta, [0.1, 0.05]) \\\n","    .build()\n","\n","# Defining evaluators for each metric\n","r2_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n","mae_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"mae\")\n","rmse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n","\n","# Initializing best scores and parameters\n","best_r2 = -float(\"inf\")\n","best_mae = float(\"inf\")\n","best_rmse = float(\"inf\")\n","best_params_r2 = None\n","best_params_mae = None\n","best_params_rmse = None\n","print('---------------------------------------------------------------------------')\n","\n","# Manually iterating over each parameter combination and evaluating metrics\n","for params in param_grid:\n","\n","    # Extracting the parameter names and values\n","    param_values = {param.name: value for param, value in params.items()}\n","\n","    print(f\"\\nTraining model with parameters: {param_values}\")\n","\n","    # Using copy to apply parameters\n","    model = xgb_regressor.copy(params).fit(train_df)\n","\n","    # Making predictions on the test data\n","    predictions = model.transform(test_df)\n","\n","    # Evaluating metrics\n","    r2 = r2_evaluator.evaluate(predictions)\n","    mae = mae_evaluator.evaluate(predictions)\n","    rmse = rmse_evaluator.evaluate(predictions)\n","\n","    # Printing the metrics for this combination\n","    print(f\"R² (Accuracy): {r2 * 100:.2f}%\")\n","    print(f\"MAE: {mae:.2f}\")\n","    print(f\"RMSE: {rmse:.2f}\")\n","    print(\"-\" * 40)\n","\n","    # Tracking the best scores and corresponding parameters\n","    if r2 > best_r2:\n","        best_r2 = r2\n","        best_params_r2 = param_values\n","\n","    if mae < best_mae:\n","        best_mae = mae\n","        best_params_mae = param_values\n","\n","    if rmse < best_rmse:\n","        best_rmse = rmse\n","        best_params_rmse = param_values\n","\n","# Printing the best model and its corresponding parameters\n","print(f\"Best R² (Accuracy): {best_r2 * 100:.2f}% with parameters: {best_params_r2}\")\n","print(f\"Best MAE: {best_mae:.2f} with parameters: {best_params_mae}\")\n","print(f\"Best RMSE: {best_rmse:.2f} with parameters: {best_params_rmse}\")\n","\n","# Calculating total runtime\n","end_time = time.time()\n","total_runtime = (end_time - start_time) / 60\n","print(f\"\\nOverall runtime: {round(total_runtime)} minutes.\")\n"]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"QhG23UzaVlh6"}},{"cell_type":"markdown","source":["#### The above cell got stopped because it got timed out. So I am manually checking for the last parameter (which couldnt complete its run)."],"metadata":{"id":"Eaa-R7FROnmC"}},{"cell_type":"code","source":["import warnings\n","from tqdm import tqdm\n","from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, OneHotEncoder\n","from pyspark.ml import Pipeline\n","from pyspark.sql.functions import mean as sql_mean\n","import pyspark.sql.functions as F\n","\n","# Ignore warnings\n","warnings.filterwarnings('ignore')\n","\n","print(\"Processing the data...\")\n","with tqdm(total=5, desc=\"Progress\") as pbar:\n","\n","    df_sample = df.sample(fraction=0.1, seed=42)  # Randomly sample 300k records of the data\n","    pbar.update(1)\n","\n","    # Handling categorical columns\n","    cat_columns = [field for (field, dtype) in df_sample.dtypes if dtype == \"string\"]\n","    stages = []\n","    for col_name in cat_columns:\n","        indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_indexed\", handleInvalid=\"keep\")\n","        encoder = OneHotEncoder(inputCol=f\"{col_name}_indexed\", outputCol=f\"{col_name}_encoded\")\n","        stages += [indexer, encoder]\n","    pbar.update(1)\n","\n","    # Assembling features\n","    num_columns = [col for col in df_sample.columns if col != 'price' and col not in cat_columns]\n","    encoded_columns = [f\"{col}_encoded\" for col in cat_columns]\n","    feature_columns = num_columns + encoded_columns\n","    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n","    stages += [assembler]\n","    pbar.update(1)\n","\n","    # Adding scaling to the pipeline\n","    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n","    stages += [scaler]\n","\n","    # Creating and applying the pipeline\n","    pipeline = Pipeline(stages=stages)\n","    pipeline_model = pipeline.fit(df_sample)\n","    df_sample = pipeline_model.transform(df_sample)\n","    pbar.update(1)\n","\n","    # Filling in missing values\n","    for col in df_sample.columns:\n","        if df_sample.schema[col].dataType.typeName() in [\"double\", \"float\", \"int\", \"long\"]:\n","            mean_value = df_sample.select(sql_mean(col)).first()[0]\n","            df_sample = df_sample.na.fill({col: mean_value})\n","    pbar.update(1)\n","\n","    # Splitting the data\n","    train_df, test_df = df_sample.randomSplit([0.8, 0.2], seed=42)\n","    pbar.update(1)\n","\n","print(\"\\n\\nData preprocessing and splitting completed!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eI8FUFiLOtSX","executionInfo":{"status":"ok","timestamp":1729725228411,"user_tz":-480,"elapsed":35401,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"9eefc83a-e261-4ed4-cd63-3456dd50f460"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing the data...\n"]},{"output_type":"stream","name":"stderr","text":["Progress: 6it [00:35,  5.84s/it]                       "]},{"output_type":"stream","name":"stdout","text":["\n","\n","Data preprocessing and splitting completed!\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["from pyspark.ml.evaluation import RegressionEvaluator\n","from sparkxgb import XGBoostRegressor\n","import time\n","\n","# Model training\n","print(\"Training XGBoost model...\")\n","\n","xgb_regressor = XGBoostRegressor(\n","    featuresCol=\"scaled_features\",\n","    labelCol=\"price\",\n","    maxDepth=8,\n","    eta=0.05,\n","    numRound=200,\n","    objective=\"reg:squarederror\",\n","    treeMethod=\"hist\",\n",")\n","\n","\n","# Before training\n","start_time = time.time()\n","\n","# Training the model\n","model = xgb_regressor.fit(train_df)\n","\n","# Making predictions\n","print(\"Making predictions...\")\n","predictions = model.transform(test_df)\n","\n","# Evaluating the model\n","print(\"Evaluating the model...\")\n","evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n","r2 = evaluator.evaluate(predictions)\n","\n","print(f\"\\nTrain size: {train_df.count()} samples\")\n","print(f\"Test size: {test_df.count()} samples\")\n","print(f\"\\n\\nR-Squared Score (Accuracy): {r2 * 100:.2f}%\")\n","\n","# Calculating total runtime\n","end_time = time.time()\n","total_runtime = (end_time - start_time) / 60\n","print(f\"\\n\\nOverall runtime: {round(total_runtime)} minutes.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NN8olLMNRGjO","outputId":"ab0693b7-ac53-456d-f80e-b3f70ba7801d","executionInfo":{"status":"ok","timestamp":1729732482296,"user_tz":-480,"elapsed":7251245,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training XGBoost model...\n","Making predictions...\n","Evaluating the model...\n","\n","Train size: 240048 samples\n","Test size: 59933 samples\n","\n","\n","R-Squared Score (Accuracy): 91.98%\n","\n","\n","Overall runtime: 121 minutes.\n"]}]},{"cell_type":"code","source":["# Calculating additional metrics\n","mae_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"mae\")\n","mae = mae_evaluator.evaluate(predictions)\n","\n","mse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"mse\")\n","mse = mse_evaluator.evaluate(predictions)\n","\n","rmse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n","rmse = rmse_evaluator.evaluate(predictions)\n","\n","print(\"Additional Metrics:\")\n","print(f\"Mean Absolute Error: {round(mae)}\")\n","print(f\"Mean Squared Error: {round(mse)}\")\n","print(f\"Root Mean Squared Error: {round(rmse)}\")"],"metadata":{"id":"fDJkKyP6RTvf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729733998563,"user_tz":-480,"elapsed":1516269,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"d464feeb-3c35-4162-ab7c-46e660f130c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Additional Metrics:\n","Mean Absolute Error: 2973\n","Mean Squared Error: 27269544\n","Root Mean Squared Error: 5222\n"]}]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"f3YtEeZ1rmct"}},{"cell_type":"markdown","source":["## **Comparison before and after training with `Best Hyper Parameters`**\n"],"metadata":{"id":"XZgfRVFHa94v"}},{"cell_type":"markdown","source":["### <font color='orange'>**Before**</font>\n","**Old parameters  :** `{'maxDepth': 6, 'numRound': 100}`\n","<br></br>\n","R-Squared Score (Accuracy): ***91.84 %***\n","<br></br>\n","**Additional Metrics:**\n","\n","Mean Absolute Error: 3018\n","\n","Root Mean Squared Error: 5268\n","\n"],"metadata":{"id":"b9homCgVbA7u"}},{"cell_type":"markdown","source":["### <font color='yellow'>**After**</font>\n","**Best parameters**  : `{'maxDepth': 8, 'numRound': 200, 'eta': 0.1}`\n","<br></br>\n","R-Squared Score (Accuracy): ***92.75 %***\n","<br></br>\n","**Additional Metrics:**\n","\n","Mean Absolute Error: 2759\n","\n","Root Mean Squared Error: 4964"],"metadata":{"id":"mSjMNt5VbC1D"}}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[{"file_id":"1-U4qBE_z5tjZUFTTCfv2skujXMGBlW8M","timestamp":1727142930071}],"authorship_tag":"ABX9TyNmEvddpnXNjXIcGNEsy6n3"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
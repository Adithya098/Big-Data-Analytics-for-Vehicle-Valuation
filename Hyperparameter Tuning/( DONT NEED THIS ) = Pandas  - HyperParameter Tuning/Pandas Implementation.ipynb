{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMTXkCmzG/lBwTqKADtqrJr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"28811w1_Q3o4","executionInfo":{"status":"ok","timestamp":1729460876584,"user_tz":-480,"elapsed":1824,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"f1956937-5196-48f4-df0c-d72549da7a9e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","tqdm is already installed.\n","\n","gdown is already installed.\n","\n","numpy is already installed.\n","\n","pandas is already installed.\n"]}],"source":["import importlib\n","import subprocess\n","import sys\n","import gc\n","\n","def check_and_install_package(package_name, version=None):\n","    try:\n","        importlib.import_module(package_name)\n","        print(f\"\\n{package_name} is already installed.\")\n","    except ImportError:\n","        print(f\"\\n{package_name} is NOT installed. Installing now...\")\n","        if version:\n","            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", f\"{package_name}=={version}\"])\n","        else:\n","            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n","        print(f\"{package_name} installation completed.\")\n","\n","# List of packages to check along with specific versions if necessary\n","packages = [\n","    {\"name\": \"tqdm\", \"version\": None},\n","    {\"name\": \"gdown\", \"version\": None},\n","    {\"name\": \"numpy\", \"version\": \"1.23.5\"},\n","    {\"name\": \"pandas\", \"version\": None}  # Added pandas\n","]\n","\n","# Check and install packages\n","for package in packages:\n","    check_and_install_package(package[\"name\"], package[\"version\"])\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A9H7FdMaRqNe","executionInfo":{"status":"ok","timestamp":1729460899546,"user_tz":-480,"elapsed":18387,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"7a0a4d08-e885-4765-a4a1-67f204f66754"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","!cp '/content/drive/MyDrive/Big Data Analytics - Project/Datasets/Feature_Engineered_DF.parquet' /content/\n","\n","# Load the parquet file into a pandas DataFrame\n","output_path = '/content/Feature_Engineered_DF.parquet'\n","df = pd.read_parquet(output_path)\n","\n","print(\"The Feature Engineered DataFrame has been loaded successfully.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Ctsfox6RkMH","executionInfo":{"status":"ok","timestamp":1729460933245,"user_tz":-480,"elapsed":16605,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"64cfda04-1e7a-4322-abd5-5c97724a9329"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["The Feature Engineered DataFrame has been loaded successfully.\n"]}]},{"cell_type":"code","source":["df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":324},"id":"MoHwCyw-R3_N","executionInfo":{"status":"ok","timestamp":1729388923165,"user_tz":-480,"elapsed":4,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"40c19858-290c-464e-c4e6-7e9873f2cad9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   fuel_type        body_type         city  city_fuel_economy  days_in_market  \\\n","0   Gasoline  SUV / Crossover      Ontario          20.000000              23   \n","1   Gasoline            Sedan    Elizabeth          22.000000              22   \n","2  Biodiesel     Pickup Truck        Omaha          22.690001              93   \n","3   Gasoline  SUV / Crossover   Clearwater          22.690001             163   \n","4   Gasoline  SUV / Crossover  Chillicothe          18.000000              25   \n","\n","  dealer_zip  engine_displacement engine_type exterior_color  \\\n","0      91761               3500.0          V6           Blue   \n","1      07202               2000.0          I4          Black   \n","2      68134               6700.0          V8          White   \n","3      33763               1500.0          I4          Black   \n","4      64601               3000.0          V6           Blue   \n","\n","   franchise_dealer  ...  major_options_count  hp_x_engine_disp  hp_x_torque  \\\n","0              True  ...                    5              0.18     -0.02369   \n","1             False  ...                    8             -0.04      0.00000   \n","2              True  ...                    5              7.40      0.00003   \n","3              True  ...                    5              0.97      0.50512   \n","4              True  ...                   15              0.08      0.00002   \n","\n","   listed_day listed_month  listed_year  age  resale_value_score  \\\n","0          20            8         2020    0                  32   \n","1          18            8         2020    3                  26   \n","2           9            6         2020    0                  30   \n","3          31            3         2020    0                  30   \n","4          16            8         2020    0                  28   \n","\n","  maintenance_cost  luxury_score  \n","0               41            33  \n","1               38            36  \n","2               46            34  \n","3               37            32  \n","4               45            39  \n","\n","[5 rows x 47 columns]"],"text/html":["\n","  <div id=\"df-1a95edb4-9295-4eff-8d8d-4308f6af6856\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fuel_type</th>\n","      <th>body_type</th>\n","      <th>city</th>\n","      <th>city_fuel_economy</th>\n","      <th>days_in_market</th>\n","      <th>dealer_zip</th>\n","      <th>engine_displacement</th>\n","      <th>engine_type</th>\n","      <th>exterior_color</th>\n","      <th>franchise_dealer</th>\n","      <th>...</th>\n","      <th>major_options_count</th>\n","      <th>hp_x_engine_disp</th>\n","      <th>hp_x_torque</th>\n","      <th>listed_day</th>\n","      <th>listed_month</th>\n","      <th>listed_year</th>\n","      <th>age</th>\n","      <th>resale_value_score</th>\n","      <th>maintenance_cost</th>\n","      <th>luxury_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Gasoline</td>\n","      <td>SUV / Crossover</td>\n","      <td>Ontario</td>\n","      <td>20.000000</td>\n","      <td>23</td>\n","      <td>91761</td>\n","      <td>3500.0</td>\n","      <td>V6</td>\n","      <td>Blue</td>\n","      <td>True</td>\n","      <td>...</td>\n","      <td>5</td>\n","      <td>0.18</td>\n","      <td>-0.02369</td>\n","      <td>20</td>\n","      <td>8</td>\n","      <td>2020</td>\n","      <td>0</td>\n","      <td>32</td>\n","      <td>41</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Gasoline</td>\n","      <td>Sedan</td>\n","      <td>Elizabeth</td>\n","      <td>22.000000</td>\n","      <td>22</td>\n","      <td>07202</td>\n","      <td>2000.0</td>\n","      <td>I4</td>\n","      <td>Black</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>8</td>\n","      <td>-0.04</td>\n","      <td>0.00000</td>\n","      <td>18</td>\n","      <td>8</td>\n","      <td>2020</td>\n","      <td>3</td>\n","      <td>26</td>\n","      <td>38</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Biodiesel</td>\n","      <td>Pickup Truck</td>\n","      <td>Omaha</td>\n","      <td>22.690001</td>\n","      <td>93</td>\n","      <td>68134</td>\n","      <td>6700.0</td>\n","      <td>V8</td>\n","      <td>White</td>\n","      <td>True</td>\n","      <td>...</td>\n","      <td>5</td>\n","      <td>7.40</td>\n","      <td>0.00003</td>\n","      <td>9</td>\n","      <td>6</td>\n","      <td>2020</td>\n","      <td>0</td>\n","      <td>30</td>\n","      <td>46</td>\n","      <td>34</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Gasoline</td>\n","      <td>SUV / Crossover</td>\n","      <td>Clearwater</td>\n","      <td>22.690001</td>\n","      <td>163</td>\n","      <td>33763</td>\n","      <td>1500.0</td>\n","      <td>I4</td>\n","      <td>Black</td>\n","      <td>True</td>\n","      <td>...</td>\n","      <td>5</td>\n","      <td>0.97</td>\n","      <td>0.50512</td>\n","      <td>31</td>\n","      <td>3</td>\n","      <td>2020</td>\n","      <td>0</td>\n","      <td>30</td>\n","      <td>37</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Gasoline</td>\n","      <td>SUV / Crossover</td>\n","      <td>Chillicothe</td>\n","      <td>18.000000</td>\n","      <td>25</td>\n","      <td>64601</td>\n","      <td>3000.0</td>\n","      <td>V6</td>\n","      <td>Blue</td>\n","      <td>True</td>\n","      <td>...</td>\n","      <td>15</td>\n","      <td>0.08</td>\n","      <td>0.00002</td>\n","      <td>16</td>\n","      <td>8</td>\n","      <td>2020</td>\n","      <td>0</td>\n","      <td>28</td>\n","      <td>45</td>\n","      <td>39</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 47 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a95edb4-9295-4eff-8d8d-4308f6af6856')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1a95edb4-9295-4eff-8d8d-4308f6af6856 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1a95edb4-9295-4eff-8d8d-4308f6af6856');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-6ce7b139-beda-4c0a-86dc-bcca3d679714\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6ce7b139-beda-4c0a-86dc-bcca3d679714')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-6ce7b139-beda-4c0a-86dc-bcca3d679714 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"}},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"cgJY2g5wSKZx"}},{"cell_type":"markdown","source":["# **Models**"],"metadata":{"id":"Nt9CqXNvSHcU"}},{"cell_type":"markdown","source":["### **Decision Trees**"],"metadata":{"id":"ILxgFpfNSLj7"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import time\n","import warnings\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.compose import ColumnTransformer\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Ignore warnings\n","warnings.filterwarnings('ignore')\n","\n","# Start tracking overall runtime\n","start_time = time.time()\n","\n","# Combine processing data and model training in the same progress bar\n","with tqdm(total=6, desc=\"Processing and Training\") as pbar:\n","\n","    # Sample 20% of the data from the original df\n","    df_sample = df.sample(frac=0.4, random_state=42)\n","    pbar.update(1)\n","\n","    # Handle categorical columns\n","    cat_columns = df_sample.select_dtypes(include=['object']).columns.tolist()\n","    num_columns = df_sample.select_dtypes(exclude=['object']).columns.tolist()\n","    num_columns.remove('price')  # Exclude the target column 'price'\n","    pbar.update(1)\n","\n","    # Convert 'franchise_dealer' to numeric if it's not already\n","    df_sample['franchise_dealer'] = df_sample['franchise_dealer'].astype(int)\n","\n","    # Prepare the preprocessing pipeline\n","    preprocessor = ColumnTransformer(\n","        transformers=[\n","            ('num', StandardScaler(), num_columns),\n","            ('cat', OneHotEncoder(handle_unknown='ignore'), cat_columns)\n","        ]\n","    )\n","    pbar.update(1)\n","\n","    # Split the data\n","    X = df_sample.drop(columns='price')\n","    y = df_sample['price']\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","    pbar.update(1)\n","\n","    # Apply the preprocessing to the features\n","    X_train_transformed = preprocessor.fit_transform(X_train)\n","    X_test_transformed = preprocessor.transform(X_test)\n","    pbar.update(1)\n","\n","    # Train Decision Tree Regressor model\n","    dt = DecisionTreeRegressor(\n","        max_depth=20,\n","        min_samples_split=10,\n","        min_samples_leaf=5,\n","        random_state=42\n","    )\n","\n","    model = dt.fit(X_train_transformed, y_train)\n","    pbar.update(1)\n","\n","# Make predictions\n","y_pred = model.predict(X_test_transformed)\n","\n","# Evaluate the model\n","r2 = r2_score(y_test, y_pred)\n","\n","# Display results\n","print(f\"\\nTrain size: {len(X_train):,} samples\")\n","print(f\"Test size: {len(X_test):,} samples\")\n","\n","# Multiply R-Squared by 100 for percentage calculation\n","print(f\"\\n\\nR-Squared Score (Accuracy): {r2 * 100:.2f}%\")\n","\n","# Calculate total runtime\n","end_time = time.time()\n","total_runtime = (end_time - start_time) / 60  # Convert seconds to minutes\n","\n","print(f\"\\n\\nOverall runtime: {round(total_runtime)} minutes.\")\n","\n","# Calculate additional metrics\n","mae = mean_absolute_error(y_test, y_pred)\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = np.sqrt(mse)\n","\n","# Output additional metrics\n","print(\"Additional Metrics:\")\n","print(f\"Mean Absolute Error: {round(mae)}\")\n","print(f\"Mean Squared Error: {round(mse)}\")\n","print(f\"Root Mean Squared Error: {round(rmse)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JQBWbeYPSPG1","executionInfo":{"status":"ok","timestamp":1729342058490,"user_tz":-480,"elapsed":522191,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"95552031-b0a8-4c94-dcd6-9a961c6d037a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing and Training: 100%|██████████| 6/6 [08:42<00:00, 87.04s/it] "]},{"output_type":"stream","name":"stdout","text":["\n","Train size: 960,012 samples\n","Test size: 240,004 samples\n","\n","\n","R-Squared Score (Accuracy): 83.21%\n","\n","\n","Overall runtime: 9 minutes.\n","Additional Metrics:\n","Mean Absolute Error: 2666\n","Mean Squared Error: 60784033\n","Root Mean Squared Error: 7796\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import time\n","import warnings\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.compose import ColumnTransformer\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Ignore warnings\n","warnings.filterwarnings('ignore')\n","\n","# Start tracking overall runtime\n","start_time = time.time()\n","\n","# Combine processing data and model training in the same progress bar\n","with tqdm(total=6, desc=\"Processing and Training\") as pbar:\n","\n","    # Sample 20% of the data from the original df\n","    df_sample = df.sample(frac=0.2, random_state=42)\n","    pbar.update(1)\n","\n","    # Handle categorical columns\n","    cat_columns = df_sample.select_dtypes(include=['object']).columns.tolist()\n","    num_columns = df_sample.select_dtypes(exclude=['object']).columns.tolist()\n","    num_columns.remove('price')  # Exclude the target column 'price'\n","    pbar.update(1)\n","\n","    # Convert 'franchise_dealer' to numeric if it's not already\n","    df_sample['franchise_dealer'] = df_sample['franchise_dealer'].astype(int)\n","\n","    # Prepare the preprocessing pipeline\n","    preprocessor = ColumnTransformer(\n","        transformers=[\n","            ('num', StandardScaler(), num_columns),\n","            ('cat', OneHotEncoder(handle_unknown='ignore'), cat_columns)\n","        ]\n","    )\n","    pbar.update(1)\n","\n","    # Split the data\n","    X = df_sample.drop(columns='price')\n","    y = df_sample['price']\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","    pbar.update(1)\n","\n","    # Apply the preprocessing to the features\n","    X_train_transformed = preprocessor.fit_transform(X_train)\n","    X_test_transformed = preprocessor.transform(X_test)\n","    pbar.update(1)\n","\n","    # Train Decision Tree Regressor model\n","    dt = DecisionTreeRegressor(\n","        max_depth=20,\n","        min_samples_split=10,\n","        min_samples_leaf=5,\n","        random_state=42\n","    )\n","\n","    model = dt.fit(X_train_transformed, y_train)\n","    pbar.update(1)\n","\n","# Make predictions\n","y_pred = model.predict(X_test_transformed)\n","\n","# Evaluate the model\n","r2 = r2_score(y_test, y_pred)\n","\n","# Display results\n","print(f\"\\nTrain size: {len(X_train):,} samples\")\n","print(f\"Test size: {len(X_test):,} samples\")\n","\n","# Multiply R-Squared by 100 for percentage calculation\n","print(f\"\\n\\nR-Squared Score (Accuracy): {r2 * 100:.2f}%\")\n","\n","# Calculate total runtime\n","end_time = time.time()\n","total_runtime = (end_time - start_time) / 60  # Convert seconds to minutes\n","\n","print(f\"\\n\\nOverall runtime: {round(total_runtime)} minutes.\")\n","\n","# Calculate additional metrics\n","mae = mean_absolute_error(y_test, y_pred)\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = np.sqrt(mse)\n","\n","# Output additional metrics\n","print(\"Additional Metrics:\")\n","print(f\"Mean Absolute Error: {round(mae)}\")\n","print(f\"Mean Squared Error: {round(mse)}\")\n","print(f\"Root Mean Squared Error: {round(rmse)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rQKiBbtzO0bc","executionInfo":{"status":"ok","timestamp":1729382870588,"user_tz":-480,"elapsed":308569,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"7c7791d7-5ae7-4d52-9ad7-235d1fdf6822"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing and Training: 100%|██████████| 6/6 [04:53<00:00, 48.97s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Train size: 480,006 samples\n","Test size: 120,002 samples\n","\n","\n","R-Squared Score (Accuracy): 71.45%\n","\n","\n","Overall runtime: 5 minutes.\n","Additional Metrics:\n","Mean Absolute Error: 2806\n","Mean Squared Error: 127337218\n","Root Mean Squared Error: 11284\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import time\n","import warnings\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split, ParameterGrid\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.compose import ColumnTransformer\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Ignore warnings\n","warnings.filterwarnings('ignore')\n","\n","# Start tracking overall runtime\n","start_time = time.time()\n","\n","# Combine processing data and model training in the same progress bar\n","with tqdm(total=6, desc=\"Processing and Training\") as pbar:\n","\n","    # Sample 40% of the data from the original df\n","    df_sample = df.sample(frac=0.4, random_state=42)\n","    pbar.update(1)\n","\n","    # Handle categorical columns\n","    cat_columns = df_sample.select_dtypes(include=['object']).columns.tolist()\n","    num_columns = df_sample.select_dtypes(exclude=['object']).columns.tolist()\n","    num_columns.remove('price')  # Exclude the target column 'price'\n","    pbar.update(1)\n","\n","    # Convert 'franchise_dealer' to numeric if it's not already\n","    df_sample['franchise_dealer'] = df_sample['franchise_dealer'].astype(int)\n","\n","    # Prepare the preprocessing pipeline\n","    preprocessor = ColumnTransformer(\n","        transformers=[\n","            ('num', StandardScaler(), num_columns),\n","            ('cat', OneHotEncoder(handle_unknown='ignore'), cat_columns)\n","        ]\n","    )\n","    pbar.update(1)\n","\n","    # Split the data\n","    X = df_sample.drop(columns='price')\n","    y = df_sample['price']\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","    pbar.update(1)\n","\n","    # Apply the preprocessing to the features\n","    X_train_transformed = preprocessor.fit_transform(X_train)\n","    X_test_transformed = preprocessor.transform(X_test)\n","    pbar.update(1)\n","\n","# Define the parameter grid\n","param_grid = {\n","    'max_depth': [10, 20, None],\n","    'min_samples_split': [5, 10, 20],\n","    'min_samples_leaf': [5, 10],\n","    'criterion': ['squared_error', 'absolute_error']\n","}\n","\n","# Custom scorer that prints results immediately along with parameters\n","def custom_scorer(y_true, y_pred, params):\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","\n","    # Print the current parameters and their corresponding metrics\n","    print(f\"\\nParameters: {params}\")\n","    print(f\"Mean Absolute Error: {mae:.2f}\")\n","    print(f\"Root Mean Squared Error: {rmse:.2f}\")\n","    print(f\"R-Squared Score (Accuracy): {r2 * 100:.2f}%\")\n","\n","    return r2  # Return R-squared as the score\n","\n","# Perform manual grid search\n","best_score = -np.inf\n","best_params = None\n","\n","for params in ParameterGrid(param_grid):\n","    dt = DecisionTreeRegressor(random_state=42, **params)\n","    dt.fit(X_train_transformed, y_train)\n","\n","    # Make predictions on the test set\n","    y_pred = dt.predict(X_test_transformed)\n","\n","    # Score and print parameters and metrics\n","    score = custom_scorer(y_test, y_pred, params)\n","\n","    # Update best score and parameters if the current score is better\n","    if score > best_score:\n","        best_score = score\n","        best_params = params\n","\n","# Print best parameters\n","print(f\"\\nBest Parameters: {best_params}\")\n","print(f\"Best R-Squared Score: {best_score * 100:.2f}%\")\n","\n","# Train final model with best parameters\n","best_model = DecisionTreeRegressor(random_state=42, **best_params)\n","best_model.fit(X_train_transformed, y_train)\n","\n","# Final evaluation\n","y_pred = best_model.predict(X_test_transformed)\n","final_r2 = r2_score(y_test, y_pred)\n","final_mae = mean_absolute_error(y_test, y_pred)\n","final_mse = mean_squared_error(y_test, y_pred)\n","final_rmse = np.sqrt(final_mse)\n","\n","print(\"\\nFinal Model Metrics:\")\n","print(f\"R-Squared Score (Accuracy): {final_r2 * 100:.2f}%\")\n","print(f\"Mean Absolute Error: {final_mae:.2f}\")\n","print(f\"Mean Squared Error: {final_mse:.2f}\")\n","print(f\"Root Mean Squared Error: {final_rmse:.2f}\")\n","\n","# Calculate total runtime\n","end_time = time.time()\n","total_runtime = (end_time - start_time) / 60  # Convert seconds to minutes\n","print(f\"\\nOverall runtime: {round(total_runtime)} minutes.\")\n"],"metadata":{"id":"KSwZRhgB2cfd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **XGB**"],"metadata":{"id":"prqzE3zeSqHu"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import warnings\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n","import xgboost as xgb\n","import time\n","\n","# Ignore warnings\n","warnings.filterwarnings('ignore')\n","\n","print(\"Processing the data...\")\n","with tqdm(total=5, desc=\"Progress\") as pbar:\n","\n","    # Sample 10% of the data\n","    df_sample = df.sample(frac=0.4, random_state=42)  # Randomly sample 300k records\n","    pbar.update(1)\n","\n","    # Handle categorical columns\n","    cat_columns = df_sample.select_dtypes(include=['object']).columns.tolist()\n","    num_columns = df_sample.select_dtypes(exclude=['object']).columns.tolist()\n","    num_columns.remove('price')  # Exclude the target column 'price'\n","    pbar.update(1)\n","\n","    # Fill missing numeric values with mean\n","    df_sample[num_columns] = df_sample[num_columns].fillna(df_sample[num_columns].mean())\n","    pbar.update(1)\n","\n","    # Preprocessing pipeline (scaling numeric features and encoding categorical features)\n","    preprocessor = ColumnTransformer(\n","        transformers=[\n","            ('num', StandardScaler(), num_columns),\n","            ('cat', OneHotEncoder(handle_unknown='ignore'), cat_columns)\n","        ]\n","    )\n","\n","    # Split the data\n","    X = df_sample.drop(columns='price')\n","    y = df_sample['price']\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","    pbar.update(1)\n","\n","    # Apply the preprocessor\n","    X_train_transformed = preprocessor.fit_transform(X_train)\n","    X_test_transformed = preprocessor.transform(X_test)\n","    pbar.update(1)\n","\n","print(\"\\n\\nData preprocessing and splitting completed!\")\n","\n","print(f\"Train_DF has {len(X_train):,} rows and {X_train_transformed.shape[1]} columns\")\n","print(\"-------------------------------------------------------------------------------------------------------------------------------\")\n","\n","# Model training\n","print(\"Training XGBoost model...\")\n","\n","# Initialize XGBoostRegressor\n","xgb_regressor = xgb.XGBRegressor(\n","    max_depth=6,\n","    n_estimators=100,\n","    objective='reg:squarederror',\n","    tree_method='hist',\n","    random_state=42\n",")\n","\n","# Track training time\n","start_time = time.time()\n","\n","# Train the model\n","xgb_regressor.fit(X_train_transformed, y_train)\n","\n","# Make predictions\n","y_pred = xgb_regressor.predict(X_test_transformed)\n","\n","# Evaluate the model\n","r2 = r2_score(y_test, y_pred)\n","\n","print(f\"\\nTrain size: {len(X_train):,} samples\")\n","print(f\"Test size: {len(X_test):,} samples\")\n","print(f\"\\n\\nR-Squared Score (Accuracy): {r2 * 100:.2f}%\")\n","\n","# Calculate total runtime\n","end_time = time.time()\n","total_runtime = (end_time - start_time) / 60  # Convert seconds to minutes\n","\n","print(f\"\\n\\nOverall runtime: {round(total_runtime, 2)} minutes.\")\n","print(\"-------------------------------------------------------------------------------------------------------------------------------\")\n","\n","# Calculate additional metrics\n","mae = mean_absolute_error(y_test, y_pred)\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = np.sqrt(mse)\n","\n","print(\"\\nAdditional Metrics:\")\n","print(f\"Mean Absolute Error: {round(mae)}\")\n","print(f\"Mean Squared Error: {round(mse)}\")\n","print(f\"Root Mean Squared Error: {round(rmse)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k1pqcVtFStQ5","executionInfo":{"status":"ok","timestamp":1729341536303,"user_tz":-480,"elapsed":49938,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"6fb95501-8157-4a7a-8c18-2befe32c9072"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing the data...\n"]},{"output_type":"stream","name":"stderr","text":["Progress: 100%|██████████| 5/5 [00:14<00:00,  2.90s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Data preprocessing and splitting completed!\n","Train_DF has 960,012 rows and 39396 columns\n","-------------------------------------------------------------------------------------------------------------------------------\n","Training XGBoost model...\n","\n","Train size: 960,012 samples\n","Test size: 240,004 samples\n","\n","\n","R-Squared Score (Accuracy): 87.34%\n","\n","\n","Overall runtime: 0.58 minutes.\n","-------------------------------------------------------------------------------------------------------------------------------\n","\n","Additional Metrics:\n","Mean Absolute Error: 3021\n","Mean Squared Error: 45804700\n","Root Mean Squared Error: 6768\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n","from sklearn.model_selection import ParameterGrid\n","import numpy as np\n","import time\n","import xgboost as xgb\n","\n","# Define the parameter grid\n","param_grid = {\n","    'max_depth': [3, 6, 9],\n","    'n_estimators': [100, 200, 300],\n","    'learning_rate': [0.01, 0.1, 0.3],\n","    'subsample': [0.8, 1.0],\n","    'colsample_bytree': [0.8, 1.0],\n","    'min_child_weight': [1, 3, 5]\n","}\n","\n","# Track training time\n","start_time = time.time()\n","\n","best_score = -np.inf\n","best_params = None\n","\n","# Manual grid search using ParameterGrid\n","print(\"Performing manual grid search...\")\n","\n","for params in ParameterGrid(param_grid):\n","    # Initialize XGBoostRegressor with the current set of parameters\n","    xgb_regressor = xgb.XGBRegressor(\n","        objective='reg:squarederror',\n","        tree_method='hist',\n","        random_state=42,\n","        **params  # Pass the parameters dynamically\n","    )\n","\n","    # Fit the model\n","    xgb_regressor.fit(X_train_transformed, y_train)\n","\n","    # Make predictions\n","    y_pred = xgb_regressor.predict(X_test_transformed)\n","\n","    # Calculate R2 score for this parameter set\n","    r2 = r2_score(y_test, y_pred)\n","\n","    # Calculate Mean Squared Error (MSE)\n","    mse = mean_squared_error(y_test, y_pred)\n","    rmse = np.sqrt(mse)\n","\n","    # Print the parameters and the metrics for this iteration\n","    print(f\"\\nParameters: {params}\")\n","    print(f\"Mean Test MSE: {mse:.2f}\")\n","    print(f\"Mean Test RMSE: {rmse:.2f}\")\n","    print(f\"R-Squared Score (Accuracy): {r2 * 100:.2f}%\")\n","\n","    # Update the best score and parameters if this iteration is better\n","    if r2 > best_score:\n","        best_score = r2\n","        best_params = params\n","\n","# Print best parameters\n","print(f\"\\nBest Parameters: {best_params}\")\n","print(f\"Best R-Squared Score: {best_score * 100:.2f}%\")\n","\n","# Train final model with best parameters\n","best_model = xgb.XGBRegressor(\n","    objective='reg:squarederror',\n","    tree_method='hist',\n","    random_state=42,\n","    **best_params\n",")\n","best_model.fit(X_train_transformed, y_train)\n","\n","# Final evaluation\n","y_pred = best_model.predict(X_test_transformed)\n","final_r2 = r2_score(y_test, y_pred)\n","final_mae = mean_absolute_error(y_test, y_pred)\n","final_mse = mean_squared_error(y_test, y_pred)\n","final_rmse = np.sqrt(final_mse)\n","\n","# Display final metrics\n","print(\"\\nFinal Model Metrics:\")\n","print(f\"R-Squared Score (Accuracy): {final_r2 * 100:.2f}%\")\n","print(f\"Mean Absolute Error: {final_mae:.2f}\")\n","print(f\"Mean Squared Error: {final_mse:.2f}\")\n","print(f\"Root Mean Squared Error: {final_rmse:.2f}\")\n","\n","# Calculate total runtime\n","end_time = time.time()\n","total_runtime = (end_time - start_time) / 60  # Convert seconds to minutes\n","\n","print(f\"\\nOverall runtime: {round(total_runtime, 2)} minutes.\")\n","print(\"-------------------------------------------------------------------------------------------------------------------------------\")\n"],"metadata":{"id":"LnS2I-ISW7LU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **GBT Regressor**"],"metadata":{"id":"tjdbWapOStol"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import warnings\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.compose import ColumnTransformer\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n","import time\n","\n","# Ignore warnings\n","warnings.filterwarnings('ignore')\n","\n","print(\"Processing the data...\")\n","with tqdm(total=5, desc=\"Progress\") as pbar:\n","\n","    # Sample 20% of the data\n","    df_sample = df.sample(frac=0.4, random_state=42)  # Randomly sample 600k records\n","    pbar.update(1)\n","\n","    # Identify categorical and numerical columns\n","    cat_columns = df_sample.select_dtypes(include=['object']).columns.tolist()\n","    num_columns = df_sample.select_dtypes(exclude=['object']).columns.tolist()\n","    num_columns.remove('price')  # Exclude the target column 'price'\n","    pbar.update(1)\n","\n","    # Fill missing values for numeric columns with mean\n","    df_sample[num_columns] = df_sample[num_columns].fillna(df_sample[num_columns].mean())\n","    pbar.update(1)\n","\n","    # Preprocessing: scale numerical features and one-hot encode categorical features\n","    preprocessor = ColumnTransformer(\n","        transformers=[\n","            ('num', StandardScaler(), num_columns),\n","            ('cat', OneHotEncoder(handle_unknown='ignore'), cat_columns)\n","        ]\n","    )\n","    pbar.update(1)\n","\n","    # Split the data into training and testing sets\n","    X = df_sample.drop(columns='price')\n","    y = df_sample['price']\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","    pbar.update(1)\n","\n","    # Apply the preprocessor to the features\n","    X_train_transformed = preprocessor.fit_transform(X_train)\n","    X_test_transformed = preprocessor.transform(X_test)\n","\n","print(\"\\n\\nData preprocessing and splitting completed!\")\n","\n","# Model training\n","print(\"Training Gradient Boosting Regressor model...\")\n","\n","# Start tracking overall runtime\n","start_time = time.time()\n","\n","# Initialize GradientBoostingRegressor\n","gbt_regressor = GradientBoostingRegressor(\n","    n_estimators=100,\n","    max_depth=5,\n","    random_state=42\n",")\n","\n","# Train the model\n","gbt_regressor.fit(X_train_transformed, y_train)\n","\n","# Make predictions\n","print(\"Making predictions...\")\n","y_pred = gbt_regressor.predict(X_test_transformed)\n","\n","# Evaluate the model\n","r2 = r2_score(y_test, y_pred)\n","\n","print(f\"\\nTrain size: {len(X_train):,} samples\")\n","print(f\"Test size: {len(X_test):,} samples\")\n","print(f\"\\n\\nR-Squared Score (Accuracy): {r2 * 100:.2f}%\")\n","\n","# Calculate total runtime\n","end_time = time.time()\n","total_runtime = (end_time - start_time) / 60  # Convert seconds to minutes\n","\n","print(f\"\\n\\nOverall runtime: {round(total_runtime)} minutes.\")\n","\n","# Calculate additional metrics\n","mae = mean_absolute_error(y_test, y_pred)\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = np.sqrt(mse)\n","\n","print(\"\\nAdditional Metrics:\")\n","print(f\"Mean Absolute Error: {round(mae)}\")\n","print(f\"Mean Squared Error: {round(mse)}\")\n","print(f\"Root Mean Squared Error: {round(rmse)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tIHrChWDS1r-","executionInfo":{"status":"ok","timestamp":1729341486367,"user_tz":-480,"elapsed":1563484,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"8deea42a-9df2-409e-9492-e08592e0b5d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing the data...\n"]},{"output_type":"stream","name":"stderr","text":["Progress: 100%|██████████| 5/5 [00:14<00:00,  2.99s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Data preprocessing and splitting completed!\n","Training Gradient Boosting Regressor model...\n","Making predictions...\n","\n","Train size: 960,012 samples\n","Test size: 240,004 samples\n","\n","\n","R-Squared Score (Accuracy): 85.40%\n","\n","\n","Overall runtime: 26 minutes.\n","\n","Additional Metrics:\n","Mean Absolute Error: 3588\n","Mean Squared Error: 52827087\n","Root Mean Squared Error: 7268\n"]}]},{"cell_type":"markdown","source":["## **Random Forest**"],"metadata":{"id":"rVHz6fhWS2Bj"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import time\n","import warnings\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.compose import ColumnTransformer\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Ignore warnings\n","warnings.filterwarnings('ignore')\n","\n","# Start tracking overall runtime\n","start_time = time.time()\n","\n","# Combine processing data and model training in the same progress bar\n","with tqdm(total=7, desc=\"Processing and Training\") as pbar:\n","\n","    # Sample 20% of the data from the original df\n","    df_sample = df.sample(frac=0.2, random_state=42)\n","    pbar.update(1)\n","\n","    # Remove rows where 'price' is <= 0 (to avoid issues with log transformation)\n","    df_sample = df_sample[df_sample['price'] > 0]\n","\n","    # Log transform the target variable\n","    df_sample['log_price'] = np.log(df_sample['price'])\n","    pbar.update(1)\n","\n","    # Handle categorical columns\n","    cat_columns = df_sample.select_dtypes(include=['object']).columns.tolist()\n","    num_columns = df_sample.select_dtypes(exclude=['object']).columns.tolist()\n","    num_columns.remove('price')\n","    num_columns.remove('log_price')  # Exclude the target columns\n","    pbar.update(1)\n","\n","    # Prepare the preprocessing pipeline\n","    preprocessor = ColumnTransformer(\n","        transformers=[\n","            ('num', StandardScaler(), num_columns),\n","            ('cat', OneHotEncoder(handle_unknown='ignore'), cat_columns)\n","        ]\n","    )\n","    pbar.update(1)\n","\n","    # Split the data into training and test sets\n","    X = df_sample.drop(columns=['price', 'log_price'])\n","    y = df_sample['log_price']\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","    pbar.update(1)\n","\n","    # Apply the preprocessing to the features\n","    X_train_transformed = preprocessor.fit_transform(X_train)\n","    X_test_transformed = preprocessor.transform(X_test)\n","    pbar.update(1)\n","\n","    # Define the RandomForestRegressor model\n","    rf = RandomForestRegressor(\n","        n_estimators=50,\n","        max_depth=10,\n","        min_samples_split=10,\n","        random_state=42\n","    )\n","\n","    # Fit the model to the training data\n","    model = rf.fit(X_train_transformed, y_train)\n","    pbar.update(1)\n","\n","# Make predictions\n","print(\"Making predictions...\")\n","y_pred_log = model.predict(X_test_transformed)\n","\n","# Apply exponential to reverse log transformation\n","y_pred = np.exp(y_pred_log)\n","\n","# Evaluate the model\n","print(\"Evaluating the model...\")\n","r2 = r2_score(np.exp(y_test), y_pred)\n","\n","print(f\"\\n\\nR-Squared Score (Accuracy): {r2 * 100:.2f}%\")\n","\n","# Display results\n","print(f\"\\nTrain size: {len(X_train):,} samples\")\n","print(f\"Test size: {len(X_test):,} samples\")\n","\n","# Calculate total runtime\n","end_time = time.time()\n","total_runtime = (end_time - start_time) / 60  # Convert seconds to minutes\n","\n","print(f\"\\nOverall runtime: {round(total_runtime)} minutes.\")\n","\n","# Calculate additional metrics\n","mae = mean_absolute_error(np.exp(y_test), y_pred)\n","mse = mean_squared_error(np.exp(y_test), y_pred)\n","rmse = np.sqrt(mse)\n","\n","# Output additional metrics\n","print(\"Additional Metrics:\")\n","print(f\"Mean Absolute Error: {round(mae)}\")\n","print(f\"Mean Squared Error: {round(mse)}\")\n","print(f\"Root Mean Squared Error: {round(rmse)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EUbaLsESTAan","executionInfo":{"status":"ok","timestamp":1729337847823,"user_tz":-480,"elapsed":2349203,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"2ed1e68a-2a5d-4ca3-9487-29daef1e252e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing and Training: 100%|██████████| 7/7 [39:04<00:00, 334.87s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Making predictions...\n","Evaluating the model...\n","\n","\n","R-Squared Score (Accuracy): 68.44%\n","\n","Train size: 480,006 samples\n","Test size: 120,002 samples\n","\n","Overall runtime: 39 minutes.\n","Additional Metrics:\n","Mean Absolute Error: 3569\n","Mean Squared Error: 140793917\n","Root Mean Squared Error: 11866\n"]}]},{"cell_type":"markdown","source":["## **Linear Regression**"],"metadata":{"id":"mV9nQ18ETBXf"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import time\n","import warnings\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.compose import ColumnTransformer\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Ignore warnings\n","warnings.filterwarnings('ignore')\n","\n","# Start tracking overall runtime\n","start_time = time.time()\n","\n","# Combine processing data and model training in the same progress bar\n","with tqdm(total=6, desc=\"Processing and Training\") as pbar:\n","\n","    # Sample 20% of the data\n","    df_sample = df.sample(frac=0.4, random_state=42)\n","    pbar.update(1)\n","\n","    # Handle categorical columns\n","    cat_columns = df_sample.select_dtypes(include=['object']).columns.tolist()\n","    num_columns = df_sample.select_dtypes(exclude=['object']).columns.tolist()\n","    num_columns.remove('price')  # Exclude the target column 'price'\n","    pbar.update(1)\n","\n","    # Convert 'franchise_dealer' to numeric if necessary\n","    df_sample['franchise_dealer'] = df_sample['franchise_dealer'].astype(int)\n","\n","    # Preprocessing pipeline\n","    preprocessor = ColumnTransformer(\n","        transformers=[\n","            ('num', StandardScaler(), num_columns),\n","            ('cat', OneHotEncoder(handle_unknown='ignore'), cat_columns)\n","        ]\n","    )\n","    pbar.update(1)\n","\n","    # Split the data into training and test sets\n","    X = df_sample.drop(columns='price')\n","    y = df_sample['price']\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","    pbar.update(1)\n","\n","    # Apply the preprocessing pipeline\n","    X_train_transformed = preprocessor.fit_transform(X_train)\n","    X_test_transformed = preprocessor.transform(X_test)\n","    pbar.update(1)\n","\n","    # Train Linear Regression model\n","    lr = LinearRegression()\n","    model = lr.fit(X_train_transformed, y_train)\n","    pbar.update(1)\n","\n","# Make predictions\n","print(\"Making predictions...\")\n","y_pred = model.predict(X_test_transformed)\n","\n","# Evaluate the model\n","r2 = r2_score(y_test, y_pred)\n","\n","# Display results\n","print(f\"\\nTrain size: {len(X_train):,} samples\")\n","print(f\"Test size: {len(X_test):,} samples\")\n","\n","# Multiply R-Squared by 100 for percentage calculation\n","print(f\"\\n\\nR-Squared Score (Accuracy): {r2 * 100:.2f}%\")\n","\n","# Calculate total runtime\n","end_time = time.time()\n","total_runtime = (end_time - start_time) / 60  # Convert seconds to minutes\n","\n","print(f\"\\nOverall runtime: {round(total_runtime)} minutes.\")\n","\n","# Calculate additional metrics\n","mae = mean_absolute_error(y_test, y_pred)\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = np.sqrt(mse)\n","\n","# Output additional metrics\n","print(\"Additional Metrics:\")\n","print(f\"Mean Absolute Error: {round(mae)}\")\n","print(f\"Mean Squared Error: {round(mse)}\")\n","print(f\"Root Mean Squared Error: {round(rmse)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WyArFV5eTFYz","executionInfo":{"status":"ok","timestamp":1729339922886,"user_tz":-480,"elapsed":806269,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"8ea083b9-961e-43c7-ff19-117ae286e7ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing and Training: 100%|██████████| 6/6 [13:25<00:00, 134.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Making predictions...\n","\n","Train size: 960,012 samples\n","Test size: 240,004 samples\n","\n","\n","R-Squared Score (Accuracy): 81.86%\n","\n","Overall runtime: 13 minutes.\n","Additional Metrics:\n","Mean Absolute Error: 4059\n","Mean Squared Error: 65651380\n","Root Mean Squared Error: 8103\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}
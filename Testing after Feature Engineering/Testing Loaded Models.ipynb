{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOO5Cx4vyMfXqTVNonP7Lh5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import importlib\n","import subprocess\n","import sys\n","import gc\n","\n","def check_and_install_package(package_name):\n","    try:\n","        importlib.import_module(package_name)\n","        print(f\"\\n{package_name} is already installed.\")\n","    except ImportError:\n","        print(f\"\\n{package_name} is NOT installed. Installing now...\")\n","        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n","        print(f\"{package_name} installation completed.\")\n","\n","# List of packages to check\n","packages = [\n","    \"tqdm\",\n","    \"dask\",\n","    \"nltk\",\n","    \"scikit-learn\",\n","    \"numpy\",\n","    \"pyspark\",\n","    \"gdown\"\n","]\n","\n","# Checking and installing the packages\n","for package in packages:\n","    check_and_install_package(package)\n"],"metadata":{"id":"2PDESIoKa-mc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730211109330,"user_tz":-480,"elapsed":8421,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"0935a430-9e00-4a6e-afa7-9d32ee0b945b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","tqdm is already installed.\n","\n","dask is already installed.\n","\n","nltk is already installed.\n","\n","scikit-learn is NOT installed. Installing now...\n","scikit-learn installation completed.\n","\n","numpy is already installed.\n","\n","pyspark is already installed.\n","\n","gdown is already installed.\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"ixBwcMWRa_kx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730211132608,"user_tz":-480,"elapsed":21699,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"ebbbb9cb-758b-43c1-de4e-50dac583fb3c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder \\\n","    .appName(\"RandomForestModel\") \\\n","    .config(\"spark.driver.memory\", \"16g\") \\\n","    .config(\"spark.executor.memory\", \"16g\") \\\n","    .config(\"spark.driver.maxResultSize\", \"8g\") \\\n","    .config(\"spark.executor.memoryOverhead\", \"12g\") \\\n","    .config(\"spark.executor.cores\", \"5\") \\\n","    .config(\"spark.kryoserializer.buffer.max\", \"2047m\") \\\n","    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n","    .config(\"spark.dynamicAllocation.enabled\", \"true\") \\\n","    .config(\"spark.hadoop.fs.file.impl\", \"org.apache.hadoop.fs.LocalFileSystem\") \\\n","    .config(\"spark.executor.extraJavaOptions\", \"-XX:+UseG1GC -XX:InitiatingHeapOccupancyPercent=35 -XX:ConcGCThreads=4 -XX:ParallelGCThreads=4\") \\\n","    .getOrCreate()\n","\n","# Verifying Spark session creation\n","print(f\"Spark session started with version: {spark.version}\")"],"metadata":{"id":"i7oRpvojbCW5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730211138499,"user_tz":-480,"elapsed":5893,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"c9a35b2c-2c61-400e-ce45-8ed816a3dcfc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Spark session started with version: 3.5.3\n"]}]},{"cell_type":"code","source":["!cp '/content/drive/MyDrive/Big Data Analytics - Project/Datasets/Feature_Engineered_DF.parquet' /content/\n","\n","output_path = '/content/Feature_Engineered_DF.parquet'\n","df = spark.read.parquet(output_path)\n","print(\"The Feature Engineered DataFrame has been loaded successfully.\")\n"],"metadata":{"id":"pJD4kVNMbG6_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730211149958,"user_tz":-480,"elapsed":11461,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"577b9e46-abb5-4eb2-9417-00104d9699f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The Feature Engineered DataFrame has been loaded successfully.\n"]}]},{"cell_type":"code","source":["# Printing the shape of the DataFrame\n","total_rows = df.count()\n","total_columns = len(df.columns)\n","\n","print(f\"The shape of the loaded DataFrame is: ({total_rows}, {total_columns})\")"],"metadata":{"id":"N5nNky2pbJAT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730211151615,"user_tz":-480,"elapsed":1659,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"386d9334-db80-49fb-d84b-d8d97f376aac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The shape of the loaded DataFrame is: (3000040, 47)\n"]}]},{"cell_type":"code","source":["# Calculating the average price\n","avg_price = df.agg({\"price\": \"avg\"}).collect()[0][0]\n","print(f\"Average price of a car: {round(avg_price)}\")"],"metadata":{"id":"r5ZS-jmQbLLL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730211152700,"user_tz":-480,"elapsed":1087,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"3c1f8475-e270-4438-d3fc-339a341a4e00"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average price of a car: 29933\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from IPython.display import display\n","import pyspark.sql.functions as F\n","\n","# Converting the Spark DataFrame to a Pandas DataFrame and displaying the first 5 rows\n","pd.set_option('display.max_columns', None)\n","pandas_df = df.orderBy(F.rand()).limit(5).toPandas()\n","display(pandas_df)\n"],"metadata":{"id":"7qHGkV1nbMpq","colab":{"base_uri":"https://localhost:8080/","height":382},"executionInfo":{"status":"ok","timestamp":1730211161958,"user_tz":-480,"elapsed":9260,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"e13457f2-30ff-4b0c-ff9e-83cb3ffa99be"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["           fuel_type        body_type             city  city_fuel_economy  \\\n","0           Gasoline     Pickup Truck      San Antonio               21.0   \n","1           Gasoline  SUV / Crossover          Norwood               21.0   \n","2           Gasoline  SUV / Crossover          Kenmore               15.0   \n","3           Gasoline  SUV / Crossover  Brooklyn Center               26.0   \n","4  Flex Fuel Vehicle          Minivan        Rio Linda               17.0   \n","\n","   days_in_market dealer_zip  engine_displacement engine_type exterior_color  \\\n","0               3      78238               2300.0          I4           Blue   \n","1               6      02062               2000.0          I4         Silver   \n","2              54      14217               3600.0          V6          Other   \n","3             131      55429               1300.0          I3          Other   \n","4              14      95673               3600.0          V6          Beige   \n","\n","   franchise_dealer  fuel_tank_volume  height  highway_fuel_economy  \\\n","0              True              18.0    71.2                  26.0   \n","1              True              16.6    66.3                  27.0   \n","2              True              22.0    69.9                  22.0   \n","3              True              13.2    64.1                  29.0   \n","4             False              20.0    67.9                  25.0   \n","\n","   horsepower interior_color  is_new   latitude  length listing_color  \\\n","0       270.0          Black    True  29.454000   210.8          BLUE   \n","1       247.0          Other   False  42.193699   188.9        SILVER   \n","2       281.0          Other   False  42.972000   203.7          GRAY   \n","3       150.0          Black    True  45.077702   171.4       UNKNOWN   \n","4       283.0          Other   False  38.680000   202.8         BROWN   \n","\n","    longitude   make_name  maximum_seating         model_name    price  \\\n","0  -98.628799        Ford              5.0             Ranger  31830.0   \n","1  -71.184097  Land Rover              5.0  Range Rover Velar  59900.0   \n","2  -78.871201   Chevrolet              8.0           Traverse  17888.0   \n","3  -93.334702       Buick              5.0          Encore GX  24975.0   \n","4 -121.481003    Chrysler              7.0     Town & Country  19590.0   \n","\n","   savings_amount  seller_rating                               sp_name  \\\n","0               0       3.583333                     McCombs Ford West   \n","1            4025       4.857143                    Land Rover Norwood   \n","2            1936       4.347826                     Paddock Chevrolet   \n","3               0       4.538462  Luther Brookdale Chevrolet Buick GMC   \n","4            2456       3.666667                               Carvana   \n","\n","   torque transmission transmission_display wheel_system_display  wheelbase  \\\n","0  265.22            A            Automatic                  4X2      126.8   \n","1  269.00            A    8-Speed Automatic      All-Wheel Drive      113.1   \n","2  266.00            A            Automatic    Front-Wheel Drive      118.9   \n","3  174.00            A            Automatic     Four-Wheel Drive      102.2   \n","4  260.00            A    6-Speed Automatic    Front-Wheel Drive      121.2   \n","\n","   width  manufactured_year  combined_fuel_economy  legroom  log_mileage  \\\n","0   85.8               2020                   23.5     77.6         8.91   \n","1   84.4               2020                   24.0     77.3         9.18   \n","2   78.5               2017                   18.5     78.1        10.66   \n","3   71.4               2020                   27.5     76.9         8.91   \n","4   88.5               2016                   21.0     77.2        10.61   \n","\n","   major_options_count  hp_x_engine_disp  hp_x_torque  listed_day  \\\n","0                    5             -0.12      0.00000           8   \n","1                   10              0.00     -0.00023           3   \n","2                    5              0.19      0.00273          18   \n","3                    1              1.39      0.93144           3   \n","4                    4              0.20     -0.01933          28   \n","\n","   listed_month  listed_year  age  resale_value_score  maintenance_cost  \\\n","0             9         2020    0                  31                40   \n","1             9         2020    0                  34                43   \n","2             7         2020    3                  20                38   \n","3             5         2020    0                  22                35   \n","4             8         2020    4                  23                37   \n","\n","   luxury_score  \n","0            33  \n","1            41  \n","2            33  \n","3            30  \n","4            32  "],"text/html":["\n","  <div id=\"df-60483394-8d4b-4a9c-83a9-d69633fa78d8\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fuel_type</th>\n","      <th>body_type</th>\n","      <th>city</th>\n","      <th>city_fuel_economy</th>\n","      <th>days_in_market</th>\n","      <th>dealer_zip</th>\n","      <th>engine_displacement</th>\n","      <th>engine_type</th>\n","      <th>exterior_color</th>\n","      <th>franchise_dealer</th>\n","      <th>fuel_tank_volume</th>\n","      <th>height</th>\n","      <th>highway_fuel_economy</th>\n","      <th>horsepower</th>\n","      <th>interior_color</th>\n","      <th>is_new</th>\n","      <th>latitude</th>\n","      <th>length</th>\n","      <th>listing_color</th>\n","      <th>longitude</th>\n","      <th>make_name</th>\n","      <th>maximum_seating</th>\n","      <th>model_name</th>\n","      <th>price</th>\n","      <th>savings_amount</th>\n","      <th>seller_rating</th>\n","      <th>sp_name</th>\n","      <th>torque</th>\n","      <th>transmission</th>\n","      <th>transmission_display</th>\n","      <th>wheel_system_display</th>\n","      <th>wheelbase</th>\n","      <th>width</th>\n","      <th>manufactured_year</th>\n","      <th>combined_fuel_economy</th>\n","      <th>legroom</th>\n","      <th>log_mileage</th>\n","      <th>major_options_count</th>\n","      <th>hp_x_engine_disp</th>\n","      <th>hp_x_torque</th>\n","      <th>listed_day</th>\n","      <th>listed_month</th>\n","      <th>listed_year</th>\n","      <th>age</th>\n","      <th>resale_value_score</th>\n","      <th>maintenance_cost</th>\n","      <th>luxury_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Gasoline</td>\n","      <td>Pickup Truck</td>\n","      <td>San Antonio</td>\n","      <td>21.0</td>\n","      <td>3</td>\n","      <td>78238</td>\n","      <td>2300.0</td>\n","      <td>I4</td>\n","      <td>Blue</td>\n","      <td>True</td>\n","      <td>18.0</td>\n","      <td>71.2</td>\n","      <td>26.0</td>\n","      <td>270.0</td>\n","      <td>Black</td>\n","      <td>True</td>\n","      <td>29.454000</td>\n","      <td>210.8</td>\n","      <td>BLUE</td>\n","      <td>-98.628799</td>\n","      <td>Ford</td>\n","      <td>5.0</td>\n","      <td>Ranger</td>\n","      <td>31830.0</td>\n","      <td>0</td>\n","      <td>3.583333</td>\n","      <td>McCombs Ford West</td>\n","      <td>265.22</td>\n","      <td>A</td>\n","      <td>Automatic</td>\n","      <td>4X2</td>\n","      <td>126.8</td>\n","      <td>85.8</td>\n","      <td>2020</td>\n","      <td>23.5</td>\n","      <td>77.6</td>\n","      <td>8.91</td>\n","      <td>5</td>\n","      <td>-0.12</td>\n","      <td>0.00000</td>\n","      <td>8</td>\n","      <td>9</td>\n","      <td>2020</td>\n","      <td>0</td>\n","      <td>31</td>\n","      <td>40</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Gasoline</td>\n","      <td>SUV / Crossover</td>\n","      <td>Norwood</td>\n","      <td>21.0</td>\n","      <td>6</td>\n","      <td>02062</td>\n","      <td>2000.0</td>\n","      <td>I4</td>\n","      <td>Silver</td>\n","      <td>True</td>\n","      <td>16.6</td>\n","      <td>66.3</td>\n","      <td>27.0</td>\n","      <td>247.0</td>\n","      <td>Other</td>\n","      <td>False</td>\n","      <td>42.193699</td>\n","      <td>188.9</td>\n","      <td>SILVER</td>\n","      <td>-71.184097</td>\n","      <td>Land Rover</td>\n","      <td>5.0</td>\n","      <td>Range Rover Velar</td>\n","      <td>59900.0</td>\n","      <td>4025</td>\n","      <td>4.857143</td>\n","      <td>Land Rover Norwood</td>\n","      <td>269.00</td>\n","      <td>A</td>\n","      <td>8-Speed Automatic</td>\n","      <td>All-Wheel Drive</td>\n","      <td>113.1</td>\n","      <td>84.4</td>\n","      <td>2020</td>\n","      <td>24.0</td>\n","      <td>77.3</td>\n","      <td>9.18</td>\n","      <td>10</td>\n","      <td>0.00</td>\n","      <td>-0.00023</td>\n","      <td>3</td>\n","      <td>9</td>\n","      <td>2020</td>\n","      <td>0</td>\n","      <td>34</td>\n","      <td>43</td>\n","      <td>41</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Gasoline</td>\n","      <td>SUV / Crossover</td>\n","      <td>Kenmore</td>\n","      <td>15.0</td>\n","      <td>54</td>\n","      <td>14217</td>\n","      <td>3600.0</td>\n","      <td>V6</td>\n","      <td>Other</td>\n","      <td>True</td>\n","      <td>22.0</td>\n","      <td>69.9</td>\n","      <td>22.0</td>\n","      <td>281.0</td>\n","      <td>Other</td>\n","      <td>False</td>\n","      <td>42.972000</td>\n","      <td>203.7</td>\n","      <td>GRAY</td>\n","      <td>-78.871201</td>\n","      <td>Chevrolet</td>\n","      <td>8.0</td>\n","      <td>Traverse</td>\n","      <td>17888.0</td>\n","      <td>1936</td>\n","      <td>4.347826</td>\n","      <td>Paddock Chevrolet</td>\n","      <td>266.00</td>\n","      <td>A</td>\n","      <td>Automatic</td>\n","      <td>Front-Wheel Drive</td>\n","      <td>118.9</td>\n","      <td>78.5</td>\n","      <td>2017</td>\n","      <td>18.5</td>\n","      <td>78.1</td>\n","      <td>10.66</td>\n","      <td>5</td>\n","      <td>0.19</td>\n","      <td>0.00273</td>\n","      <td>18</td>\n","      <td>7</td>\n","      <td>2020</td>\n","      <td>3</td>\n","      <td>20</td>\n","      <td>38</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Gasoline</td>\n","      <td>SUV / Crossover</td>\n","      <td>Brooklyn Center</td>\n","      <td>26.0</td>\n","      <td>131</td>\n","      <td>55429</td>\n","      <td>1300.0</td>\n","      <td>I3</td>\n","      <td>Other</td>\n","      <td>True</td>\n","      <td>13.2</td>\n","      <td>64.1</td>\n","      <td>29.0</td>\n","      <td>150.0</td>\n","      <td>Black</td>\n","      <td>True</td>\n","      <td>45.077702</td>\n","      <td>171.4</td>\n","      <td>UNKNOWN</td>\n","      <td>-93.334702</td>\n","      <td>Buick</td>\n","      <td>5.0</td>\n","      <td>Encore GX</td>\n","      <td>24975.0</td>\n","      <td>0</td>\n","      <td>4.538462</td>\n","      <td>Luther Brookdale Chevrolet Buick GMC</td>\n","      <td>174.00</td>\n","      <td>A</td>\n","      <td>Automatic</td>\n","      <td>Four-Wheel Drive</td>\n","      <td>102.2</td>\n","      <td>71.4</td>\n","      <td>2020</td>\n","      <td>27.5</td>\n","      <td>76.9</td>\n","      <td>8.91</td>\n","      <td>1</td>\n","      <td>1.39</td>\n","      <td>0.93144</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>2020</td>\n","      <td>0</td>\n","      <td>22</td>\n","      <td>35</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Flex Fuel Vehicle</td>\n","      <td>Minivan</td>\n","      <td>Rio Linda</td>\n","      <td>17.0</td>\n","      <td>14</td>\n","      <td>95673</td>\n","      <td>3600.0</td>\n","      <td>V6</td>\n","      <td>Beige</td>\n","      <td>False</td>\n","      <td>20.0</td>\n","      <td>67.9</td>\n","      <td>25.0</td>\n","      <td>283.0</td>\n","      <td>Other</td>\n","      <td>False</td>\n","      <td>38.680000</td>\n","      <td>202.8</td>\n","      <td>BROWN</td>\n","      <td>-121.481003</td>\n","      <td>Chrysler</td>\n","      <td>7.0</td>\n","      <td>Town &amp; Country</td>\n","      <td>19590.0</td>\n","      <td>2456</td>\n","      <td>3.666667</td>\n","      <td>Carvana</td>\n","      <td>260.00</td>\n","      <td>A</td>\n","      <td>6-Speed Automatic</td>\n","      <td>Front-Wheel Drive</td>\n","      <td>121.2</td>\n","      <td>88.5</td>\n","      <td>2016</td>\n","      <td>21.0</td>\n","      <td>77.2</td>\n","      <td>10.61</td>\n","      <td>4</td>\n","      <td>0.20</td>\n","      <td>-0.01933</td>\n","      <td>28</td>\n","      <td>8</td>\n","      <td>2020</td>\n","      <td>4</td>\n","      <td>23</td>\n","      <td>37</td>\n","      <td>32</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60483394-8d4b-4a9c-83a9-d69633fa78d8')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-60483394-8d4b-4a9c-83a9-d69633fa78d8 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-60483394-8d4b-4a9c-83a9-d69633fa78d8');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-9989b4ae-27f5-45fd-ae11-a1d50ec40ad3\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9989b4ae-27f5-45fd-ae11-a1d50ec40ad3')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-9989b4ae-27f5-45fd-ae11-a1d50ec40ad3 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_2bb641ab-437d-4d63-bcff-af55983e0de9\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pandas_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_2bb641ab-437d-4d63-bcff-af55983e0de9 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('pandas_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"pandas_df"}},"metadata":{}}]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"WgsFlpF-bY1t"}},{"cell_type":"markdown","source":["## **Random Forest**"],"metadata":{"id":"iLXgNnYkaf7N"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pmgPFiEzaSE6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3c442c25-f934-4aea-d15b-ed524e598809","executionInfo":{"status":"ok","timestamp":1730204768914,"user_tz":-480,"elapsed":20855,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Processing Test Data: 100%|██████████| 5/5 [00:20<00:00,  4.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Data preprocessing for test data completed.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["from pyspark.sql import SparkSession\n","from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, OneHotEncoder\n","from pyspark.ml import Pipeline\n","from pyspark.ml.regression import RandomForestRegressionModel\n","from pyspark.ml.evaluation import RegressionEvaluator\n","import pyspark.sql.functions as F\n","from tqdm import tqdm\n","import warnings\n","import time\n","\n","# Start to track runtime\n","start_time = time.time()\n","\n","# Processing and preparing the test data\n","with tqdm(total=5, desc=\"Processing Test Data\") as pbar:\n","\n","    # Random sampling 20% of the data (or use the same fraction as training if needed)\n","    df_sample = df.sample(fraction=0.2, seed=42)\n","    pbar.update(1)\n","\n","    # Filtering out rows where 'price' <= 0 to avoid log transformation issues\n","    df_sample = df_sample.filter(F.col(\"price\") > 0)\n","\n","    # Log transforming the target variable\n","    df_sample = df_sample.withColumn(\"log_price\", F.log(\"price\"))\n","    pbar.update(1)\n","\n","    # Handling categorical columns\n","    cat_columns = [field for (field, dtype) in df_sample.dtypes if dtype == \"string\"]\n","    stages = []\n","    for col_name in cat_columns:\n","        indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_indexed\", handleInvalid=\"keep\")\n","        encoder = OneHotEncoder(inputCol=f\"{col_name}_indexed\", outputCol=f\"{col_name}_encoded\")\n","        stages += [indexer, encoder]\n","    pbar.update(1)\n","\n","    # Convert 'franchise_dealer' to numeric if applicable\n","    df_sample = df_sample.withColumn(\"franchise_dealer\", F.col(\"franchise_dealer\").cast(\"int\"))\n","\n","    # Assemble features (ensure all columns used in 'VectorAssembler' are numeric)\n","    num_columns = [col for col in df_sample.columns if col not in ['price', 'log_price'] + cat_columns]\n","    encoded_columns = [f\"{col}_encoded\" for col in cat_columns]\n","    feature_columns = num_columns + encoded_columns\n","    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n","    stages += [assembler]\n","\n","    # Adding scaling to the pipeline (scaling the assembled feature vectors)\n","    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n","    stages += [scaler]\n","\n","    # Creating and applying the pipeline\n","    pipeline = Pipeline(stages=stages)\n","    pipeline_model = pipeline.fit(df_sample)\n","    df_sample = pipeline_model.transform(df_sample)\n","    pbar.update(1)\n","\n","    # Splitting the data into training and test sets\n","    _, test_df = df_sample.randomSplit([0.8, 0.2], seed=42)  # only keeping test_df here for evaluation\n","    pbar.update(1)\n","\n","print(\"Data preprocessing for test data completed.\")\n"]},{"cell_type":"code","source":["# Path where the model is saved\n","saved_model_path = \"/content/drive/MyDrive/Big Data Analytics - Project/models/Random_Forest_model_FE\"\n","\n","# Load the saved Random Forest model\n","loaded_model = RandomForestRegressionModel.load(saved_model_path)\n","print(f\"Model loaded successfully from {saved_model_path}\")\n","\n","# Make predictions on the test data\n","print(\"Making predictions with the loaded model on test data...\")\n","predictions = loaded_model.transform(test_df)\n","\n","# Exponentiate predictions to get them back in the original scale\n","predictions = predictions.withColumn(\"exp_prediction\", F.exp(\"prediction\"))\n","\n","# Evaluate the loaded model\n","print(\"Evaluating the loaded model...\")\n","\n","# R2 Score\n","evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"exp_prediction\", metricName=\"r2\")\n","r2 = evaluator.evaluate(predictions)\n","print(f\"\\nR-Squared Score (Accuracy): {r2 * 100:.2f}%\")\n","\n","# Additional metrics\n","mae_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"exp_prediction\", metricName=\"mae\")\n","mae = mae_evaluator.evaluate(predictions)\n","\n","mse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"exp_prediction\", metricName=\"mse\")\n","mse = mse_evaluator.evaluate(predictions)\n","\n","rmse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"exp_prediction\", metricName=\"rmse\")\n","rmse = rmse_evaluator.evaluate(predictions)\n","\n","print(\"\\nAdditional Metrics:\")\n","print(f\"Mean Absolute Error: {round(mae)}\")\n","print(f\"Mean Squared Error: {round(mse)}\")\n","print(f\"Root Mean Squared Error: {round(rmse)}\")"],"metadata":{"id":"_xWcA_IGbU-t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730170767385,"user_tz":-480,"elapsed":469,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"35537f44-7717-4e21-e188-f3573bf63196"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model loaded successfully from /content/drive/MyDrive/Big Data Analytics - Project/models/Random_Forest_model_FE\n","Making predictions with the loaded model on test data...\n","Evaluating the loaded model...\n","\n","R-Squared Score (Accuracy): 86.35%\n","\n","Additional Metrics:\n","Mean Absolute Error: 3488\n","Mean Squared Error: 44980420\n","Root Mean Squared Error: 6707\n"]}]},{"cell_type":"code","source":["# Path where the model is saved\n","saved_model_path = \"/content/drive/MyDrive/Big Data Analytics - Project/models/Random_Forest_model_FE\"\n","\n","# Load the saved Random Forest model\n","loaded_model = RandomForestRegressionModel.load(saved_model_path)\n","\n","# Make predictions on the test data\n","predictions = loaded_model.transform(test_df)\n","\n","# Exponentiate predictions to get them back in the original scale\n","predictions = predictions.withColumn(\"exp_prediction\", F.exp(\"prediction\"))\n","\n","# Calculate Mean Absolute Percentage Error (MAPE)\n","mape = predictions.withColumn(\"percentage_error\", F.abs((F.col(\"price\") - F.col(\"exp_prediction\")) / F.col(\"price\")) * 100)\n","mape_value = mape.select(F.mean(\"percentage_error\")).collect()[0][0]\n","\n","# Calculate Symmetric Mean Absolute Percentage Error (SMAPE)\n","smape = predictions.withColumn(\n","    \"smape_error\",\n","    F.abs(F.col(\"price\") - F.col(\"exp_prediction\")) / ((F.abs(F.col(\"price\")) + F.abs(F.col(\"exp_prediction\"))) / 2) * 100\n",")\n","smape_value = smape.select(F.mean(\"smape_error\")).collect()[0][0]\n","\n","print(f\"Mean Absolute Percentage Error (MAPE): {round(mape_value, 2)}%\")\n","print(f\"Symmetric Mean Absolute Percentage Error (SMAPE): {round(smape_value, 2)}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"swA43uZbHhHQ","executionInfo":{"status":"ok","timestamp":1730198228014,"user_tz":-480,"elapsed":475981,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"8cf5f599-c458-4731-8e50-f8e2aebd8fa7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Absolute Percentage Error (MAPE): 12.1%\n","Symmetric Mean Absolute Percentage Error (SMAPE): 11.8%\n"]}]},{"cell_type":"code","source":["from pyspark.sql import functions as F\n","\n","# Path where the model is saved\n","saved_model_path = \"/content/drive/MyDrive/Big Data Analytics - Project/models/Random_Forest_model_FE\"\n","\n","# Load the saved Random Forest model\n","loaded_model = RandomForestRegressionModel.load(saved_model_path)\n","\n","# Make predictions on the test data\n","predictions = loaded_model.transform(test_df)\n","\n","# Exponentiate predictions to get them back in the original scale\n","predictions = predictions.withColumn(\"exp_prediction\", F.exp(\"prediction\"))\n","\n","# Define error ranges for the distribution table up to 100%\n","error_ranges = {\n","    \"0-10%\": (0.0, 0.10),\n","    \"10-20%\": (0.10, 0.20),\n","    \"20-30%\": (0.20, 0.30),\n","    \"30-40%\": (0.30, 0.40),\n","    \"40-50%\": (0.40, 0.50),\n","    \"50-60%\": (0.50, 0.60),\n","    \"60-70%\": (0.60, 0.70),\n","    \"70-80%\": (0.70, 0.80),\n","    \"80-90%\": (0.80, 0.90),\n","    \"90-100%\": (0.90, 1.0)\n","}\n","\n","distribution_results = {}\n","\n","# Calculate the distribution for each error range\n","for label, (lower, upper) in error_ranges.items():\n","    within_range = predictions.withColumn(\n","        \"in_range\",\n","        F.when(\n","            (F.abs((F.col(\"price\") - F.col(\"exp_prediction\")) / F.col(\"price\")) >= lower) &\n","            (F.abs((F.col(\"price\") - F.col(\"exp_prediction\")) / F.col(\"price\")) < upper),\n","            1\n","        ).otherwise(0)\n","    )\n","\n","    percentage_in_range = within_range.agg(F.mean(\"in_range\")).collect()[0][0] * 100\n","\n","    distribution_results[label] = percentage_in_range\n","\n","# Print the distribution table\n","print(\"Error Range Distribution Table for Random Forest:\\n\")\n","print(f\"{'Error Range':<15} | {'Percentage of Total Predictions (%)':<10}\")\n","print(\"-\" * 50)\n","for error_range, percentage in distribution_results.items():\n","    print(f\"{error_range:<15} | {percentage:<10.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ItZF5V3w0tdm","executionInfo":{"status":"ok","timestamp":1730210738770,"user_tz":-480,"elapsed":2258911,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"04dc7e8c-578e-4fd9-999c-1a3c24fec976"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error Range Distribution Table for Random Forest:\n","\n","Error Range     | Percentage of Total Predictions (%)\n","--------------------------------------------------\n","0-10%           | 54.00     \n","10-20%          | 30.14     \n","20-30%          | 9.97      \n","30-40%          | 3.14      \n","40-50%          | 1.22      \n","50-60%          | 0.61      \n","60-70%          | 0.33      \n","70-80%          | 0.17      \n","80-90%          | 0.12      \n","90-100%         | 0.08      \n"]}]},{"cell_type":"code","source":["tolerance_levels = [i / 100 for i in range(10, 51, 10)]  # [0.10, 0.20, 0.30, 0.40, 0.50]\n","accuracy_results = {}  # Dictionary to store the accuracy results for each tolerance level\n","\n","# Calculate accuracy for each tolerance level\n","for tolerance in tolerance_levels:\n","    within_tolerance = predictions.withColumn(\n","        \"within_tolerance\",\n","        F.when(F.abs((F.col(\"price\") - F.col(\"exp_prediction\")) / F.col(\"price\")) <= tolerance, 1).otherwise(0)\n","    )\n","\n","    # Compute the accuracy by averaging the 'within_tolerance' column\n","    accuracy = within_tolerance.agg(F.mean(\"within_tolerance\")).collect()[0][0] * 100\n","\n","    # Store the result in the dictionary\n","    accuracy_results[f\"{int(tolerance * 100)}%\"] = accuracy\n","    # print(f\"Accuracy within {int(tolerance * 100)}% tolerance: {accuracy:.2f}%\")\n","\n","# Display the results for each tolerance level\n","print(\"Summary of Accuracy Results:\")\n","for tolerance, acc in accuracy_results.items():\n","    print(f\"Tolerance Level: {tolerance} - Accuracy: {acc:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0fOAK-tSIGbd","executionInfo":{"status":"ok","timestamp":1730204596545,"user_tz":-480,"elapsed":339,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"c98fcade-6c7a-43bb-d90f-9a8d15ddcc19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Summary of Accuracy Results:\n","Tolerance Level: 10% - Accuracy: 54.00%\n","Tolerance Level: 20% - Accuracy: 84.14%\n","Tolerance Level: 30% - Accuracy: 94.11%\n","Tolerance Level: 40% - Accuracy: 97.26%\n","Tolerance Level: 50% - Accuracy: 98.48%\n"]}]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"-oGsKYUDbZ-j"}},{"cell_type":"markdown","source":["## **Linear Regression**"],"metadata":{"id":"FFwp4VxLcGaL"}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, OneHotEncoder\n","from pyspark.ml import Pipeline\n","from pyspark.ml.regression import LinearRegressionModel\n","from pyspark.ml.evaluation import RegressionEvaluator\n","import pyspark.sql.functions as F\n","from tqdm import tqdm\n","import warnings\n","import time\n","\n","# Start to track runtime\n","start_time = time.time()\n","\n","# Processing and preparing the test data\n","with tqdm(total=4, desc=\"Processing Test Data\") as pbar:\n","\n","    # Sample the data for testing (20% fraction used in training)\n","    df_sample = df.sample(fraction=0.2, seed=42)\n","    pbar.update(1)\n","\n","    # Handling categorical columns\n","    cat_columns = [field for (field, dtype) in df_sample.dtypes if dtype == \"string\"]\n","    stages = []\n","    for col_name in cat_columns:\n","        indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_indexed\", handleInvalid=\"keep\")\n","        encoder = OneHotEncoder(inputCol=f\"{col_name}_indexed\", outputCol=f\"{col_name}_encoded\")\n","        stages += [indexer, encoder]\n","    pbar.update(1)\n","\n","    # Converting 'franchise_dealer' to numeric if applicable\n","    df_sample = df_sample.withColumn(\"franchise_dealer\", F.col(\"franchise_dealer\").cast(\"int\"))\n","\n","    # Assemble features (ensure all columns used in 'VectorAssembler' are numeric)\n","    num_columns = [col for col in df_sample.columns if col not in ['price'] + cat_columns]\n","    encoded_columns = [f\"{col}_encoded\" for col in cat_columns]\n","    feature_columns = num_columns + encoded_columns\n","    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n","    stages += [assembler]\n","\n","    # Adding scaling to the pipeline (scaling the assembled feature vectors)\n","    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n","    stages += [scaler]\n","\n","    # Creating and applying the pipeline\n","    pipeline = Pipeline(stages=stages)\n","    pipeline_model = pipeline.fit(df_sample)\n","    df_sample = pipeline_model.transform(df_sample)\n","    pbar.update(1)\n","\n","    # Splitting the data into test set only for evaluation\n","    _, test_df = df_sample.randomSplit([0.8, 0.2], seed=42)\n","    pbar.update(1)\n","\n","print(\"Data preprocessing for test data completed.\")\n"],"metadata":{"id":"Vm71aomqcK5k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730200587166,"user_tz":-480,"elapsed":24041,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"b52f49cf-92d5-4a49-dffe-a86b50e08abb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing Test Data: 100%|██████████| 4/4 [00:24<00:00,  6.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Data preprocessing for test data completed.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# Path where the saved model is located\n","saved_model_path = \"/content/drive/MyDrive/Big Data Analytics - Project/models/Linear_Regression_model_FE\"\n","\n","# Load the saved Linear Regression model\n","loaded_model = LinearRegressionModel.load(saved_model_path)\n","print(f\"Model loaded successfully from {saved_model_path}\")\n","\n","# Make predictions on the test data\n","print(\"Making predictions with the loaded model on test data...\")\n","predictions = loaded_model.transform(test_df)\n","\n","# Evaluate the loaded model\n","print(\"Evaluating the loaded model...\")\n","\n","# R2 Score\n","evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n","r2 = evaluator.evaluate(predictions)\n","print(f\"\\nR-Squared Score (Accuracy): {r2 * 100:.2f}%\")\n","\n","# Additional metrics\n","mae_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"mae\")\n","mae = mae_evaluator.evaluate(predictions)\n","\n","mse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"mse\")\n","mse = mse_evaluator.evaluate(predictions)\n","\n","rmse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n","rmse = rmse_evaluator.evaluate(predictions)\n","\n","print(\"\\nAdditional Metrics:\")\n","print(f\"Mean Absolute Error: {round(mae)}\")\n","print(f\"Mean Squared Error: {round(mse)}\")\n","print(f\"Root Mean Squared Error: {round(rmse)}\")"],"metadata":{"id":"ogZHXFdCcNwl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730176472918,"user_tz":-480,"elapsed":2006992,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"3800779b-1756-4394-9674-0d498bcc8e7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model loaded successfully from /content/drive/MyDrive/Big Data Analytics - Project/models/Linear_Regression_model_FE\n","Making predictions with the loaded model on test data...\n","Evaluating the loaded model...\n","\n","R-Squared Score (Accuracy): 84.20%\n","\n","Additional Metrics:\n","Mean Absolute Error: 4131\n","Mean Squared Error: 52079104\n","Root Mean Squared Error: 7217\n"]}]},{"cell_type":"code","source":["# Load the saved Linear Regression model\n","saved_model_path = \"/content/drive/MyDrive/Big Data Analytics - Project/models/Linear_Regression_model_FE\"\n","loaded_model = LinearRegressionModel.load(saved_model_path)\n","\n","predictions = loaded_model.transform(test_df)\n","\n","# function to calculate MAPE\n","def calculate_mape(df, label_col=\"price\", prediction_col=\"prediction\"):\n","    mape_df = df.withColumn(\"abs_percentage_error\",\n","                            F.abs((F.col(label_col) - F.col(prediction_col)) / F.col(label_col)))\n","    mape = mape_df.select(F.mean(\"abs_percentage_error\")).collect()[0][0]\n","    return mape * 100  # MAPE as a percentage\n","\n","# function to calculate SMAPE\n","def calculate_smape(df, label_col=\"price\", prediction_col=\"prediction\"):\n","    smape_df = df.withColumn(\"symmetric_absolute_percentage_error\",\n","                             2 * F.abs(F.col(label_col) - F.col(prediction_col)) /\n","                             (F.abs(F.col(label_col)) + F.abs(F.col(prediction_col)))\n","                            )\n","    smape = smape_df.select(F.mean(\"symmetric_absolute_percentage_error\")).collect()[0][0]\n","    return smape * 100  # SMAPE as a percentage\n","\n","# Calculate MAPE\n","mape = calculate_mape(predictions)\n","print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n","\n","# Calculate SMAPE\n","smape = calculate_smape(predictions)\n","print(f\"Symmetric Mean Absolute Percentage Error (SMAPE): {smape:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a9fxtyjEMtze","executionInfo":{"status":"ok","timestamp":1730201261735,"user_tz":-480,"elapsed":674571,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"a054ba24-ce60-4419-95c2-15cb2f6f7b51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Absolute Percentage Error (MAPE): 18.82%\n","Symmetric Mean Absolute Percentage Error (SMAPE): 18.45%\n"]}]},{"cell_type":"code","source":["from pyspark.sql import functions as F\n","\n","# error ranges for the distribution table up to 100%\n","error_ranges = {\n","    \"0-10%\": (0.0, 0.10),\n","    \"10-20%\": (0.10, 0.20),\n","    \"20-30%\": (0.20, 0.30),\n","    \"30-40%\": (0.30, 0.40),\n","    \"40-50%\": (0.40, 0.50),\n","    \"50-60%\": (0.50, 0.60),\n","    \"60-70%\": (0.60, 0.70),\n","    \"70-80%\": (0.70, 0.80),\n","    \"80-90%\": (0.80, 0.90),\n","    \"90-100%\": (0.90, 1.0)\n","}\n","\n","distribution_results = {}\n","\n","# Calculate the distribution for each error range\n","for label, (lower, upper) in error_ranges.items():\n","    within_range = predictions.withColumn(\n","        \"in_range\",\n","        F.when(\n","            (F.abs((F.col(\"price\") - F.col(\"prediction\")) / F.col(\"price\")) >= lower) &\n","            (F.abs((F.col(\"price\") - F.col(\"prediction\")) / F.col(\"price\")) < upper),\n","            1\n","        ).otherwise(0)\n","    )\n","\n","    percentage_in_range = within_range.agg(F.mean(\"in_range\")).collect()[0][0] * 100\n","\n","    distribution_results[label] = percentage_in_range\n","\n","print(\"Error Range Distribution Table for GBT:\")\n","print(\"\\n\")\n","print(f\"{'Error Range':<15} | {'Percentage of Total Predictions (%)':<10}\")\n","print(\"-\" * 50)\n","for error_range, percentage in distribution_results.items():\n","    print(f\"{error_range:<15} | {percentage:<10.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bXUBTfEG1S6u","executionInfo":{"status":"ok","timestamp":1730205426649,"user_tz":-480,"elapsed":3,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"9d71a1fd-ed9b-4010-ba1c-95308572622b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error Range Distribution Table for Linear Regression:\n","\n","\n","Error Range     | Percentage of Total Predictions (%)\n","--------------------------------------------------\n","0-10%           | 46.73     \n","10-20%          | 28.02     \n","20-30%          | 11.35     \n","30-40%          | 4.72      \n","40-50%          | 2.49      \n","50-60%          | 1.56      \n","60-70%          | 1.01      \n","70-80%          | 0.78      \n","80-90%          | 0.63      \n","90-100%         | 0.44      \n"]}]},{"cell_type":"code","source":["tolerance_levels = [i / 100 for i in range(10, 51, 10)]  # [0.10, 0.20, 0.30, 0.40, 0.50]\n","accuracy_results = {}  # Dictionary to store the accuracy results for each tolerance level\n","\n","# Calculate accuracy for each tolerance level\n","for tolerance in tolerance_levels:\n","    within_tolerance = predictions.withColumn(\n","        \"within_tolerance\",\n","        F.when(F.abs((F.col(\"price\") - F.col(\"prediction\")) / F.col(\"price\")) <= tolerance, 1).otherwise(0)\n","    )\n","\n","    # Compute the accuracy by averaging the 'within_tolerance' column\n","    accuracy = within_tolerance.agg(F.mean(\"within_tolerance\")).collect()[0][0] * 100\n","\n","    # Store the result in the dictionary\n","    accuracy_results[f\"{int(tolerance * 100)}%\"] = accuracy\n","    # print(f\"Accuracy within {int(tolerance * 100)}% tolerance: {accuracy:.2f}%\")\n","\n","# Display the results for each tolerance level\n","print(\"Summary of Accuracy Results:\")\n","for tolerance, acc in accuracy_results.items():\n","    print(f\"Tolerance Level: {tolerance} - Accuracy: {acc:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xqv9-eGaTb9M","executionInfo":{"status":"ok","timestamp":1730204469865,"user_tz":-480,"elapsed":358,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"deee0b4a-6626-4e5c-aaa3-9fe7b37926c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Summary of Accuracy Results:\n","Tolerance Level: 10% - Accuracy: 46.73%\n","Tolerance Level: 20% - Accuracy: 74.75%\n","Tolerance Level: 30% - Accuracy: 86.10%\n","Tolerance Level: 40% - Accuracy: 90.82%\n","Tolerance Level: 50% - Accuracy: 93.31%\n"]}]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"R-fOAj3ZcXJQ"}},{"cell_type":"markdown","source":["## **GBT regressor**"],"metadata":{"id":"dpso0zOXdF6d"}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, OneHotEncoder\n","from pyspark.ml import Pipeline\n","from pyspark.ml.regression import GBTRegressionModel\n","from pyspark.ml.evaluation import RegressionEvaluator\n","import pyspark.sql.functions as F\n","from tqdm import tqdm\n","import warnings\n","import time\n","\n","# Ignore warnings\n","warnings.filterwarnings('ignore')\n","\n","# Start to track runtime\n","start_time = time.time()\n","\n","print(\"Processing the test data...\")\n","\n","# Processing and preparing the test data\n","with tqdm(total=4, desc=\"Progress\") as pbar:\n","\n","    # Sample the data for testing (20% fraction used in training)\n","    df_sample = df.sample(fraction=0.2, seed=42)\n","    pbar.update(1)\n","\n","    # Handling categorical columns\n","    cat_columns = [field for (field, dtype) in df_sample.dtypes if dtype == \"string\"]\n","    stages = []\n","    for col_name in cat_columns:\n","        indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_indexed\", handleInvalid=\"keep\")\n","        encoder = OneHotEncoder(inputCol=f\"{col_name}_indexed\", outputCol=f\"{col_name}_encoded\")\n","        stages += [indexer, encoder]\n","    pbar.update(1)\n","\n","    # Converting 'franchise_dealer' to numeric if applicable\n","    df_sample = df_sample.withColumn(\"franchise_dealer\", F.col(\"franchise_dealer\").cast(\"int\"))\n","\n","    # Assemble features (ensure all columns used in 'VectorAssembler' are numeric)\n","    num_columns = [col for col in df_sample.columns if col not in ['price'] + cat_columns]\n","    encoded_columns = [f\"{col}_encoded\" for col in cat_columns]\n","    feature_columns = num_columns + encoded_columns\n","    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n","    stages += [assembler]\n","\n","    # Adding scaling to the pipeline (scaling the assembled feature vectors)\n","    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n","    stages += [scaler]\n","\n","    # Creating and applying the pipeline\n","    pipeline = Pipeline(stages=stages)\n","    pipeline_model = pipeline.fit(df_sample)\n","    test_df = pipeline_model.transform(df_sample)\n","    pbar.update(1)\n","\n","    # Splitting the data into test set only for evaluation\n","    _, test_df = test_df.randomSplit([0.8, 0.2], seed=42)\n","    pbar.update(1)\n","\n","print(\"Data preprocessing for test data completed.\")\n"],"metadata":{"id":"LYVdIg_edtca","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730193119367,"user_tz":-480,"elapsed":14156,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"4b8a63a8-d6c0-4608-cf29-8a0e569daa2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing the test data...\n"]},{"output_type":"stream","name":"stderr","text":["Progress: 100%|██████████| 4/4 [00:13<00:00,  3.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Data preprocessing for test data completed.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# Load the saved GBT model\n","saved_model_path = \"/content/drive/MyDrive/Big Data Analytics - Project/models/GBT_model_FE\"\n","loaded_model = GBTRegressionModel.load(saved_model_path)\n","print(f\"Model loaded successfully from {saved_model_path}\")\n","\n","# Make predictions on the test data\n","print(\"Making predictions with the loaded model on test data...\")\n","predictions = loaded_model.transform(test_df)\n","\n","# Evaluate the loaded model\n","print(\"Evaluating the loaded model...\")\n","\n","# R2 Score\n","evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n","r2 = evaluator.evaluate(predictions)\n","print(f\"\\nR-Squared Score (Accuracy): {r2 * 100:.2f}%\")\n","\n","# Additional metrics\n","mae_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"mae\")\n","mae = mae_evaluator.evaluate(predictions)\n","\n","mse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"mse\")\n","mse = mse_evaluator.evaluate(predictions)\n","\n","rmse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n","rmse = rmse_evaluator.evaluate(predictions)\n","\n","print(\"\\nAdditional Metrics:\")\n","print(f\"Mean Absolute Error: {round(mae)}\")\n","print(f\"Mean Squared Error: {round(mse)}\")\n","print(f\"Root Mean Squared Error: {round(rmse)}\")"],"metadata":{"id":"YxLF__Ecdxzn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730170732803,"user_tz":-480,"elapsed":502,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"bb584068-7836-432b-ea72-ac5ec138ba75"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model loaded successfully from /content/drive/MyDrive/Big Data Analytics - Project/models/GBT_model_FE\n","Making predictions with the loaded model on test data...\n","Evaluating the loaded model...\n","\n","R-Squared Score (Accuracy): 88.57%\n","\n","Additional Metrics:\n","Mean Absolute Error: 3649\n","Mean Squared Error: 37663588\n","Root Mean Squared Error: 6137\n"]}]},{"cell_type":"code","source":["# Load the saved Linear Regression model\n","saved_model_path = \"/content/drive/MyDrive/Big Data Analytics - Project/models/GBT_model_FE\"\n","loaded_model = GBTRegressionModel.load(saved_model_path)\n","\n","predictions = loaded_model.transform(test_df)\n","\n","# function to calculate MAPE\n","def calculate_mape(df, label_col=\"price\", prediction_col=\"prediction\"):\n","    mape_df = df.withColumn(\"abs_percentage_error\",\n","                            F.abs((F.col(label_col) - F.col(prediction_col)) / F.col(label_col)))\n","    mape = mape_df.select(F.mean(\"abs_percentage_error\")).collect()[0][0]\n","    return mape * 100  # MAPE as a percentage\n","\n","# function to calculate SMAPE\n","def calculate_smape(df, label_col=\"price\", prediction_col=\"prediction\"):\n","    smape_df = df.withColumn(\"symmetric_absolute_percentage_error\",\n","                             2 * F.abs(F.col(label_col) - F.col(prediction_col)) /\n","                             (F.abs(F.col(label_col)) + F.abs(F.col(prediction_col)))\n","                            )\n","    smape = smape_df.select(F.mean(\"symmetric_absolute_percentage_error\")).collect()[0][0]\n","    return smape * 100  # SMAPE as a percentage\n","\n","# Calculate MAPE\n","mape = calculate_mape(predictions)\n","print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n","\n","# Calculate SMAPE\n","smape = calculate_smape(predictions)\n","print(f\"Symmetric Mean Absolute Percentage Error (SMAPE): {smape:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LRxmI1w9ixzk","executionInfo":{"status":"ok","timestamp":1730193624242,"user_tz":-480,"elapsed":463213,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"6520ec74-5656-4f99-9492-d7006ba632f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Absolute Percentage Error (MAPE): 14.43%\n","Symmetric Mean Absolute Percentage Error (SMAPE): 13.56%\n"]}]},{"cell_type":"code","source":["from pyspark.sql import functions as F\n","\n","# error ranges for the distribution table up to 100%\n","error_ranges = {\n","    \"0-10%\": (0.0, 0.10),\n","    \"10-20%\": (0.10, 0.20),\n","    \"20-30%\": (0.20, 0.30),\n","    \"30-40%\": (0.30, 0.40),\n","    \"40-50%\": (0.40, 0.50),\n","    \"50-60%\": (0.50, 0.60),\n","    \"60-70%\": (0.60, 0.70),\n","    \"70-80%\": (0.70, 0.80),\n","    \"80-90%\": (0.80, 0.90),\n","    \"90-100%\": (0.90, 1.0)\n","}\n","\n","distribution_results = {}\n","\n","# Calculate the distribution for each error range\n","for label, (lower, upper) in error_ranges.items():\n","    within_range = predictions.withColumn(\n","        \"in_range\",\n","        F.when(\n","            (F.abs((F.col(\"price\") - F.col(\"prediction\")) / F.col(\"price\")) >= lower) &\n","            (F.abs((F.col(\"price\") - F.col(\"prediction\")) / F.col(\"price\")) < upper),\n","            1\n","        ).otherwise(0)\n","    )\n","\n","    percentage_in_range = within_range.agg(F.mean(\"in_range\")).collect()[0][0] * 100\n","\n","    distribution_results[label] = percentage_in_range\n","\n","print(\"Error Range Distribution Table for GBT:\")\n","print(\"\\n\")\n","print(f\"{'Error Range':<15} | {'Percentage of Total Predictions (%)':<10}\")\n","print(\"-\" * 50)\n","for error_range, percentage in distribution_results.items():\n","    print(f\"{error_range:<15} | {percentage:<10.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jJ6vsSY-wyZI","executionInfo":{"status":"ok","timestamp":1730197626307,"user_tz":-480,"elapsed":465,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"1a5802e1-3fb5-4fba-b604-acd08e7a2326"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error Range Distribution Table for GBT:\n","\n","\n","Error Range     | Percentage of Total Predictions (%)\n","--------------------------------------------------\n","0-10%           | 49.23     \n","10-20%          | 29.53     \n","20-30%          | 11.95     \n","30-40%          | 4.62      \n","40-50%          | 2.01      \n","50-60%          | 0.93      \n","60-70%          | 0.56      \n","70-80%          | 0.32      \n","80-90%          | 0.20      \n","90-100%         | 0.13      \n"]}]},{"cell_type":"code","source":["tolerance_levels = [i / 100 for i in range(10, 51, 10)]  # [0.10, 0.20, 0.30, 0.40, 0.50]\n","accuracy_results = {}  # Dictionary to store the accuracy results for each tolerance level\n","\n","# Calculate accuracy for each tolerance level\n","for tolerance in tolerance_levels:\n","    within_tolerance = predictions.withColumn(\n","        \"within_tolerance\",\n","        F.when(F.abs((F.col(\"price\") - F.col(\"prediction\")) / F.col(\"price\")) <= tolerance, 1).otherwise(0)\n","    )\n","\n","    # Compute the accuracy by averaging the 'within_tolerance' column\n","    accuracy = within_tolerance.agg(F.mean(\"within_tolerance\")).collect()[0][0] * 100\n","\n","    # Store the result in the dictionary\n","    accuracy_results[f\"{int(tolerance * 100)}%\"] = accuracy\n","    # print(f\"Accuracy within {int(tolerance * 100)}% tolerance: {accuracy:.2f}%\")\n","\n","# Display the results for each tolerance level\n","print(\"Summary of Accuracy Results:\")\n","for tolerance, acc in accuracy_results.items():\n","    print(f\"Tolerance Level: {tolerance} - Accuracy: {acc:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9YR4DWb5jOM-","executionInfo":{"status":"ok","timestamp":1730204532384,"user_tz":-480,"elapsed":477,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"eda064fe-de5b-4ff6-b204-c2a19d98ab6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Summary of Accuracy Results:\n","Tolerance Level: 10% - Accuracy: 49.23%\n","Tolerance Level: 20% - Accuracy: 78.75%\n","Tolerance Level: 30% - Accuracy: 90.70%\n","Tolerance Level: 40% - Accuracy: 95.33%\n","Tolerance Level: 50% - Accuracy: 97.33%\n"]}]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"XDI2-1ZKPmVW"}},{"cell_type":"markdown","source":["## **Decision Tree Regressor**"],"metadata":{"id":"TbtT5dNnPrBO"}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, OneHotEncoder\n","from pyspark.ml import Pipeline\n","from pyspark.ml.regression import DecisionTreeRegressionModel\n","from pyspark.ml.evaluation import RegressionEvaluator\n","import pyspark.sql.functions as F\n","from tqdm import tqdm\n","import warnings\n","import time\n","\n","# Ignore warnings\n","warnings.filterwarnings('ignore')\n","\n","# Start to track runtime\n","start_time = time.time()\n","\n","print(\"Processing the test data...\")\n","\n","# Processing and preparing the test data\n","with tqdm(total=4, desc=\"Progress\") as pbar:\n","\n","    # Sample the data for testing (20% fraction used in training)\n","    df_sample = df.sample(fraction=0.2, seed=42)\n","    pbar.update(1)\n","\n","    # Handling categorical columns\n","    cat_columns = [field for (field, dtype) in df_sample.dtypes if dtype == \"string\"]\n","    stages = []\n","    for col_name in cat_columns:\n","        indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_indexed\", handleInvalid=\"keep\")\n","        encoder = OneHotEncoder(inputCol=f\"{col_name}_indexed\", outputCol=f\"{col_name}_encoded\")\n","        stages += [indexer, encoder]\n","    pbar.update(1)\n","\n","    # Converting 'franchise_dealer' to numeric if applicable\n","    df_sample = df_sample.withColumn(\"franchise_dealer\", F.col(\"franchise_dealer\").cast(\"int\"))\n","\n","    # Assemble features (ensure all columns used in 'VectorAssembler' are numeric)\n","    num_columns = [col for col in df_sample.columns if col not in ['price'] + cat_columns]\n","    encoded_columns = [f\"{col}_encoded\" for col in cat_columns]\n","    feature_columns = num_columns + encoded_columns\n","    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n","    stages += [assembler]\n","\n","    # Adding scaling to the pipeline (scaling the assembled feature vectors)\n","    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n","    stages += [scaler]\n","\n","    # Creating and applying the pipeline\n","    pipeline = Pipeline(stages=stages)\n","    pipeline_model = pipeline.fit(df_sample)\n","    test_df = pipeline_model.transform(df_sample)\n","    pbar.update(1)\n","\n","    # Splitting the data into test set only for evaluation\n","    _, test_df = test_df.randomSplit([0.8, 0.2], seed=42)\n","    pbar.update(1)\n","\n","print(\"Data preprocessing for test data completed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wdI3E3fgQx4w","executionInfo":{"status":"ok","timestamp":1730211192943,"user_tz":-480,"elapsed":20562,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"b9242270-be9e-4edd-dec8-50ffa4cf6626"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing the test data...\n"]},{"output_type":"stream","name":"stderr","text":["Progress: 100%|██████████| 4/4 [00:19<00:00,  4.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Data preprocessing for test data completed.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# Load the saved Decision Tree model\n","saved_model_path = \"/content/drive/MyDrive/Big Data Analytics - Project/models/Decision_Tree_Regression_model_FE\"\n","loaded_model = DecisionTreeRegressionModel.load(saved_model_path)\n","print(f\"Model loaded successfully from {saved_model_path}\")\n","\n","# Make predictions on the test data\n","print(\"Making predictions with the loaded model on test data...\")\n","predictions = loaded_model.transform(test_df)\n","\n","# Evaluate the loaded model\n","print(\"Evaluating the loaded model...\")\n","\n","# R2 Score\n","evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n","r2 = evaluator.evaluate(predictions)\n","print(f\"\\nR-Squared Score (Accuracy): {r2 * 100:.2f}%\")\n","\n","# Additional metrics\n","mae_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"mae\")\n","mae = mae_evaluator.evaluate(predictions)\n","\n","mse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"mse\")\n","mse = mse_evaluator.evaluate(predictions)\n","\n","rmse_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n","rmse = rmse_evaluator.evaluate(predictions)\n","\n","print(\"\\nAdditional Metrics:\")\n","print(f\"Mean Absolute Error: {round(mae)}\")\n","print(f\"Mean Squared Error: {round(mse)}\")\n","print(f\"Root Mean Squared Error: {round(rmse)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9T8KeKdWQ7xg","executionInfo":{"status":"ok","timestamp":1730212098530,"user_tz":-480,"elapsed":902976,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"a216d897-163f-42d9-9d6f-406572b5cfba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model loaded successfully from /content/drive/MyDrive/Big Data Analytics - Project/models/Decision_Tree_Regression_model_FE\n","Making predictions with the loaded model on test data...\n","Evaluating the loaded model...\n","\n","R-Squared Score (Accuracy): 88.38%\n","\n","Additional Metrics:\n","Mean Absolute Error: 3161\n","Mean Squared Error: 38316567\n","Root Mean Squared Error: 6190\n"]}]},{"cell_type":"code","source":["from pyspark.sql import functions as F\n","from pyspark.ml.regression import DecisionTreeRegressionModel\n","\n","# function to calculate MAPE\n","def calculate_mape(df, label_col=\"price\", prediction_col=\"prediction\"):\n","    mape_df = df.withColumn(\"abs_percentage_error\",\n","                            F.abs((F.col(label_col) - F.col(prediction_col)) / F.col(label_col)))\n","    mape = mape_df.select(F.mean(\"abs_percentage_error\")).collect()[0][0]\n","    return mape * 100  # MAPE as a percentage\n","\n","# function to calculate SMAPE\n","def calculate_smape(df, label_col=\"price\", prediction_col=\"prediction\"):\n","    smape_df = df.withColumn(\"symmetric_absolute_percentage_error\",\n","                             2 * F.abs(F.col(label_col) - F.col(prediction_col)) /\n","                             (F.abs(F.col(label_col)) + F.abs(F.col(prediction_col)))\n","                            )\n","    smape = smape_df.select(F.mean(\"symmetric_absolute_percentage_error\")).collect()[0][0]\n","    return smape * 100  # SMAPE as a percentage\n","\n","# Calculate MAPE\n","mape = calculate_mape(predictions)\n","print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n","\n","# Calculate SMAPE\n","smape = calculate_smape(predictions)\n","print(f\"Symmetric Mean Absolute Percentage Error (SMAPE): {smape:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"56OmjTazRQEC","executionInfo":{"status":"ok","timestamp":1730212522070,"user_tz":-480,"elapsed":423543,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"bc8b7a49-ad8b-463f-a05c-b2c7d2173f7e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Absolute Percentage Error (MAPE): 11.78%\n","Symmetric Mean Absolute Percentage Error (SMAPE): 11.13%\n"]}]},{"cell_type":"code","source":["from pyspark.sql import functions as F\n","\n","# error ranges for the distribution table up to 100%\n","error_ranges = {\n","    \"0-10%\": (0.0, 0.10),\n","    \"10-20%\": (0.10, 0.20),\n","    \"20-30%\": (0.20, 0.30),\n","    \"30-40%\": (0.30, 0.40),\n","    \"40-50%\": (0.40, 0.50),\n","    \"50-60%\": (0.50, 0.60),\n","    \"60-70%\": (0.60, 0.70),\n","    \"70-80%\": (0.70, 0.80),\n","    \"80-90%\": (0.80, 0.90),\n","    \"90-100%\": (0.90, 1.0)\n","}\n","\n","distribution_results = {}\n","\n","# Calculate the distribution for each error range\n","for label, (lower, upper) in error_ranges.items():\n","    within_range = predictions.withColumn(\n","        \"in_range\",\n","        F.when(\n","            (F.abs((F.col(\"price\") - F.col(\"prediction\")) / F.col(\"price\")) >= lower) &\n","            (F.abs((F.col(\"price\") - F.col(\"prediction\")) / F.col(\"price\")) < upper),\n","            1\n","        ).otherwise(0)\n","    )\n","\n","    percentage_in_range = within_range.agg(F.mean(\"in_range\")).collect()[0][0] * 100\n","\n","    distribution_results[label] = percentage_in_range\n","\n","print(\"Error Range Distribution Table for Decision Trees:\")\n","print(\"\\n\")\n","print(f\"{'Error Range':<15} | {'Percentage of Total Predictions (%)':<10}\")\n","print(\"-\" * 50)\n","for error_range, percentage in distribution_results.items():\n","    print(f\"{error_range:<15} | {percentage:<10.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S0iXtlh2SBdX","executionInfo":{"status":"ok","timestamp":1730214775740,"user_tz":-480,"elapsed":2253672,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"03e293f8-e905-4a40-935d-b336c66914d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error Range Distribution Table for Decision Trees:\n","\n","\n","Error Range     | Percentage of Total Predictions (%)\n","--------------------------------------------------\n","0-10%           | 58.66     \n","10-20%          | 26.57     \n","20-30%          | 8.76      \n","30-40%          | 2.94      \n","40-50%          | 1.22      \n","50-60%          | 0.64      \n","60-70%          | 0.39      \n","70-80%          | 0.22      \n","80-90%          | 0.13      \n","90-100%         | 0.11      \n"]}]},{"cell_type":"code","source":["tolerance_levels = [i / 100 for i in range(10, 51, 10)]  # [0.10, 0.20, 0.30, 0.40, 0.50]\n","accuracy_results = {}  # Dictionary to store the accuracy results for each tolerance level\n","\n","# Calculate accuracy for each tolerance level\n","for tolerance in tolerance_levels:\n","    within_tolerance = predictions.withColumn(\n","        \"within_tolerance\",\n","        F.when(F.abs((F.col(\"price\") - F.col(\"prediction\")) / F.col(\"price\")) <= tolerance, 1).otherwise(0)\n","    )\n","\n","    # Compute the accuracy by averaging the 'within_tolerance' column\n","    accuracy = within_tolerance.agg(F.mean(\"within_tolerance\")).collect()[0][0] * 100\n","\n","    # Store the result in the dictionary\n","    accuracy_results[f\"{int(tolerance * 100)}%\"] = accuracy\n","    # print(f\"Accuracy within {int(tolerance * 100)}% tolerance: {accuracy:.2f}%\")\n","\n","# Display the results for each tolerance level\n","print(\"Summary of Accuracy Results:\")\n","for tolerance, acc in accuracy_results.items():\n","    print(f\"Tolerance Level: {tolerance} - Accuracy: {acc:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GaPGXEXNeoi3","executionInfo":{"status":"ok","timestamp":1730215961206,"user_tz":-480,"elapsed":1185468,"user":{"displayName":"Adithya R","userId":"06981244434554202327"}},"outputId":"73014a76-3264-4f84-e93d-66fbec6dd931"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Summary of Accuracy Results:\n","Tolerance Level: 10% - Accuracy: 58.66%\n","Tolerance Level: 20% - Accuracy: 85.23%\n","Tolerance Level: 30% - Accuracy: 93.99%\n","Tolerance Level: 40% - Accuracy: 96.94%\n","Tolerance Level: 50% - Accuracy: 98.15%\n"]}]}]}